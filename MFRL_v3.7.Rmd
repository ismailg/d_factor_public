---
title: "Reinforcement Learning Model Parameter Recovery and Analysis"
author: "Your Name"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      fig.width = 10, fig.height = 7)
```

# Introduction: RL Model Parameter Recovery for Trust Game

This document provides a comprehensive approach for fitting reinforcement learning (RL) models to repeated trust game data and addressing common parameter recovery issues. The main challenges addressed are:

1. **Parameter Identifiability**: Some parameters (particularly social preference parameters like envy and guilt) may have similar effects on behavior, making them difficult to estimate individually.

2. **Optimization Problems**: RL model fitting often suffers from local minima and parameter boundary issues.

3. **Numerical Stability**: Standard optimization approaches can be vulnerable to numerical instabilities.

4. **Diagnostic Tools**: We need methods to assess which parameters can be reliably recovered.

This document provides an end-to-end pipeline for analyzing model fit, parameter recovery, and making decisions about which parameters to fix versus estimate.

## Loading Required Libraries

```{r load_libraries}
# Core libraries
library(tidyverse)
library(optimx)
library(lhs)      # For Latin hypercube sampling
library(parallel) # For parallel computing
library(pbapply)  # For progress bars (optional)

# Visualization libraries
library(ggplot2)
library(gridExtra)
library(viridis)
library(reshape2)
library(scales)

# Set a seed for reproducibility
# set.seed(123)
```

# 1. Basic Helper Functions

These are utility functions to support the RL model:

```{r helper_functions}
#' Convert investment value to a discrete state bin (1-3)
#' 
#' Maps continuous investment values to discrete states for the Q-learning model
#' 
#' @param investment Numeric investment amount
#' @return Integer state bin (1, 2, or 3)
get_investment_bin <- function(investment) {
  if (investment <= 7)   return(1)
  if (investment <= 14)  return(2)
  return(3)
}

#' Convert return proportion to a discrete action bin (1-6)
#' 
#' Maps continuous return proportions to discrete actions for the Q-learning model
#' 
#' @param return_prop Numeric return proportion (0-1)
#' @return Integer action bin (1-6)
get_return_bin <- function(return_prop) {
  if (return_prop < 0 || return_prop > 1) 
    stop("Return proportion must be between 0 and 1.")
  # 6 equal-sized bins in [0,1]
  return(min(floor(return_prop * 6) + 1, 6))
}

#' Calculate utility using Fehr-Schmidt inequality aversion model
#' 
#' Computes utility based on own payoff and other's payoff, accounting for
#' disadvantageous inequality (envy) and advantageous inequality (guilt)
#' 
#' @param own_payoff Numeric payoff for self
#' @param other_payoff Numeric payoff for other player
#' @param envy Parameter for disadvantageous inequality (when other gets more)
#' @param guilt Parameter for advantageous inequality (when self gets more)
#' @return Numeric utility value
calculate_fs_utility <- function(own_payoff, other_payoff, envy, guilt) {
  # Disadvantageous inequality (when other gets more than self)
  disadv <- max(other_payoff - own_payoff, 0)
  # Advantageous inequality (when self gets more than other)
  adv    <- max(own_payoff - other_payoff, 0)
  # Fehr-Schmidt utility
  return(own_payoff - envy * disadv - guilt * adv)
}

#' Map investor HMM state name to numeric bin
#' 
#' @param state Character state name ("unhappy", "neutral", or "happy")
#' @return Integer state bin (1, 2, or 3)
state_to_bin <- function(state) {
  if (state == "unhappy") return(1)
  if (state == "neutral") return(2)
  if (state == "happy")   return(3)
  stop("state_to_bin: unknown state")
}

#' Map numeric bin to investment amount
#' 
#' @param s_bin Integer state bin (1, 2, or 3)
#' @return Numeric investment amount
bin_to_investment <- function(s_bin) {
  # 1 => invests 4, 2 => invests 11, 3 => invests 17
  if (s_bin == 1) return(4)
  if (s_bin == 2) return(11)
  if (s_bin == 3) return(17)
  stop("Invalid s_bin in bin_to_investment()")
}

#' Map action bin to return proportion
#' 
#' @param a_bin Integer action bin (1-6)
#' @return Numeric return proportion
bin_to_return_prop <- function(a_bin) {
  # midpoints of 6 equal bins in [0,1]: (2*a_bin - 1)/12
  return((2 * a_bin - 1) / 12)
}
```

# 2. Investor's HMM Transition Functions

These functions model how the investor changes their internal state based on the net profit/loss they receive. These represent the "environment" that the trustee (our RL agent) interacts with.

```{r investor_hmm}
#' Update investor state based on profit/loss in standard condition
#' 
#' @param state Current state ("unhappy", "neutral", or "happy")
#' @param PnL Profit/loss (return - investment)
#' @return New state name
updateState <- function(state, PnL) {
  if (state == "unhappy") {
    mod <- c(
      exp(0.0 + 0.0 * PnL),
      exp(-3.366027  + 0.40910797 * PnL),
      exp(-3.572619  - 0.08137274 * PnL)
    )
  } else if (state == "neutral") {
    mod <- c(
      exp(0.0 + 0.0 * PnL),
      exp(3.3142637  + 0.3763408  * PnL),
      exp(0.9169736  + 0.4502838  * PnL)
    )
  } else if (state == "happy") {
    mod <- c(
      exp(0.0 + 0.0 * PnL),
      exp(0.7134085  + 0.02101626 * PnL),
      exp(2.2215478  + 0.16162964 * PnL)
    )
  } else {
    stop("updateState: unknown current state.")
  }
  mod <- mod / sum(mod)
  new_states <- c("unhappy","neutral","happy")
  return(new_states[sample(seq_along(mod), 1, prob = mod)])
}

#' Update investor state based on profit/loss in volatile condition
#' 
#' Alternative transition function for second game condition
#' 
#' @param state Current state ("unhappy", "neutral", or "happy")
#' @param PnL Profit/loss (return - investment)
#' @return New state name
updateState_vol <- function(state, PnL) {
  if (state == "unhappy") {
    mod <- c(
      exp(0.0 + 0.0 * PnL),
      exp(-3.366027  + 0.40910797 * PnL),
      exp(-3.572619  - 0.08137274 * PnL)
    )
  } else if (state == "neutral") {
    # Example alternative transitions. You can customize.
    mod <- c(
      exp(0.0 + 0.0 * PnL),
      exp(1 + 0.27 * PnL),
      exp(-4 + 0.75 * PnL)
    )
  } else if (state == "happy") {
    mod <- c(
      exp(0.0 + 0.0 * PnL),
      exp(0.7134085  + 0.02101626 * PnL),
      exp(2.2215478  + 0.16162964 * PnL)
    )
  } else {
    stop("updateState_vol: unknown current state.")
  }
  mod <- mod / sum(mod)
  new_states <- c("unhappy","neutral","happy")
  return(new_states[sample(seq_along(mod), 1, prob = mod)])
}
```

# 3. RL Model Simulation Functions

The simulation functions generate data using the RL model and HMM investors. These are used for parameter recovery testing and posterior predictive checks.

```{r simulation_functions}
#' Simulate data for two games using model-free RL with HMM investor
#' 
#' This function generates artificial data from the RL model interacting with
#' an HMM investor over two games.
#' 
#' @param params_trustee Parameters for the trustee (alpha, temp, envy, guilt)
#' @param game_size Number of rounds per game
#' @param playerId Identifier for the simulated player
#' @return Dataframe with simulated game data
simulate_2games_data_mf_hmm <- function(params_trustee, game_size = 25, playerId = 1) {
  # Extract parameters
  if (is.list(params_trustee)) {
    alpha <- params_trustee$alpha
    temp <- params_trustee$temp
    envy <- params_trustee$envy
    guilt <- params_trustee$guilt
  } else if (length(params_trustee) == 4) {
    alpha <- params_trustee[1]
    temp <- params_trustee[2]
    envy <- params_trustee[3]
    guilt <- params_trustee[4]
  } else {
    stop("simulate_2games_data_mf_hmm expects 4 trustee parameters: alpha, temp, envy, guilt")
  }
  
  # Parameter validation to prevent numerical issues
  alpha <- min(max(alpha, 0.001), 0.999)
  temp <- max(temp, 0.01)
  
  total_rounds <- 2 * game_size
  
  # Create dataframe to store simulation results
  df <- data.frame(
    trial = 1:total_rounds,
    investment = rep(NA, total_rounds),
    return = rep(NA, total_rounds),
    gameNum.f = factor(rep("first game", total_rounds),
                       levels = c("first game", "second game"))
  )
  df$gameNum.f[(game_size + 1):total_rounds] <- "second game"
  
  # Track additional information for debugging
  df$investor_state <- rep(NA, total_rounds)
  df$chosen_action <- rep(NA, total_rounds)
  df$reward <- rep(NA, total_rounds)
  df$td_error <- rep(NA, total_rounds)
  
  # Start each game in the 'neutral' state for the investor
  current_state <- "neutral"
  
  # Trustee Q-values: 3 states x 6 actions
  Q <- matrix(0, nrow = 3, ncol = 6)
  gamma <- 1  # Discount factor
  
  for (t in 1:total_rounds) {
    # Reinitialize Q and investor state at the start of game 2
    if (t == (game_size + 1)) {
      Q <- matrix(0, nrow = 3, ncol = 6)
      current_state <- "neutral"
    }
    
    # 1) Investor invests based on their current state
    s_bin <- state_to_bin(current_state)
    invest_amt <- bin_to_investment(s_bin)
    df$investment[t] <- invest_amt
    df$investor_state[t] <- current_state
    
    # 2) Trustee chooses action from Q–learning's softmax
    Q_s <- Q[s_bin, ]
    Q_shifted <- Q_s - max(Q_s)  # For numerical stability
    probs <- exp(Q_shifted / temp)
    probs <- pmax(probs, 1e-12)  # Avoid zero probabilities
    probs <- probs / sum(probs)
    
    a_bin <- sample(1:6, 1, prob = probs)  # Sample action from softmax distribution
    df$chosen_action[t] <- a_bin
    
    ret_prop <- bin_to_return_prop(a_bin)
    ret_amt <- round(ret_prop * (3 * invest_amt))
    df$return[t] <- ret_amt
    
    # 3) Calculate payoffs and reward
    trustee_payoff <- 3 * invest_amt - ret_amt
    investor_payoff <- ret_amt - invest_amt
    
    # Fehr–Schmidt utility for trustee
    rew <- calculate_fs_utility(trustee_payoff, investor_payoff, envy, guilt)
    df$reward[t] <- rew
    
    # 4) Q–update
    if (t < total_rounds) {
      # Next investor state depends on whether it's game1 or game2
      if (df$gameNum.f[t] == "first game") {
        updateFunc <- updateState
      } else {
        updateFunc <- updateState_vol
      }
      PnL <- investor_payoff  # (ret_amt - invest_amt)
      next_state <- updateFunc(current_state, PnL)
      s_bin_next <- state_to_bin(next_state)
      
      # TD learning update
      td_err <- rew + gamma * max(Q[s_bin_next, ]) - Q[s_bin, a_bin]
      df$td_error[t] <- td_err
      
      Q[s_bin, a_bin] <- Q[s_bin, a_bin] + alpha * td_err
      
      current_state <- next_state
    } else {
      # final round
      td_err <- rew - Q[s_bin, a_bin]
      df$td_error[t] <- td_err
      
      Q[s_bin, a_bin] <- Q[s_bin, a_bin] + alpha * td_err
    }
  }
  
  df$playerId <- playerId
  df$roundNum <- rep(1:game_size, 2)  # Add round numbers within each game
  
  # Store Q-values and true parameters as attributes
  attr(df, "Q_values") <- Q
  attr(df, "true_params") <- list(alpha=alpha, temp=temp, envy=envy, guilt=guilt)
  
  return(df)
}
```

# 4. Model-Free Reinforcement Learning Model

This is the core RL model for the trustee in the Trust Game. It takes observed data and computes the negative log likelihood of the choices given the model parameters.

```{r direct_learning_model}
#' Model-free RL model for trustee choices in the Trust Game
#' 
#' This function implements a Q-learning model with Fehr-Schmidt social 
#' preferences. It computes the negative log likelihood of observed choices 
#' given the parameter values.
#' 
#' @param params_free Vector of free parameters to be estimated
#' @param data Dataframe containing observed game data
#' @param param_fixed List of fixed parameters (not to be estimated)
#' @param return_internals Whether to return internal model variables
#' @return Negative log likelihood (or model internals if requested)
direct_learning_model <- function(params_free, data, param_fixed = list(), return_internals = FALSE) {
  # 1) Reconstruct full parameter set from free and fixed parameters
  all_names <- c("alpha", "temp", "envy", "guilt")
  par_vals <- numeric(length(all_names))
  
  idx_free <- 1
  for (i in seq_along(all_names)) {
    nm <- all_names[i]
    if (!is.null(param_fixed[[nm]])) {
      # Use fixed parameter value
      par_vals[i] <- param_fixed[[nm]]
    } else {
      # Use value from free parameters vector
      if (idx_free <= length(params_free)) {
        par_vals[i] <- params_free[idx_free]
        idx_free <- idx_free + 1
      } else {
        warning(paste("Not enough free parameters provided. Missing value for", nm))
        par_vals[i] <- NA
      }
    }
  }
  
  # Input validation and bounds enforcement
  alpha <- min(max(par_vals[1], 0.001), 0.999)  # Avoid exact 0,1
  temp <- max(par_vals[2], 0.01)  # Prevent division by zero
  envy <- max(par_vals[3], 0)  # Non-negative
  guilt <- max(par_vals[4], 0)  # Non-negative
  
  # Model constants
  gamma <- 1  # Discount factor
  n_actions <- 6  # Number of discretized actions
  
  # Initialize variables
  n_trials <- nrow(data)
  neg_log_lik <- 0
  Q_values <- matrix(0, nrow=3, ncol=n_actions)
  
  # For storing model internals if requested
  if (return_internals) {
    internals <- list(
      trial = integer(),
      state = integer(),
      action = integer(),
      reward = numeric(),
      next_state = integer(),
      td_error = numeric(),
      probs = list(),
      log_lik = numeric(),
      Q_values = list()
    )
  }
  
  # Track the current game (to reset Q-values between games)
  current_game <- data$gameNum.f[1]
  
  # Loop through all trials
  for (t in seq_len(n_trials)) {
    invest_amt <- data$investment[t]
    actual_return <- data$return[t]
    
    # Skip invalid trials
    if (is.na(invest_amt) || is.na(actual_return) || invest_amt == 0) 
      next
    
    # Reset Q-values at the start of a new game
    if (t > 1 && data$gameNum.f[t] != current_game) {
      Q_values <- matrix(0, nrow=3, ncol=6)
      current_game <- data$gameNum.f[t]
    }
    
    # Get current state (based on investment amount)
    s_bin <- get_investment_bin(invest_amt)
    
    # Calculate action probabilities using softmax
    Q_s <- Q_values[s_bin,]
    shift <- Q_s - max(Q_s)  # For numerical stability
    probs <- exp(shift / temp)
    probs <- pmax(probs, 1e-12)  # Avoid zero probabilities
    probs <- probs / sum(probs)
    
    # Get actual chosen action (from observed return)
    actual_prop <- actual_return / (3 * invest_amt)
    chosen_bin <- get_return_bin(actual_prop)
    
    # Ensure action bin is valid
    if (chosen_bin < 1 || chosen_bin > 6) {
      warning(paste("Invalid action bin:", chosen_bin, "for return proportion:", actual_prop))
      chosen_bin <- min(max(chosen_bin, 1), 6)
    }
    
    # Update negative log likelihood
    current_ll <- log(probs[chosen_bin])
    neg_log_lik <- neg_log_lik - current_ll
    
    # Calculate payoffs and reward
    trustee_payoff <- 3 * invest_amt - actual_return
    investor_payoff <- actual_return - invest_amt
    reward <- calculate_fs_utility(trustee_payoff, investor_payoff, envy, guilt)
    
    # Calculate future value for TD learning
    if (t < n_trials) {
      next_invest <- data$investment[t + 1]
      if (!is.na(next_invest) && next_invest > 0) {
        next_s_bin <- get_investment_bin(next_invest)
        future_val <- max(Q_values[next_s_bin,])
      } else {
        future_val <- 0
      }
    } else {
      future_val <- 0
    }
    
    # TD learning update
    pe <- reward + gamma*future_val - Q_values[s_bin, chosen_bin]
    Q_values[s_bin, chosen_bin] <- Q_values[s_bin, chosen_bin] + alpha*pe
    
    # Store internals if requested
    if (return_internals) {
      internals$trial <- c(internals$trial, t)
      internals$state <- c(internals$state, s_bin)
      internals$action <- c(internals$action, chosen_bin)
      internals$reward <- c(internals$reward, reward)
      internals$next_state <- c(internals$next_state, ifelse(t < n_trials, next_s_bin, NA))
      internals$td_error <- c(internals$td_error, pe)
      internals$probs[[length(internals$probs) + 1]] <- probs
      internals$log_lik <- c(internals$log_lik, current_ll)
      internals$Q_values[[length(internals$Q_values) + 1]] <- Q_values
    }
  }
  
  # Return results
  if (return_internals) {
    return(list(neg_log_lik = neg_log_lik, internals = internals, final_Q = Q_values))
  } else {
    return(neg_log_lik)
  }
}
```

# 5. Parameter Transformation Functions

These functions help with the optimization by transforming bounded parameters to unbounded space, which improves optimization stability.

```{r parameter_transforms}
#' Transform parameter from unbounded to bounded space using logistic function
#' 
#' @param x Unbounded parameter value
#' @param lb Lower bound
#' @param ub Upper bound
#' @return Bounded parameter value
transform_bounded <- function(x, lb, ub) {
  lb + (ub - lb) * (1/(1 + exp(-x))) # Logistic transform
}

#' Transform parameter from bounded to unbounded space (inverse logistic)
#' 
#' @param y Bounded parameter value
#' @param lb Lower bound
#' @param ub Upper bound
#' @return Unbounded parameter value
inverse_bounded <- function(y, lb, ub) {
  -log((ub - lb)/(y - lb) - 1)
}
```

# 6. Robust Model Fitting

This is an enhanced fitting function that uses multiple optimization methods and starting points to improve parameter recovery.

```{r robust_fitting}
#' Fit RL model to data with robust optimization
#' 
#' This function finds the best-fitting parameters by using multiple
#' optimization methods and starting points. It handles parameter transformations
#' to improve stability and provides detailed diagnostics.
#' 
#' @param participant_data Dataframe with observed game data
#' @param param_fixed List of parameters to fix (not estimate)
#' @param n_multistart Number of different starting points to try
#' @param verbose Whether to print detailed progress information
#' @return List with fitted parameters and diagnostics
fit_direct_model_robust <- function(participant_data,
                                  param_fixed = list(alpha=NULL, temp=NULL, envy=NULL, guilt=NULL),
                                  n_multistart = 10,
                                  verbose = FALSE) {
  # For convenience, create roundNum if not present
  if (!"roundNum" %in% names(participant_data)) {
    participant_data <- participant_data %>%
      group_by(gameNum.f, playerId) %>%
      mutate(roundNum = row_number()) %>%
      ungroup()
  }
  
  # Set bounds for free parameters
  bounds_list <- list(
    alpha = c(0.001, 0.999),  # Avoid exact 0,1 boundaries
    temp  = c(0.01, 15),
    envy  = c(0, 5),
    guilt = c(0, 2)
  )
  
  # Identify which parameters are free vs. fixed
  all_names <- c("alpha", "temp", "envy", "guilt")
  free_names <- c()
  lower <- c()
  upper <- c()
  
  for (nm in all_names) {
    if (is.null(param_fixed[[nm]])) {
      free_names <- c(free_names, nm)
      lower <- c(lower, bounds_list[[nm]][1])
      upper <- c(upper, bounds_list[[nm]][2])
    }
  }
  
  # If all parameters are fixed, just evaluate NLL without optimization
  if (length(free_names) == 0) {
    nll_val <- direct_learning_model(params_free=numeric(0),
                                  data=participant_data,
                                  param_fixed=param_fixed)
    return(list(params=param_fixed,
              neg_log_lik=nll_val,
              aic=NA, bic=NA,
              converged=TRUE,
              message="All parameters fixed; no optimization done.",
              internals=NULL))
  }
  
  # Initialize tracking variables
  best_nll <- Inf
  best_par <- NULL
  all_fits <- list()
  
  # Parameter transformation function for optimization
  transform_params <- function(unconstrained_params) {
    constrained <- numeric(length(unconstrained_params))
    for (i in seq_along(free_names)) {
      nm <- free_names[i]
      if (nm == "alpha") {
        # Logit transformation for alpha in (0,1)
        constrained[i] <- 1/(1+exp(-unconstrained_params[i]))
      } else if (nm == "temp") {
        # Exp transformation for positive temp
        constrained[i] <- transform_bounded(unconstrained_params[i], 0.01,15)
      } else if (nm == "envy") {
        constrained[i] <- transform_bounded(unconstrained_params[i], 0, 5)
      } else if (nm == "guilt") {
        constrained[i] <- transform_bounded(unconstrained_params[i], 0, 2)
      }
    }
    return(constrained)
  }

  # Inverse transformation function
  inverse_transform <- function(constrained_params) {
    unconstrained <- numeric(length(constrained_params))
    for (i in seq_along(free_names)) {
      nm <- free_names[i]
      if (nm == "alpha") {
        # Inverse logit
        unconstrained[i] <- log(constrained_params[i]/(1-constrained_params[i]))
      } else if (nm == "temp") {
        # Log transformation
        unconstrained[i] <- log(constrained_params[i])
      } else if (nm == "envy") {
        unconstrained[i] <- inverse_bounded(constrained_params[i], 0, 5)
      } else if (nm == "guilt") {
        unconstrained[i] <- inverse_bounded(constrained_params[i], 0, 2)
      }
    }
    return(unconstrained)
  }
  
  # Wrapped objective function with transformation
  objective_transformed <- function(unconstrained_params) {
    constrained_params <- transform_params(unconstrained_params)
    return(direct_learning_model(constrained_params, participant_data, param_fixed))
  }
  
  # Create theoretically informed starting points
  init_list <- list()
  
  # First we add theory-based starting points
  if ("alpha" %in% free_names && "temp" %in% free_names) {
    alpha_starts <- c(0.2, 0.5, 0.8)  # Common learning rates
    temp_starts <- c(0.5, 1.0, 3.0)    # Common temperature values
    
    for (a in alpha_starts) {
      for (t in temp_starts) {
        init <- lower  # Start with lower bounds
        idx_alpha <- which(free_names == "alpha")
        idx_temp <- which(free_names == "temp")
        
        # Set specific values for alpha and temp
        init[idx_alpha] <- a
        init[idx_temp] <- t
        
        # Add envy and guilt values if they're free parameters
        if ("envy" %in% free_names) {
          idx_envy <- which(free_names == "envy")
          init[idx_envy] <- 0.5  # Moderate envy
        }
        if ("guilt" %in% free_names) {
          idx_guilt <- which(free_names == "guilt")
          init[idx_guilt] <- 0.3  # Moderate guilt
        }
        
        # Transform to unconstrained space and add to init list
        init_list[[length(init_list) + 1]] <- inverse_transform(init)
      }
    }
  }
  
  # Add additional random starting points using Latin Hypercube Sampling
  remaining_points <- n_multistart - length(init_list)
  if (remaining_points > 0) {
    lhs_samples <- randomLHS(remaining_points, length(free_names))
    for (i in 1:remaining_points) {
      init <- lower + (upper - lower) * lhs_samples[i,]
      init_list[[length(init_list) + 1]] <- inverse_transform(init)
    }
  }
  
  # Try multiple optimization methods for each starting point
  for (i in seq_along(init_list)) {
    init <- init_list[[i]]
    
    if (verbose) {
      cat("Starting optimization", i, "of", length(init_list), "...\n")
      cat("Initial unconstrained params:", init, "\n")
    }
    
    # METHOD 1: Simulated annealing for global search
    fit_global <- tryCatch({
      optim(par = init,
            fn = objective_transformed,
            method = "SANN",
            control = list(maxit = 1000, temp = 10, tmax = 10))
    }, error = function(e) {
      if (verbose) cat("SANN optimization failed:", e$message, "\n")
      NULL
    })
    
    if (!is.null(fit_global)) {
      # METHOD 2: L-BFGS-B to refine result
      fit_lbfgs <- tryCatch({
        optimx(par = fit_global$par,
               fn = objective_transformed,
               method = "L-BFGS-B",
               control = list(maxit=1000, dowarn=FALSE))
      }, error = function(e) {
        if (verbose) cat("L-BFGS-B optimization failed:", e$message, "\n")
        NULL
      })
      
      if (!is.null(fit_lbfgs)) {
        val <- fit_lbfgs$value[1]
        if (val < best_nll) {
          best_nll <- val
          best_par_transformed <- as.numeric(fit_lbfgs[1, 1:length(free_names)])
          best_par <- transform_params(best_par_transformed)
          
          if (verbose) {
            cat("New best value:", val, "with params:", best_par, "\n")
          }
        }
        
        # Store all fits for diagnostics
        all_fits[[length(all_fits) + 1]] <- list(
          method = "L-BFGS-B after SANN",
          value = val,
          params = transform_params(as.numeric(fit_lbfgs[1, 1:length(free_names)])),
          converged = fit_lbfgs$convcode[1] == 0
        )
      }
    }
    
    # METHOD 3: Try Nelder-Mead directly
    fit_nm <- tryCatch({
      optim(par = init,
            fn = objective_transformed,
            method = "Nelder-Mead",
            control = list(maxit = 2000))
    }, error = function(e) {
      if (verbose) cat("Nelder-Mead optimization failed:", e$message, "\n")
      NULL
    })
    
    if (!is.null(fit_nm)) {
      val <- fit_nm$value
      if (val < best_nll) {
        best_nll <- val
        best_par <- transform_params(fit_nm$par)
        
        if (verbose) {
          cat("New best value from Nelder-Mead:", val, "with params:", best_par, "\n")
        }
      }
      
      all_fits[[length(all_fits) + 1]] <- list(
        method = "Nelder-Mead",
        value = val,
        params = transform_params(fit_nm$par),
        converged = fit_nm$convergence == 0
      )
    }
  }
  
  # Check if optimization succeeded
  if (is.null(best_par)) {
    return(list(params=NA, neg_log_lik=NA, aic=NA, bic=NA,
              converged=FALSE, message="Fitting failed - all methods.",
              all_fits=all_fits))
  }
  
  # Reconstruct the full parameter set
  final_par <- param_fixed
  idx <- 1
  for (nm in all_names) {
    if (is.null(final_par[[nm]])) {
      final_par[[nm]] <- best_par[idx]
      idx <- idx + 1
    }
  }
  
  # Compute AIC & BIC
  n_obs <- sum(!is.na(participant_data$investment) & participant_data$investment > 0)
  n_par <- length(free_names)
  aic <- 2*best_nll + 2*n_par
  bic <- 2*best_nll + log(n_obs)*n_par
  
  # Get model internals for the best parameters
  internals <- tryCatch({
    result <- direct_learning_model(
      params_free = unlist(final_par[free_names]),
      data = participant_data,
      param_fixed = param_fixed,
      return_internals = TRUE
    )
    result$internals
  }, error = function(e) {
    warning("Failed to get model internals: ", e$message)
    NULL
  })
  
  # Return results
  list(params = final_par,
     neg_log_lik = best_nll,
     aic = aic,
     bic = bic,
     converged = TRUE,
     message = "OK",
     all_fits = all_fits,
     internals = internals)
}
```

# 7. Parallel Fitting of Multiple Participants

This function fits the model to data from multiple participants in parallel, using the approach from the original code provided.

```{r parallel_fitting}
#' Fit model to data from multiple participants in parallel
#' 
#' @param full_data Dataframe with data from all participants
#' @param param_fixed List of parameters to fix (not estimate)
#' @param n_multistart Number of different starting points to try
#' @param n_cores Number of CPU cores to use for parallel processing
#' @return Dataframe with fitting results for all participants
# fit_all_participants_parallel <- function(full_data, 
#                                          param_fixed = list(), 
#                                          n_multistart = 10, 
#                                          n_cores = 8) {
#   # Split data by participant
#   participants <- split(full_data, full_data$playerId)
#   
#   # Set up parallel cluster
#   cl <- makeCluster(n_cores)
#   
#   # Export necessary functions to cluster
#   clusterExport(cl, varlist = c(
#     "direct_learning_model", "fit_direct_model_robust",
#     "transform_bounded", "inverse_bounded",
#     "get_investment_bin", "get_return_bin", "calculate_fs_utility",
#     "param_fixed", "n_multistart",
#     "randomLHS"
#   ), envir = environment())
#   
#   # Load required libraries in each cluster node
#   clusterEvalQ(cl, {
#     library(tidyverse)
#     library(optimx)
#     library(lhs)
#   })
#   
#   # Fit model to each participant's data in parallel
#   if (requireNamespace("pbapply", quietly = TRUE)) {
#     results_list <- pbapply::pblapply(participants, function(p_data) {
#       tryCatch({
#         fit_result <- fit_direct_model_robust(
#           p_data, 
#           param_fixed = param_fixed, 
#           n_multistart = n_multistart,
#           verbose = FALSE
#         )
#         
#         # Format results
#         data.frame(
#           playerId = unique(p_data$playerId),
#           neg_log_lik = fit_result$neg_log_lik,
#           aic = fit_result$aic,
#           bic = fit_result$bic,
#           alpha = ifelse(is.null(fit_result$params$alpha), NA, fit_result$params$alpha),
#           temp = ifelse(is.null(fit_result$params$temp), NA, fit_result$params$temp),
#           envy = ifelse(is.null(fit_result$params$envy), NA, fit_result$params$envy),
#           guilt = ifelse(is.null(fit_result$params$guilt), NA, fit_result$params$guilt),
#           converged = !is.null(fit_result$converged) && fit_result$converged,
#           message = ifelse(is.null(fit_result$message), "Error", fit_result$message),
#           stringsAsFactors = FALSE
#         )
#       }, error = function(e) {
#         data.frame(
#           playerId = unique(p_data$playerId),
#           neg_log_lik = NA, aic = NA, bic = NA,
#           alpha = NA, temp = NA, envy = NA, guilt = NA,
#           converged = FALSE,
#           message = as.character(e),
#           stringsAsFactors = FALSE
#         )
#       })
#     }, cl = cl)
#   } else {
#     results_list <- parLapplyLB(cl, participants, function(p_data) {
#       tryCatch({
#         fit_result <- fit_direct_model_robust(
#           p_data, 
#           param_fixed = param_fixed, 
#           n_multistart = n_multistart,
#           verbose = FALSE
#         )
#         
#         # Format results
#         data.frame(
#           playerId = unique(p_data$playerId),
#           neg_log_lik = fit_result$neg_log_lik,
#           aic = fit_result$aic,
#           bic = fit_result$bic,
#           alpha = ifelse(is.null(fit_result$params$alpha), NA, fit_result$params$alpha),
#           temp = ifelse(is.null(fit_result$params$temp), NA, fit_result$params$temp),
#           envy = ifelse(is.null(fit_result$params$envy), NA, fit_result$params$envy),
#           guilt = ifelse(is.null(fit_result$params$guilt), NA, fit_result$params$guilt),
#           converged = !is.null(fit_result$converged) && fit_result$converged,
#           message = ifelse(is.null(fit_result$message), "Error", fit_result$message),
#           stringsAsFactors = FALSE
#         )
#       }, error = function(e) {
#         data.frame(
#           playerId = unique(p_data$playerId),
#           neg_log_lik = NA, aic = NA, bic = NA,
#           alpha = NA, temp = NA, envy = NA, guilt = NA,
#           converged = FALSE,
#           message = as.character(e),
#           stringsAsFactors = FALSE
#         )
#       })
#     })
#   }
#   
#   # Stop the cluster
#   stopCluster(cl)
#   
#   # Combine results
#   results_df <- do.call(rbind, results_list)
#   return(results_df)
# }

#' Fit model to data from multiple participants in parallel
#' 
#' @param data Dataframe with data from all participants
#' @param param_fixed List of parameters to fix (not estimate)
#' @param n_multistart Number of different starting points to try
#' @param n_cores Number of cores for parallel processing
#' @param verbose Whether to print progress information
#' @return Dataframe with fitting results for all participants
fit_all_participants_parallel <- function(data, 
                                         param_fixed = list(), 
                                         n_multistart = 10, 
                                         n_cores = parallel::detectCores() - 1,
                                         verbose = TRUE) {
  # Start timing
  start_time <- Sys.time()
  if (verbose) cat("Starting parallel fitting with", n_cores, "cores...\n")
  
  # Split data by participant
  participants <- split(data, data$playerId)
  n_participants <- length(participants)
  
  if (verbose) cat("Processing", n_participants, "participants...\n")
  
  # Set up parallel cluster
  cl <- parallel::makeCluster(n_cores)
  on.exit(parallel::stopCluster(cl))
  
  # Export necessary functions to cluster
  parallel::clusterExport(cl, varlist = c(
    "direct_learning_model", 
    "fit_direct_model_robust",
    "transform_bounded", 
    "inverse_bounded",
    "get_investment_bin", 
    "get_return_bin", 
    "calculate_fs_utility",
    "param_fixed", 
    "n_multistart",
    "randomLHS"
  ), envir = environment())
  
  # Load required libraries in each cluster node
  parallel::clusterEvalQ(cl, {
    library(tidyverse)
    library(optimx)
    library(lhs)
  })
  
  # Function to process one participant
  process_participant <- function(p_data) {
    tryCatch({
      # Get participant ID
      p_id <- unique(p_data$playerId)
      
      # Fit model
      fit_result <- fit_direct_model_robust(
        p_data, 
        param_fixed = param_fixed, 
        n_multistart = n_multistart,
        verbose = FALSE  # Must be FALSE in workers
      )
      
      # Format results
      data.frame(
        playerId = p_id,
        neg_log_lik = fit_result$neg_log_lik,
        aic = fit_result$aic,
        bic = fit_result$bic,
        alpha = ifelse(is.null(fit_result$params$alpha), NA, fit_result$params$alpha),
        temp = ifelse(is.null(fit_result$params$temp), NA, fit_result$params$temp),
        envy = ifelse(is.null(fit_result$params$envy), NA, fit_result$params$envy),
        guilt = ifelse(is.null(fit_result$params$guilt), NA, fit_result$params$guilt),
        converged = !is.null(fit_result$converged) && fit_result$converged,
        message = ifelse(is.null(fit_result$message), "Error", fit_result$message),
        stringsAsFactors = FALSE
      )
    }, error = function(e) {
      # Return error information
      data.frame(
        playerId = unique(p_data$playerId),
        neg_log_lik = NA, aic = NA, bic = NA,
        alpha = NA, temp = NA, envy = NA, guilt = NA,
        converged = FALSE,
        message = as.character(e),
        stringsAsFactors = FALSE
      )
    })
  }
  
  # Run parallel fitting with progress tracking
  if (requireNamespace("pbapply", quietly = TRUE) && verbose) {
    results_list <- pbapply::pblapply(participants, process_participant, cl = cl)
  } else {
    results_list <- parallel::parLapply(cl, participants, process_participant)
  }
  
  # Combine results
  results_df <- do.call(rbind, results_list)
  
  # Calculate success rate
  success_rate <- mean(results_df$converged, na.rm = TRUE) * 100
  
  # Calculate total runtime
  end_time <- Sys.time()
  total_duration <- as.numeric(difftime(end_time, start_time, units = "secs"))
  
  if (verbose) {
    cat("\nFitting complete!\n")
    cat("Total runtime:", 
        sprintf("%.1f minutes (%.1f hours)\n", 
                total_duration/60, total_duration/3600))
    cat("Success rate:", sprintf("%.1f%%\n", success_rate))
    
    # Report parameter statistics
    for (param in c("alpha", "temp", "envy", "guilt")) {
      if (param %in% names(param_fixed)) {
        cat(param, "was fixed at", param_fixed[[param]], "\n")
      } else {
        valid_values <- results_df[[param]][!is.na(results_df[[param]])]
        if (length(valid_values) > 0) {
          cat(param, "mean:", sprintf("%.3f", mean(valid_values)), 
              "SD:", sprintf("%.3f", sd(valid_values)), 
              "Range:", sprintf("[%.3f, %.3f]", min(valid_values), max(valid_values)), 
              "\n")
        } else {
          cat(param, ": No valid estimates\n")
        }
      }
    }
  }
  
  # Add timing information
  attr(results_df, "timing") <- list(
    start_time = start_time,
    end_time = end_time,
    total_seconds = total_duration
  )
  
  return(results_df)
}

#fit_all_participants_parallel(test_data2)
```

# 8. Out-of-Sample Testing

These functions implement out-of-sample testing to validate model fits

```{r out_of_sample}
#' Simulate RL model's predictions for a single game
#' 
#' @param game_data Dataframe with observed game data
#' @param params Model parameters
#' @param Q_init Initial Q-values (optional)
#' @return List with negative log likelihood, Q-values, and predictions
simulate_model_game <- function(game_data, params, Q_init = NULL) {
  # Extract parameters
  if (is.list(params)) {
    alpha <- params$alpha
    temp <- params$temp
    envy <- params$envy
    guilt <- params$guilt
  } else {
    alpha <- params[1]
    temp <- params[2]
    envy <- params[3]
    guilt <- params[4]
  }
  
  # Constants
  gamma <- 1
  n_actions <- 6
  
  # Initialize
  n_trials <- nrow(game_data)
  nll <- 0
  predictions <- data.frame(
    round = integer(), 
    observed_bin = integer(),
    predicted_bin = integer(), 
    predicted_prob = numeric()
  )
  
  # Initialize Q-values
  if (is.null(Q_init)) {
    Q_values <- matrix(0, nrow = 3, ncol = n_actions)
  } else {
    Q_values <- Q_init
  }
  
  # Verify game_data has only one game
  current_game <- unique(game_data$gameNum.f)
  if (length(current_game) != 1) {
    stop("simulate_model_game: game_data must contain exactly one game")
  }
  
  # Process each trial
  for (t in seq_len(n_trials)) {
    investment <- game_data$investment[t]
    actual_return <- game_data$return[t]
    
    # Skip invalid trials
    if (is.na(investment) || is.na(actual_return) || investment == 0) {
      next
    }
    
    # Get current state
    s_bin <- get_investment_bin(investment)
    
    # Calculate action probabilities using softmax
    Q_s <- Q_values[s_bin, ]
    shift <- Q_s - max(Q_s)  # For numerical stability
    probs <- exp(shift / temp)
    probs <- pmax(probs, 1e-12)  # Avoid zero probabilities
    probs <- probs / sum(probs)
    
    # Get actual action bin
    actual_prop <- actual_return / (3 * investment)
    observed_bin <- get_return_bin(actual_prop)
    
    # Get predicted action bin
    predicted_bin <- which.max(probs)
    
    # Store prediction
    predictions <- rbind(predictions, data.frame(
      round = t,
      observed_bin = observed_bin,
      predicted_bin = predicted_bin,
      predicted_prob = probs[observed_bin]
    ))
    
    # Update negative log likelihood
    nll <- nll - log(probs[observed_bin])
    
    # Calculate reward
    trustee_payoff <- 3 * investment - actual_return
    investor_payoff <- actual_return - investment
    reward <- calculate_fs_utility(trustee_payoff, investor_payoff, envy, guilt)
    
    # Calculate future value for TD learning
    if (t < n_trials) {
      next_invest <- game_data$investment[t + 1]
      if (!is.na(next_invest) && next_invest > 0) {
        next_s_bin <- get_investment_bin(next_invest)
        future_val <- max(Q_values[next_s_bin, ])
      } else {
        future_val <- 0
      }
    } else {
      future_val <- 0
    }
    
    # TD learning update
    pe <- reward + gamma * future_val - Q_values[s_bin, observed_bin]
    Q_values[s_bin, observed_bin] <- Q_values[s_bin, observed_bin] + alpha * pe
  }
  
  # Return results
  list(nll = nll, Q_values = Q_values, predictions = predictions)
}

#' Get final Q-values from training data
#' 
#' @param training_data Dataframe with training data
#' @param params Model parameters
#' @return List of Q-values for each game
get_training_Q_values <- function(training_data, params) {
  # Get unique games
  games <- unique(training_data$gameNum.f)
  Q_list <- list()
  
  # Process each game
  for (g in games) {
    # Get data for this game
    game_data <- training_data %>% filter(gameNum.f == g)
    
    # Simulate game to get final Q-values
    sim_result <- simulate_model_game(game_data, params)
    Q_list[[g]] <- sim_result$Q_values
  }
  
  return(Q_list)
}

#' Test model on held-out data
#' 
#' @param test_data Dataframe with test data
#' @param params Model parameters
#' @param training_Q_list List of Q-values from training
#' @return List with test results
test_model <- function(test_data, params, training_Q_list) {
  # Get unique games
  games <- unique(test_data$gameNum.f)
  total_nll <- 0
  details <- list()
  
  # Process each game
  for (g in games) {
    # Get data for this game
    game_data <- test_data %>% filter(gameNum.f == g)
    
    # Check if we have training Q-values for this game
    if (is.null(training_Q_list[[g]])) {
      warning(paste("No training Q-values found for game", g))
      next
    }
    
    # Get initial Q-values from training
    Q_init <- training_Q_list[[g]]
    
    # Test model on this game
    sim_result <- simulate_model_game(game_data, params, Q_init = Q_init)
    total_nll <- total_nll + sim_result$nll
    details[[g]] <- sim_result
  }
  
  # Return results
  list(total_nll = total_nll, details = details)
}

#' Fit model on training data and test on held-out data
#' 
#' @param participant_data Dataframe with participant data
#' @param param_fixed List of parameters to fix (not estimate)
#' @param n_multistart Number of different starting points to try
#' @param train_cutoff Round number to split training/test data
#' @return List with fitting and testing results
fit_and_test_participant <- function(participant_data,
                                   param_fixed = list(),
                                   n_multistart = 10,
                                   train_cutoff = 20) {
  # Create round numbers if not present
  if (!"roundNum" %in% names(participant_data)) {
    participant_data <- participant_data %>%
      group_by(gameNum.f, playerId) %>%
      mutate(roundNum = row_number()) %>%
      ungroup()
  }
  
  # Split data into training and test sets
  training_data <- participant_data %>% filter(roundNum <= train_cutoff)
  test_data <- participant_data %>% filter(roundNum > train_cutoff)
  
  # Fit model on training data
  fit_result <- fit_direct_model_robust(
    training_data, 
    param_fixed = param_fixed, 
    n_multistart = n_multistart
  )
  
  # Check if fitting succeeded
  if (!fit_result$converged) {
    return(list(
      playerId = unique(participant_data$playerId),
      fit_error = "Fitting failed",
      test_nll = NA,
      bin_accuracy = NA,
      parameters = NA,
      training_fit_nll = NA
    ))
  }
  
  # Extract fitted parameters
  params <- fit_result$params
  
  # Get Q-values from training
  training_Q_list <- get_training_Q_values(training_data, params)
  
  # Test model on held-out data
  test_result <- test_model(test_data, params, training_Q_list)
  
  # Calculate action bin prediction accuracy
  all_predictions <- do.call(rbind, lapply(test_result$details, function(x) x$predictions))
  if (!is.null(all_predictions) && nrow(all_predictions) > 0) {
    bin_accuracy <- mean(all_predictions$observed_bin == all_predictions$predicted_bin)
  } else {
    bin_accuracy <- NA
  }
  
  # Return results
  list(
    playerId = unique(participant_data$playerId),
    fit_error = NA,
    test_nll = test_result$total_nll,
    bin_accuracy = bin_accuracy,
    parameters = params,
    training_fit_nll = fit_result$neg_log_lik
  )
}

#' Fit and test all participants in parallel
#' 
#' @param full_data Dataframe with data from all participants
#' @param param_fixed List of parameters to fix (not estimate)
#' @param n_multistart Number of different starting points to try
#' @param n_cores Number of CPU cores to use for parallel processing
#' @param train_cutoff Round number to split training/test data
#' @return Dataframe with fitting and testing results for all participants
fit_and_test_all_participants <- function(full_data,
                                        param_fixed = list(),
                                        n_multistart = 10,
                                        n_cores = 8,
                                        train_cutoff = 20) {
  # Create round numbers if not present
  if (!"roundNum" %in% names(full_data)) {
    full_data <- full_data %>%
      group_by(gameNum.f, playerId) %>%
      mutate(roundNum = row_number()) %>%
      ungroup()
  }
  
  # Split data by participant
  participants <- split(full_data, full_data$playerId)
  
  # Set up parallel cluster
  cl <- makeCluster(n_cores)
  
  # Export necessary functions to cluster
  clusterExport(cl, varlist = c(
    "direct_learning_model", "fit_direct_model_robust",
    "transform_bounded", "inverse_bounded",
    "simulate_model_game", "get_training_Q_values", "test_model",
    "fit_and_test_participant",
    "get_investment_bin", "get_return_bin", "calculate_fs_utility",
    "param_fixed", "n_multistart", "train_cutoff",
    "randomLHS"
  ), envir = environment())
  
  # Load required libraries in each cluster node
  clusterEvalQ(cl, {
    library(tidyverse)
    library(optimx)
    library(lhs)
  })
  
  # Fit and test each participant in parallel
  if (requireNamespace("pbapply", quietly = TRUE)) {
    results_list <- pbapply::pblapply(participants, function(p_data) {
      tryCatch({
        fit_and_test_participant(
          p_data,
          param_fixed = param_fixed,
          n_multistart = n_multistart,
          train_cutoff = train_cutoff
        )
      }, error = function(e) {
        list(
          playerId = unique(p_data$playerId),
          fit_error = as.character(e),
          test_nll = NA,
          bin_accuracy = NA,
          parameters = NA,
          training_fit_nll = NA
        )
      })
    }, cl = cl)
  } else {
    results_list <- parLapplyLB(cl, participants, function(p_data) {
      tryCatch({
        fit_and_test_participant(
          p_data,
          param_fixed = param_fixed,
          n_multistart = n_multistart,
          train_cutoff = train_cutoff
        )
      }, error = function(e) {
        list(
          playerId = unique(p_data$playerId),
          fit_error = as.character(e),
          test_nll = NA,
          bin_accuracy = NA,
          parameters = NA,
          training_fit_nll = NA
        )
      })
    })
  }
  
  # Stop the cluster
  stopCluster(cl)
  
  # Combine results
  results_df <- do.call(rbind, lapply(results_list, function(res) {
    data.frame(
      playerId = res$playerId,
      fit_error = ifelse(is.null(res$fit_error), NA, res$fit_error),
      test_nll = res$test_nll,
      bin_accuracy = res$bin_accuracy,
      training_fit_nll = res$training_fit_nll,
      alpha = ifelse(is.null(res$parameters$alpha), NA, res$parameters$alpha),
      temp = ifelse(is.null(res$parameters$temp), NA, res$parameters$temp),
      envy = ifelse(is.null(res$parameters$envy), NA, res$parameters$envy),
      guilt = ifelse(is.null(res$parameters$guilt), NA, res$parameters$guilt),
      stringsAsFactors = FALSE
    )
  }))
  
  return(results_df)
}
```

# 9. Parameter Recovery Testing

These functions test if the model parameters can be reliably recovered from simulated data. This is a critical diagnostic tool for assessing parameter identifiability.

```{r parameter_recovery}
#' Test parameter recovery with simulated data (Parallel Version)
#' 
#' @param n_sims Number of simulations to run
#' @param game_size Number of rounds per game
#' @param param_fixed List of parameters to fix (not estimate)
#' @param param_ranges List of parameter ranges to sample from
#' @param n_multistart Number of different starting points to try
#' @param n_cores Number of cores to use for parallel processing
#' @param verbose Whether to print detailed progress information
#' @param progress_callback Function to call to update progress
#' @return List with parameter recovery results
param_recovery_experiment <- function(n_sims=100, game_size=25, 
                                             param_fixed=list(), 
                                             param_ranges=NULL,
                                             n_multistart=10,
                                             n_cores=parallel::detectCores()-1,
                                             verbose=FALSE,
                                             progress_callback=NULL) {
  # Set up parameter ranges if not provided
  if (is.null(param_ranges)) {
    param_ranges <- list(
      alpha = seq(0.05, 0.9, length.out=5),
      temp = c(0.5, 1, 2, 4),
      envy = c(0.2, 1, 2),
      guilt = c(0.2, 0.5, 1)
    )
  }
  
  # Create a grid of parameters, respecting fixed parameters
  grid_data <- list()
  for (param in c("alpha", "temp", "envy", "guilt")) {
    if (!is.null(param_fixed[[param]])) {
      grid_data[[param]] <- param_fixed[[param]]
    } else {
      grid_data[[param]] <- param_ranges[[param]]
    }
  }
  
  param_grid <- expand.grid(grid_data)
  
  # Limit to n_sims combinations if needed
  if (nrow(param_grid) > n_sims) {
    param_grid <- param_grid[sample(nrow(param_grid), n_sims), ]
  }
  
  # Setup parallel cluster
  cl <- parallel::makeCluster(n_cores)
  
  on.exit(parallel::stopCluster(cl))
  
  # Export necessary functions and objects to all workers
  parallel::clusterExport(cl, varlist = c(
    "simulate_2games_data_mf_hmm", 
    "fit_direct_model_robust",
    "direct_learning_model",
    "transform_bounded",
    "inverse_bounded",
    "get_investment_bin",
    "get_return_bin",
    "calculate_fs_utility",
    "state_to_bin",
    "bin_to_investment",
    "bin_to_return_prop",
    "updateState",
    "updateState_vol",
    "param_fixed",
    "n_multistart",
    "randomLHS",
    "game_size"
  ), envir = environment())
  
  # Load required libraries on all workers
  parallel::clusterEvalQ(cl, {
    library(tidyverse)
    library(optimx)
    library(lhs)
  })
  
  # Create a function to process a single simulation
  process_sim <- function(i, param_grid, param_fixed, game_size, n_multistart, verbose) {
    # Extract parameters for this simulation
    params_true <- list(
      alpha = param_grid$alpha[i],
      temp = param_grid$temp[i],
      envy = param_grid$envy[i],
      guilt = param_grid$guilt[i]
    )
    
    # Override with fixed parameters just to be sure
    for (param in names(param_fixed)) {
      params_true[[param]] <- param_fixed[[param]]
    }
    
    # Simulate data
    set.seed(i)  # For reproducibility
    sim_data <- simulate_2games_data_mf_hmm(params_true, game_size=game_size, playerId=i)
    
    # Fit model
    fit_result <- tryCatch({
      fit_direct_model_robust(
        sim_data, 
        param_fixed=param_fixed,
        n_multistart=n_multistart,
        verbose=FALSE  # Always set verbose to FALSE in parallel mode
      )
    }, error = function(e) {
      list(params=NULL, converged=FALSE, message=as.character(e))
    })
    
    # Return the results
    list(
      sim_id = i,
      true_params = params_true,
      fit_result = fit_result,
      # Don't return full sim_data to save memory
      sim_summary = list(
        n_rounds = nrow(sim_data),
        avg_investment = mean(sim_data$investment, na.rm=TRUE),
        avg_return = mean(sim_data$return, na.rm=TRUE)
      )
    )
  }
  
  # Run simulations in parallel with progress tracking
  if (requireNamespace("pbapply", quietly = TRUE) && verbose) {
    results <- pbapply::pblapply(1:nrow(param_grid), function(i) {
      process_sim(i, param_grid, param_fixed, game_size, n_multistart, FALSE)
    }, cl = cl)
  } else {
    results <- parallel::parLapply(cl, 1:nrow(param_grid), function(i) {
      process_sim(i, param_grid, param_fixed, game_size, n_multistart, FALSE)
    })
  }
  
  # Compile all results into a dataframe
  summary_df <- do.call(rbind, lapply(results, function(r) {
    if (is.null(r$fit_result$params) || any(is.na(r$fit_result$params))) {
      data.frame(
        sim_id = r$sim_id,
        true_alpha = r$true_params$alpha,
        fit_alpha = NA,
        alpha_error = NA,
        true_temp = r$true_params$temp,
        fit_temp = NA,
        temp_error = NA,
        true_envy = r$true_params$envy,
        fit_envy = NA,
        envy_error = NA,
        true_guilt = r$true_params$guilt,
        fit_guilt = NA,
        guilt_error = NA,
        neg_log_lik = NA,
        converged = FALSE,
        stringsAsFactors = FALSE
      )
    } else {
      data.frame(
        sim_id = r$sim_id,
        true_alpha = r$true_params$alpha,
        fit_alpha = r$fit_result$params$alpha,
        alpha_error = abs(r$true_params$alpha - r$fit_result$params$alpha),
        true_temp = r$true_params$temp,
        fit_temp = r$fit_result$params$temp,
        temp_error = abs(r$true_params$temp - r$fit_result$params$temp),
        true_envy = r$true_params$envy,
        fit_envy = r$fit_result$params$envy,
        envy_error = abs(r$true_params$envy - r$fit_result$params$envy),
        true_guilt = r$true_params$guilt,
        fit_guilt = r$fit_result$params$guilt,
        guilt_error = abs(r$true_params$guilt - r$fit_result$params$guilt),
        neg_log_lik = r$fit_result$neg_log_lik,
        converged = TRUE,
        stringsAsFactors = FALSE
      )
    }
  }))
  
  # Calculate summary statistics (same as before)
  # [rest of the function remains the same]
  
  all_params <- c("alpha", "temp", "envy", "guilt")
  free_params <- all_params[!all_params %in% names(param_fixed)]
  
  # Calculate correlations for free parameters
  correlations <- lapply(free_params, function(param) {
    true_col <- paste0("true_", param)
    fit_col <- paste0("fit_", param)
    values <- summary_df[, c(true_col, fit_col)]
    
    # Need enough non-NA pairs for correlation
    valid_pairs <- sum(!is.na(values[,1]) & !is.na(values[,2]))
    if (valid_pairs < 3) {
      return(NA)
    }
    
    cor(values[,1], values[,2], use="complete.obs")
  })
  names(correlations) <- free_params
  
  # Calculate mean errors for free parameters
  mean_errors <- lapply(free_params, function(param) {
    err_col <- paste0(param, "_error")
    mean(summary_df[[err_col]], na.rm=TRUE)
  })
  names(mean_errors) <- free_params
  
  # Calculate success rate
  success_rate <- mean(!is.na(summary_df$neg_log_lik))
  
  # Return complete results
  list(
    results = results,  # Contains individual simulation results
    summary_df = summary_df,
    correlations = correlations,
    mean_errors = mean_errors,
    success_rate = success_rate
  )
}


########################################
plot_recovery_results <- function(recovery_results, 
                                      output_dir = "recovery_plots",
                                      base_filename = "recovery",
                                      display = FALSE) {
  library(ggplot2)
  
  # Create output directory if it doesn't exist
  if (!dir.exists(output_dir)) {
    dir.create(output_dir, recursive = TRUE)
  }
  
  # Extract data
  all_params <- c("alpha", "temp", "envy", "guilt")
  df <- recovery_results$summary_df
  
  # Store file paths for saved plots
  saved_files <- list()
  
  # Create and save individual plots first (safer than combined grid)
  for (param in all_params) {
    true_col <- paste0("true_", param)
    fit_col <- paste0("fit_", param)
    
    # Skip if parameter was fixed
    if (!(true_col %in% colnames(df)) || !(fit_col %in% colnames(df))) {
      # Create a simple "fixed parameter" plot
      p <- ggplot() + 
        annotate("text", x = 0.5, y = 0.5, label = "Parameter was fixed") +
        theme_minimal() +
        labs(title = paste(param, "(Fixed)"))
    } else {
      # Extract data
      plot_df <- data.frame(
        true_val = df[[true_col]],
        fit_val = df[[fit_col]]
      )
      
      # Remove NAs
      plot_df <- plot_df[complete.cases(plot_df),]
      
      if (nrow(plot_df) < 3) {
        # Create "not enough data" plot
        p <- ggplot() + 
          annotate("text", x = 0.5, y = 0.5, label = "Not enough data") +
          theme_minimal() +
          labs(title = paste(param, "(Not enough data)"))
      } else {
        # Calculate correlation
        r <- cor(plot_df$true_val, plot_df$fit_val)
        
        # Create normal recovery plot
        p <- ggplot(plot_df, aes(x = true_val, y = fit_val)) +
          geom_point(color = "blue", alpha = 0.5) +
          geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
          geom_smooth(method = "lm", se = TRUE, color = "blue") +
          labs(
            title = param,
            x = paste("True", param),
            y = paste("Estimated", param)
          ) +
          annotate("text", 
                  x = min(plot_df$true_val), 
                  y = max(plot_df$fit_val),
                  label = paste("r =", round(r, 2)),
                  hjust = 0, vjust = 1) +
          theme_minimal()
      }
    }
    
    # Save individual plot to file
    filename <- file.path(output_dir, paste0(base_filename, "_", param, ".png"))
    ggsave(filename, p, width = 6, height = 5, dpi = 100)
    saved_files[[param]] <- filename
    
    # Force garbage collection
    rm(p)
    gc()
  }
  
  # Try to create a combined plot file if requested
  if (display) {
    tryCatch({
      # Load individual plots
      plot_list <- list()
      for (param in all_params) {
        # Skip if no file was saved for this parameter
        if (!param %in% names(saved_files)) next
        
        # Load the plot from file
        filename <- saved_files[[param]]
        
        # Create placeholder in list
        if (!(true_col %in% colnames(df)) || !(fit_col %in% colnames(df))) {
          plot_list[[param]] <- ggplot() + 
            annotate("text", x = 0.5, y = 0.5, label = "Parameter was fixed") +
            theme_minimal() +
            labs(title = paste(param, "(Fixed)"))
        } else {
          # Extract data
          plot_df <- data.frame(
            true_val = df[[true_col]],
            fit_val = df[[fit_col]]
          )
          
          # Remove NAs
          plot_df <- plot_df[complete.cases(plot_df),]
          
          if (nrow(plot_df) < 3) {
            plot_list[[param]] <- ggplot() + 
              annotate("text", x = 0.5, y = 0.5, label = "Not enough data") +
              theme_minimal() +
              labs(title = paste(param, "(Not enough data)"))
          } else {
            # Calculate correlation
            r <- cor(plot_df$true_val, plot_df$fit_val)
            
            # Create plot
            plot_list[[param]] <- ggplot(plot_df, aes(x = true_val, y = fit_val)) +
              geom_point(color = "blue", alpha = 0.5) +
              geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
              geom_smooth(method = "lm", se = TRUE, color = "blue") +
              labs(
                title = param,
                x = paste("True", param),
                y = paste("Estimated", param)
              ) +
              annotate("text", 
                      x = min(plot_df$true_val), 
                      y = max(plot_df$fit_val),
                      label = paste("r =", round(r, 2)),
                      hjust = 0, vjust = 1) +
              theme_minimal()
          }
        }
      }
      
      # Save combined plot to file
      filename <- file.path(output_dir, paste0(base_filename, "_combined.png"))
      combined <- gridExtra::grid.arrange(grobs = plot_list, ncol = 2)
      ggsave(filename, combined, width = 12, height = 10, dpi = 100)
      saved_files[["combined"]] <- filename
    }, error = function(e) {
      message("Error creating combined plot: ", e$message)
      message("Individual plots were still saved successfully.")
    })
  }
  
  # Return the list of saved files
  return(saved_files)
}

######################################################
#' Run a full parameter recovery analysis with safe plotting
#' 
#' @param n_sims Number of simulations for initial test
#' @param game_size Number of rounds per game
#' @param verbose Whether to print detailed progress information
#' @param save_plots Whether to save plots to files
#' @param display_plots Whether to attempt displaying plots (may crash)
#' @param output_dir Directory for saved plots
#' @return List with analysis results
run_recovery_analysis <- function(n_sims = 10, 
                                     game_size = 25, 
                                     verbose = FALSE,
                                     save_plots = TRUE,
                                     display_plots = FALSE,
                                     output_dir = "recovery_plots") {
  # Track timing
  start_time <- Sys.time()
  
  # Run a pilot simulation to estimate time
  if (verbose) cat("Running pilot simulation to estimate total time...\n")
  pilot_start <- Sys.time()
  pilot_recovery <- param_recovery_experiment(
    n_sims = 1, 
    game_size = game_size,
    verbose = FALSE
  )
  pilot_end <- Sys.time()
  
  # Estimate total time
  pilot_duration <- as.numeric(difftime(pilot_end, pilot_start, units = "secs"))
  estimated_total <- pilot_duration * n_sims
  
  if (verbose) {
    cat("Estimated total time: ", 
        sprintf("%.1f minutes (%.1f hours)\n", 
                estimated_total/60, estimated_total/3600))
  }
  
  # Check if we should continue
  if (estimated_total > 3600 && interactive()) {
    response <- readline(prompt = paste0(
      "This analysis may take approximately ", 
      round(estimated_total/3600, 1), 
      " hours. Continue? (y/n): "))
    if (tolower(substr(response, 1, 1)) != "y") {
      cat("Analysis cancelled by user.\n")
      return(NULL)
    }
  }
  
  # Step 1: Run parameter recovery experiment with all parameters free
  if (verbose) cat("Running parameter recovery experiment with all parameters free...\n")
  
  # Track progress during long computations
  progress_tracker <- function(i, n_sims) {
    if (verbose && i %% max(1, floor(n_sims/10)) == 0) {
      elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
      estimated_remaining <- (elapsed / i) * (n_sims - i)
      cat(sprintf("[%d/%d] %.1f%% complete. Est. remaining: %.1f minutes\n", 
                  i, n_sims, 100*i/n_sims, estimated_remaining/60))
      
      # Report memory usage
      mem_used <- gc(reset = TRUE)
      cat(sprintf("Memory usage: %.2f MB\n", mem_used[2, 2]))
    }
  }
  
  # Main simulation
  all_free_recovery <- param_recovery_experiment(
    n_sims = n_sims, 
    game_size = game_size,
    verbose = verbose,
    progress_callback = progress_tracker
  )
  
  # Step 2: Analyze which parameters can be recovered reliably
  if (verbose) cat("Analyzing parameter identifiability...\n")
  
  # Calculate correlations between true and recovered parameters
  correlations <- all_free_recovery$correlations
  
  # Determine which parameters to fix based on recovery quality
  reliable_threshold <- 0.6  # Correlation threshold for reliable recovery
  
  params_to_fix <- c()
  suggested_values <- list()
  
  for (param in names(correlations)) {
    if (is.na(correlations[[param]]) || correlations[[param]] < reliable_threshold) {
      params_to_fix <- c(params_to_fix, param)
      
      # Suggest median value from literature or previous studies
      if (param == "envy") {
        suggested_values[[param]] <- 1.0  # Common value for envy
      } else if (param == "guilt") {
        suggested_values[[param]] <- 0.5  # Common value for guilt
      } else if (param == "alpha") {
        suggested_values[[param]] <- 0.3  # Common learning rate
      } else if (param == "temp") {
        suggested_values[[param]] <- 1.5  # Common temperature
      }
    }
  }
  
  # Step 3: Run recovery with poorly identified parameters fixed
  if (length(params_to_fix) > 0) {
    if (verbose) cat("Running parameter recovery with fixed parameters:", 
                    paste(params_to_fix, collapse=", "), "...\n")
    
    param_fixed <- list()
    for (param in params_to_fix) {
      param_fixed[[param]] <- suggested_values[[param]]
    }
    
    fixed_recovery <- param_recovery_experiment(
      n_sims = n_sims,
      game_size = game_size,
      param_fixed = param_fixed,
      verbose = verbose,
      progress_callback = progress_tracker
    )
  } else {
    if (verbose) cat("All parameters appear to be reliably recovered.\n")
    fixed_recovery <- NULL
  }
  
  # Step 4: Save or display plots
  if (save_plots) {
    if (verbose) cat("Saving recovery plots to files...\n")
    
    # Save plots for all free parameters
    plots_all_free <- plot_recovery_results(
      all_free_recovery,
      output_dir = output_dir,
      base_filename = "all_free",
      display = display_plots
    )
    
    # Save plots for fixed parameters if applicable
    if (!is.null(fixed_recovery)) {
      plots_fixed <- plot_recovery_results(
        fixed_recovery,
        output_dir = output_dir,
        base_filename = "fixed_params",
        display = display_plots
      )
    }
    
    if (verbose) {
      cat("Plots saved to directory:", normalizePath(output_dir), "\n")
    }
  }
  
  # Step 5: Generate recommendations
  if (verbose) {
    cat("\nParameter Recovery Analysis Results:\n")
    cat("------------------------------------\n")
    
    for (param in names(correlations)) {
      cat(param, ": ")
      
      if (is.na(correlations[[param]])) {
        cat("Insufficient data for correlation calculation\n")
      } else if (correlations[[param]] > 0.8) {
        cat("Excellent recovery (r=", round(correlations[[param]], 2), 
            "). Keep as free parameter.\n", sep="")
      } else if (correlations[[param]] > 0.6) {
        cat("Good recovery (r=", round(correlations[[param]], 2), 
            "). Can be kept as free parameter.\n", sep="")
      } else if (correlations[[param]] > 0.4) {
        cat("Moderate recovery (r=", round(correlations[[param]], 2), 
            "). Consider fixing or using informative priors.\n", sep="")
      } else {
        cat("Poor recovery (r=", round(correlations[[param]], 2), 
            "). Recommended to fix at literature value: ", 
            suggested_values[[param]], "\n", sep="")
      }
    }
  }
  
  # Force garbage collection
  gc(verbose = FALSE)
  
  # Calculate total runtime
  end_time <- Sys.time()
  total_duration <- as.numeric(difftime(end_time, start_time, units = "secs"))
  
  if (verbose) {
    cat("\nTotal runtime: ", 
        sprintf("%.1f minutes (%.1f hours)\n", 
                total_duration/60, total_duration/3600))
  }
  
  # Return all results
  list(
    all_free_recovery = all_free_recovery,
    fixed_recovery = fixed_recovery,
    params_to_fix = params_to_fix,
    suggested_values = suggested_values,
    runtime = list(
      start_time = start_time,
      end_time = end_time,
      total_seconds = total_duration
    )
  )
}

```

```{r parameter_recovery}
#' Plot parameter recovery results to files (no display)
#' 
#' @param recovery_results Results from param_recovery_experiment
#' @param output_dir Directory where to save plots
#' @param base_filename Base filename for plots
#' @param display Whether to display plots (risky) or just save to files
#' @return Named list of file paths for saved plots
plot_recovery_results_safe <- function(recovery_results, 
                                      output_dir = "recovery_plots",
                                      base_filename = "recovery",
                                      display = FALSE) {
  library(ggplot2)
  
  # Create output directory if it doesn't exist
  if (!dir.exists(output_dir)) {
    dir.create(output_dir, recursive = TRUE)
  }
  
  # Extract data
  all_params <- c("alpha", "temp", "envy", "guilt")
  df <- recovery_results$summary_df
  
  # Store file paths for saved plots
  saved_files <- list()
  
  # Create and save individual plots first (safer than combined grid)
  for (param in all_params) {
    true_col <- paste0("true_", param)
    fit_col <- paste0("fit_", param)
    
    # Skip if parameter was fixed
    if (!(true_col %in% colnames(df)) || !(fit_col %in% colnames(df))) {
      # Create a simple "fixed parameter" plot
      p <- ggplot() + 
        annotate("text", x = 0.5, y = 0.5, label = "Parameter was fixed") +
        theme_minimal() +
        labs(title = paste(param, "(Fixed)"))
    } else {
      # Extract data
      plot_df <- data.frame(
        true_val = df[[true_col]],
        fit_val = df[[fit_col]]
      )
      
      # Remove NAs
      plot_df <- plot_df[complete.cases(plot_df),]
      
      if (nrow(plot_df) < 3) {
        # Create "not enough data" plot
        p <- ggplot() + 
          annotate("text", x = 0.5, y = 0.5, label = "Not enough data") +
          theme_minimal() +
          labs(title = paste(param, "(Not enough data)"))
      } else {
        # Calculate correlation
        r <- cor(plot_df$true_val, plot_df$fit_val)
        
        # Create normal recovery plot
        p <- ggplot(plot_df, aes(x = true_val, y = fit_val)) +
          geom_point(color = "blue", alpha = 0.5) +
          geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
          geom_smooth(method = "lm", se = TRUE, color = "blue") +
          labs(
            title = param,
            x = paste("True", param),
            y = paste("Estimated", param)
          ) +
          annotate("text", 
                  x = min(plot_df$true_val), 
                  y = max(plot_df$fit_val),
                  label = paste("r =", round(r, 2)),
                  hjust = 0, vjust = 1) +
          theme_minimal()
      }
    }
    
    # Save individual plot to file
    filename <- file.path(output_dir, paste0(base_filename, "_", param, ".png"))
    ggsave(filename, p, width = 6, height = 5, dpi = 100)
    saved_files[[param]] <- filename
    
    # Force garbage collection
    rm(p)
    gc()
  }
  
  # Try to create a combined plot file if requested
  if (display) {
    tryCatch({
      # Load individual plots
      plot_list <- list()
      for (param in all_params) {
        # Skip if no file was saved for this parameter
        if (!param %in% names(saved_files)) next
        
        # Load the plot from file
        filename <- saved_files[[param]]
        
        # Create placeholder in list
        if (!(true_col %in% colnames(df)) || !(fit_col %in% colnames(df))) {
          plot_list[[param]] <- ggplot() + 
            annotate("text", x = 0.5, y = 0.5, label = "Parameter was fixed") +
            theme_minimal() +
            labs(title = paste(param, "(Fixed)"))
        } else {
          # Extract data
          plot_df <- data.frame(
            true_val = df[[true_col]],
            fit_val = df[[fit_col]]
          )
          
          # Remove NAs
          plot_df <- plot_df[complete.cases(plot_df),]
          
          if (nrow(plot_df) < 3) {
            plot_list[[param]] <- ggplot() + 
              annotate("text", x = 0.5, y = 0.5, label = "Not enough data") +
              theme_minimal() +
              labs(title = paste(param, "(Not enough data)"))
          } else {
            # Calculate correlation
            r <- cor(plot_df$true_val, plot_df$fit_val)
            
            # Create plot
            plot_list[[param]] <- ggplot(plot_df, aes(x = true_val, y = fit_val)) +
              geom_point(color = "blue", alpha = 0.5) +
              geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
              geom_smooth(method = "lm", se = TRUE, color = "blue") +
              labs(
                title = param,
                x = paste("True", param),
                y = paste("Estimated", param)
              ) +
              annotate("text", 
                      x = min(plot_df$true_val), 
                      y = max(plot_df$fit_val),
                      label = paste("r =", round(r, 2)),
                      hjust = 0, vjust = 1) +
              theme_minimal()
          }
        }
      }
      
      # Save combined plot to file
      filename <- file.path(output_dir, paste0(base_filename, "_combined.png"))
      combined <- gridExtra::grid.arrange(grobs = plot_list, ncol = 2)
      ggsave(filename, combined, width = 12, height = 10, dpi = 100)
      saved_files[["combined"]] <- filename
    }, error = function(e) {
      message("Error creating combined plot: ", e$message)
      message("Individual plots were still saved successfully.")
    })
  }
  
  # Return the list of saved files
  return(saved_files)
}

#' Parallelized parameter recovery experiment with progress tracking
#' 
#' @param n_sims Number of simulations to run
#' @param game_size Number of rounds per game
#' @param param_fixed List of parameters to fix (not estimate)
#' @param param_ranges List of parameter ranges to sample from
#' @param n_multistart Number of different starting points to try
#' @param n_cores Number of cores to use for parallel processing
#' @param verbose Whether to print detailed progress information
#' @param progress_callback Function to call to update progress
#' @return List with parameter recovery results
param_recovery_experiment_parallel <- function(n_sims=20, 
                                             game_size=25, 
                                             param_fixed=list(), 
                                             param_ranges=NULL,
                                             n_multistart=10,
                                             n_cores=parallel::detectCores() - 1,
                                             verbose=FALSE,
                                             progress_callback=NULL) {
  # Set up parameter ranges if not provided
  if (is.null(param_ranges)) {
    param_ranges <- list(
      alpha = seq(0.05, 0.9, length.out=5),
      temp = c(0.5, 1, 2, 4),
      envy = c(0.2, 1, 2),
      guilt = c(0.2, 0.5, 1)
    )
  }
  
  # Create a grid of parameters, respecting fixed parameters
  grid_data <- list()
  for (param in c("alpha", "temp", "envy", "guilt")) {
    if (!is.null(param_fixed[[param]])) {
      grid_data[[param]] <- param_fixed[[param]]
    } else {
      grid_data[[param]] <- param_ranges[[param]]
    }
  }
  
  param_grid <- expand.grid(grid_data)
  
  # Limit to n_sims combinations if needed
  if (nrow(param_grid) > n_sims) {
    param_grid <- param_grid[sample(nrow(param_grid), n_sims), ]
  }
  
  # Create a function to process one simulation
  process_simulation <- function(i, param_grid, param_fixed, game_size, n_multistart) {
    # Extract parameters for this simulation
    params_true <- list(
      alpha = param_grid$alpha[i],
      temp = param_grid$temp[i],
      envy = param_grid$envy[i],
      guilt = param_grid$guilt[i]
    )
    
    # Override with fixed parameters just to be sure
    for (param in names(param_fixed)) {
      params_true[[param]] <- param_fixed[[param]]
    }
    
    # Simulate data
    set.seed(i)  # For reproducibility
    sim_data <- simulate_2games_data_mf_hmm(params_true, game_size=game_size, playerId=i)
    
    # Fit model
    fit_result <- tryCatch({
      fit_direct_model_robust(
        sim_data, 
        param_fixed=param_fixed,
        n_multistart=n_multistart,
        verbose=FALSE  # Always set to FALSE in parallel workers
      )
    }, error = function(e) {
      return(list(params=NULL, converged=FALSE, message=as.character(e)))
    })
    
    # Return results
    list(
      sim_id = i,
      true_params = params_true,
      fit_result = fit_result,
      # Don't return full sim_data to save memory
      sim_summary = list(
        n_rounds = nrow(sim_data),
        avg_investment = mean(sim_data$investment, na.rm=TRUE),
        avg_return = mean(sim_data$return, na.rm=TRUE)
      )
    )
  }
  
  # Set up parallel cluster
  if (verbose) cat("Setting up parallel cluster with", n_cores, "cores...\n")
  cl <- parallel::makeCluster(n_cores)
  on.exit(parallel::stopCluster(cl))
  
  # Export necessary functions and objects to all workers
  parallel::clusterExport(cl, varlist = c(
    "simulate_2games_data_mf_hmm", 
    "fit_direct_model_robust",
    "direct_learning_model",
    "transform_bounded",
    "inverse_bounded",
    "get_investment_bin",
    "get_return_bin",
    "calculate_fs_utility",
    "state_to_bin",
    "bin_to_investment",
    "bin_to_return_prop",
    "updateState",
    "updateState_vol",
    "param_fixed",
    "n_multistart",
    "game_size"
  ), envir = environment())
  
  # Load required libraries on all workers
  parallel::clusterEvalQ(cl, {
    library(tidyverse)
    library(optimx)
    library(lhs)
  })
  
  # Run simulations in parallel
  if (verbose) cat("Running", n_sims, "simulations in parallel...\n")
  
  if (requireNamespace("pbapply", quietly = TRUE) && verbose) {
    results <- pbapply::pblapply(1:nrow(param_grid), function(i) {
      result <- process_simulation(i, param_grid, param_fixed, game_size, n_multistart)
      
      # Call progress callback if provided
      if (!is.null(progress_callback)) {
        progress_callback(i, nrow(param_grid))
      }
      
      return(result)
    }, cl = cl)
  } else {
    results <- parallel::parLapply(cl, 1:nrow(param_grid), function(i) {
      result <- process_simulation(i, param_grid, param_fixed, game_size, n_multistart)
      
      # In non-pbapply version, we can't easily call progress_callback
      # but we can at least print progress if verbose
      if (verbose) {
        cat("Completed simulation", i, "of", nrow(param_grid), "\n")
      }
      
      return(result)
    })
  }
  
  if (verbose) cat("All simulations completed. Processing results...\n")
  
  # Compile all results into a dataframe
  summary_df <- do.call(rbind, lapply(results, function(r) {
    if (is.null(r$fit_result$params) || any(is.na(r$fit_result$params))) {
      data.frame(
        sim_id = r$sim_id,
        true_alpha = r$true_params$alpha,
        fit_alpha = NA,
        alpha_error = NA,
        true_temp = r$true_params$temp,
        fit_temp = NA,
        temp_error = NA,
        true_envy = r$true_params$envy,
        fit_envy = NA,
        envy_error = NA,
        true_guilt = r$true_params$guilt,
        fit_guilt = NA,
        guilt_error = NA,
        neg_log_lik = NA,
        converged = FALSE,
        stringsAsFactors = FALSE
      )
    } else {
      data.frame(
        sim_id = r$sim_id,
        true_alpha = r$true_params$alpha,
        fit_alpha = r$fit_result$params$alpha,
        alpha_error = abs(r$true_params$alpha - r$fit_result$params$alpha),
        true_temp = r$true_params$temp,
        fit_temp = r$fit_result$params$temp,
        temp_error = abs(r$true_params$temp - r$fit_result$params$temp),
        true_envy = r$true_params$envy,
        fit_envy = r$fit_result$params$envy,
        envy_error = abs(r$true_params$envy - r$fit_result$params$envy),
        true_guilt = r$true_params$guilt,
        fit_guilt = r$fit_result$params$guilt,
        guilt_error = abs(r$true_params$guilt - r$fit_result$params$guilt),
        neg_log_lik = r$fit_result$neg_log_lik,
        converged = TRUE,
        stringsAsFactors = FALSE
      )
    }
  }))
  
  # Calculate summary statistics
  all_params <- c("alpha", "temp", "envy", "guilt")
  free_params <- all_params[!all_params %in% names(param_fixed)]
  
  # Calculate correlations for free parameters
  correlations <- lapply(free_params, function(param) {
    true_col <- paste0("true_", param)
    fit_col <- paste0("fit_", param)
    values <- summary_df[, c(true_col, fit_col)]
    
    # Need enough non-NA pairs for correlation
    valid_pairs <- sum(!is.na(values[,1]) & !is.na(values[,2]))
    if (valid_pairs < 3) {
      return(NA)
    }
    
    cor(values[,1], values[,2], use="complete.obs")
  })
  names(correlations) <- free_params
  
  # Calculate mean errors for free parameters
  mean_errors <- lapply(free_params, function(param) {
    err_col <- paste0(param, "_error")
    mean(summary_df[[err_col]], na.rm=TRUE)
  })
  names(mean_errors) <- free_params
  
  # Calculate success rate
  success_rate <- mean(!is.na(summary_df$neg_log_lik))
  
  if (verbose) {
    cat("Parameter recovery complete. Success rate:", 
        round(100 * success_rate), "%\n")
    
    cat("Parameter correlations (true vs. estimated):\n")
    for (param in names(correlations)) {
      cat("  ", param, ": r =", round(correlations[[param]], 3), "\n")
    }
  }
  
  # Return complete results
  list(
    full_results = results,
    summary_df = summary_df,
    correlations = correlations,
    mean_errors = mean_errors,
    success_rate = success_rate
  )
}

#' Run a full parameter recovery analysis with safe plotting and parallelization
#' 
#' @param n_sims Number of simulations for initial test
#' @param game_size Number of rounds per game
#' @param n_cores Number of cores to use for parallel processing
#' @param verbose Whether to print detailed progress information
#' @param save_plots Whether to save plots to files
#' @param display_plots Whether to attempt displaying plots (may crash)
#' @param output_dir Directory for saved plots
#' @return List with analysis results
run_recovery_analysis_safe <- function(n_sims = 100, 
                                     game_size = 25,
                                     n_cores = parallel::detectCores() - 1,
                                     verbose = TRUE,  # Changed default to TRUE for interactive use
                                     save_plots = TRUE,
                                     display_plots = TRUE, # Changed default to TRUE to show plots
                                     output_dir = "recovery_plots") {
  # Track timing
  start_time <- Sys.time()
  
  # Run a pilot simulation to estimate time
  if (verbose) cat("Running pilot simulation to estimate total time...\n")
  pilot_start <- Sys.time()
  
  # Use just 1 core for the pilot
  pilot_recovery <- param_recovery_experiment_parallel(
    n_sims = 1, 
    game_size = game_size,
    n_cores = 1,
    verbose = FALSE
  )
  
  pilot_end <- Sys.time()
  
  # Estimate total time (adjusted for parallelization)
  pilot_duration <- as.numeric(difftime(pilot_end, pilot_start, units = "secs"))
  # Rough estimate - parallelization won't scale linearly, but it's a start
  estimated_total <- (pilot_duration * n_sims) / n_cores  
  
  if (verbose) {
    cat("Estimated total time: ", 
        sprintf("%.1f minutes (%.1f hours)\n", 
                estimated_total/60, estimated_total/3600))
  }
  
  # Check if we should continue
  if (estimated_total > 3600 && interactive()) {
    response <- readline(prompt = paste0(
      "This analysis may take approximately ", 
      round(estimated_total/3600, 1), 
      " hours. Continue? (y/n): "))
    if (tolower(substr(response, 1, 1)) != "y") {
      cat("Analysis cancelled by user.\n")
      return(NULL)
    }
  }
  
  # Step 1: Run parameter recovery experiment with all parameters free
  if (verbose) cat("Running parameter recovery experiment with all parameters free...\n")
  
  # Progress tracker function for periodic updates
  last_update_time <- Sys.time()
  progress_tracker <- function(i, n_sims) {
    current_time <- Sys.time()
    # Only update every 30 seconds to avoid excessive printing
    if (as.numeric(difftime(current_time, last_update_time, units = "secs")) > 30) {
      elapsed <- as.numeric(difftime(current_time, start_time, units = "secs"))
      estimated_remaining <- (elapsed / i) * (n_sims - i)
      cat(sprintf("[%d/%d] %.1f%% complete. Est. remaining: %.1f minutes\n", 
                  i, n_sims, 100*i/n_sims, estimated_remaining/60))
      
      # Report memory usage
      mem_used <- gc(reset = TRUE)
      cat(sprintf("Memory usage: %.2f MB\n", mem_used[2, 2]))
      
      # Update last update time
      last_update_time <<- current_time
    }
  }
  
  # Main simulation with parallelization
  all_free_recovery <- param_recovery_experiment_parallel(
    n_sims = n_sims, 
    game_size = game_size,
    n_cores = n_cores,
    verbose = verbose,
    progress_callback = progress_tracker
  )
  
  # Step 2: Analyze and display parameter identifiability results
  if (verbose) {
    cat("\nParameter Recovery Analysis Results:\n")
    cat("------------------------------------\n")
    
    correlations <- all_free_recovery$correlations
    
    for (param in names(correlations)) {
      cat(param, ": ")
      
      if (is.na(correlations[[param]])) {
        cat("Insufficient data for correlation calculation\n")
      } else if (correlations[[param]] > 0.8) {
        cat("Excellent recovery (r=", round(correlations[[param]], 2), 
            "). Recommended: Keep as free parameter.\n", sep="")
      } else if (correlations[[param]] > 0.6) {
        cat("Good recovery (r=", round(correlations[[param]], 2), 
            "). Recommended: Keep as free parameter.\n", sep="")
      } else if (correlations[[param]] > 0.4) {
        cat("Moderate recovery (r=", round(correlations[[param]], 2), 
            "). Consider fixing or using informative priors.\n", sep="")
      } else {
        cat("Poor recovery (r=", round(correlations[[param]], 2), 
            "). Consider fixing this parameter.\n", sep="")
      }
    }
  }
  
  # Step 3: Save or display plots
  if (save_plots || display_plots) {
    if (verbose) cat("\nGenerating recovery plots for all free parameters...\n")
    
    # Save plots for all free parameters
    plots_all_free <- plot_recovery_results_safe(
      all_free_recovery,
      output_dir = output_dir,
      base_filename = "all_free",
      display = display_plots
    )
    
    if (save_plots && verbose) {
      cat("Plots saved to directory:", normalizePath(output_dir), "\n")
    }
  }
  
  # Step 4: Interactive determination of parameters to fix
  cat("\nBased on the plots and correlations, you can now choose which parameters to fix.\n")
  
  # Get suggested literature values for reference
  suggested_values <- list(
    envy = 1.0,        # Common value for envy
    guilt = 0.5,       # Common value for guilt
    alpha_Q = 0.3,     # Common learning rate
    temp = 1.5,        # Common temperature
    sensitivity = 0.2  # Common sensitivity value
  )
  
  # Ask which parameters to fix
  params_to_fix <- c()
  param_fixed <- list()
  
  cat("\nFor each parameter, enter 'y' to fix it or 'n' to keep it free.\n")
  
  for (param in names(all_free_recovery$correlations)) {
    # Check if the parameter exists in the suggested values
    suggestion_text <- ""
    if (param %in% names(suggested_values)) {
      suggestion_text <- paste0(" [Suggested value: ", suggested_values[[param]], "]")
    }
    
    fix_response <- readline(prompt = paste0("Fix parameter '", param, "'? (y/n): "))
    
    if (tolower(substr(fix_response, 1, 1)) == "y") {
      value_prompt <- paste0("Enter value to fix '", param, "' at", suggestion_text, ": ")
      value_input <- readline(prompt = value_prompt)
      
      # Validate numeric input
      value <- tryCatch({
        as.numeric(value_input)
      }, warning = function(w) {
        cat("Warning: Invalid number. Using suggested value instead.\n")
        return(suggested_values[[param]] %||% 0.5)  # Use suggested value or 0.5 as fallback
      }, error = function(e) {
        cat("Error: Invalid input. Using suggested value instead.\n")
        return(suggested_values[[param]] %||% 0.5)  # Use suggested value or 0.5 as fallback
      })
      
      params_to_fix <- c(params_to_fix, param)
      param_fixed[[param]] <- value
      cat("Parameter '", param, "' will be fixed at ", value, "\n", sep="")
    } else {
      cat("Parameter '", param, "' will remain free.\n", sep="")
    }
  }
  
  # Step 5: Run recovery with user-specified fixed parameters
  fixed_recovery <- NULL
  if (length(params_to_fix) > 0) {
    if (verbose) {
      cat("\nRunning parameter recovery with fixed parameters:\n")
      for (param in names(param_fixed)) {
        cat("  ", param, " = ", param_fixed[[param]], "\n", sep="")
      }
    }
    
    fixed_recovery <- param_recovery_experiment_parallel(
      n_sims = n_sims,
      game_size = game_size,
      param_fixed = param_fixed,
      n_cores = n_cores,
      verbose = verbose,
      progress_callback = progress_tracker
    )
    
    # Display and save plots for fixed parameters
    if (save_plots || display_plots) {
      if (verbose) cat("\nGenerating recovery plots with fixed parameters...\n")
      
      plots_fixed <- plot_recovery_results_safe(
        fixed_recovery,
        output_dir = output_dir,
        base_filename = "fixed_params",
        display = display_plots
      )
      
      if (save_plots && verbose) {
        cat("Plots saved to directory:", normalizePath(output_dir), "\n")
      }
    }
    
    # Display fixed parameter recovery results
    if (verbose && !is.null(fixed_recovery$correlations)) {
      cat("\nParameter Recovery Results with Fixed Parameters:\n")
      cat("-----------------------------------------------\n")
      
      for (param in names(fixed_recovery$correlations)) {
        cat(param, ": ")
        
        if (is.na(fixed_recovery$correlations[[param]])) {
          cat("Insufficient data for correlation calculation\n")
        } else if (fixed_recovery$correlations[[param]] > 0.8) {
          cat("Excellent recovery (r=", round(fixed_recovery$correlations[[param]], 2), 
              ")\n", sep="")
        } else if (fixed_recovery$correlations[[param]] > 0.6) {
          cat("Good recovery (r=", round(fixed_recovery$correlations[[param]], 2), 
              ")\n", sep="")
        } else if (fixed_recovery$correlations[[param]] > 0.4) {
          cat("Moderate recovery (r=", round(fixed_recovery$correlations[[param]], 2), 
              ")\n", sep="")
        } else {
          cat("Poor recovery (r=", round(fixed_recovery$correlations[[param]], 2), 
              ")\n", sep="")
        }
      }
    }
  } else {
    if (verbose) cat("\nNo parameters were fixed. Results based on all free parameters.\n")
  }
  
  # Force garbage collection
  gc(verbose = FALSE)
  
  # Calculate total runtime
  end_time <- Sys.time()
  total_duration <- as.numeric(difftime(end_time, start_time, units = "secs"))
  
  if (verbose) {
    cat("\nTotal runtime: ", 
        sprintf("%.1f minutes (%.1f hours)\n", 
                total_duration/60, total_duration/3600))
  }
  
  # Return all results
  list(
    all_free_recovery = all_free_recovery,
    fixed_recovery = fixed_recovery,
    params_to_fix = params_to_fix,
    param_fixed = param_fixed,
    runtime = list(
      start_time = start_time,
      end_time = end_time,
      total_seconds = total_duration
    )
  )
}

# Helper to handle NULL with a default value (similar to %||% in purrr)
`%||%` <- function(x, y) if (is.null(x)) y else x
```

# 10. Complete Analysis Pipeline

This function brings together all the tools to perform a complete analysis of model fit and parameter recovery.

```{r full_pipeline}
#' Run a complete model analysis pipeline
#' 
#' This function tests parameter recovery, fits the model to real data,
#' determines which parameters should be fixed vs. estimated, and
#' provides comprehensive diagnostics.
#' 
#' @param data Dataframe with observed game data
#' @param n_recovery Number of simulations for recovery testing
#' @param do_out_of_sample Whether to perform out-of-sample testing
#' @param train_rounds Number of rounds to use for training (if doing out-of-sample testing)
#' @param n_cores Number of CPU cores to use for parallel processing
#' @param verbose Whether to print detailed progress information
#' @return List with analysis results
run_full_analysis <- function(data, 
                            n_recovery=100, 
                            do_out_of_sample=TRUE,
                            train_rounds=20,
                            n_cores=8,
                            verbose=TRUE) {
  
  # Step 1: Test parameter recovery
  if (verbose) cat("Testing parameter recovery...\n")
  recovery_results <- run_recovery_analysis(
    n_sims=n_recovery, 
    game_size=max(data$roundNum, na.rm=TRUE),
    verbose=verbose
  )
  
  # Step 2: Determine which parameters to fix
  if (verbose) cat("\nDetermining which parameters to fix...\n")
  params_to_fix <- recovery_results$params_to_fix
  suggested_values <- recovery_results$suggested_values
  
  if (length(params_to_fix) > 0) {
    if (verbose) {
      cat("Based on recovery analysis, these parameters should be fixed:\n")
      for (param in params_to_fix) {
        cat("  ", param, "=", suggested_values[[param]], "\n")
      }
    }
    
    param_fixed <- suggested_values
  } else {
    if (verbose) cat("All parameters appear to be reliably recovered. No parameters need to be fixed.\n")
    param_fixed <- list()
  }
  
  # Step 3: Fit the model to the real data
  if (verbose) cat("\nFitting model to real data...\n")
  
  if (do_out_of_sample) {
    # Out-of-sample fitting and testing
    if (verbose) cat("Performing out-of-sample testing...\n")
    fit_results <- fit_and_test_all_participants(
      data,
      param_fixed=param_fixed,
      n_multistart=10,
      n_cores=n_cores,
      train_cutoff=train_rounds
    )
    
    if (verbose) {
      cat("\nOut-of-Sample Testing Results:\n")
      cat("-----------------------------\n")
      cat("Average bin prediction accuracy:", mean(fit_results$bin_accuracy, na.rm=TRUE), "\n")
      cat("Convergence rate:", mean(!is.na(fit_results$training_fit_nll)), "\n")
      
      # Print parameter summaries
      for (param in c("alpha", "temp", "envy", "guilt")) {
        if (param %in% names(param_fixed)) {
          cat(param, "was fixed at", param_fixed[[param]], "\n")
        } else {
          cat(param, "mean:", mean(fit_results[[param]], na.rm=TRUE), 
              "SD:", sd(fit_results[[param]], na.rm=TRUE), "\n")
        }
      }
    }
  } else {
    # Regular fitting without out-of-sample testing
    fit_results <- fit_all_participants_parallel(
      data,
      param_fixed=param_fixed,
      n_multistart=10,
      n_cores=n_cores
    )
    
    if (verbose) {
      cat("\nFitting Results:\n")
      cat("---------------\n")
      cat("Convergence rate:", mean(!is.na(fit_results$neg_log_lik)), "\n")
      
      # Print parameter summaries
      for (param in c("alpha", "temp", "envy", "guilt")) {
        if (param %in% names(param_fixed)) {
          cat(param, "was fixed at", param_fixed[[param]], "\n")
        } else {
          cat(param, "mean:", mean(fit_results[[param]], na.rm=TRUE), 
              "SD:", sd(fit_results[[param]], na.rm=TRUE), "\n")
        }
      }
    }
  }
  
  # Step 4: Save results
  results <- list(
    recovery_results = recovery_results,
    params_to_fix = params_to_fix,
    suggested_values = suggested_values,
    fit_results = fit_results,
    out_of_sample = do_out_of_sample
  )
  
  # Step 5: Generate plots
  if (verbose) cat("\nGenerating parameter distribution plots...\n")
  
  # Plot parameter distributions
  for (param in c("alpha", "temp", "envy", "guilt")) {
    if (!(param %in% names(param_fixed)) && param %in% names(fit_results)) {
      # Skip if all values are NA
      if (all(is.na(fit_results[[param]]))) next
      
      # Create histogram
      hist(fit_results[[param]], 
           main=paste("Distribution of", param), 
           xlab=param, 
           breaks=20,
           col="skyblue")
    }
  }
  
  return(results)
}
```

# Example Usage


```{r example, eval=FALSE}
# 1. Load your data
#data <- read.csv("final_data_anonym.csv")

# # 2. Check if we can recover parameters from simulated data
# recovery_test <- param_recovery_experiment(n_sims=100, game_size=25, verbose=FALSE)
# plot_recovery_results(recovery_test)
# 
# # 3. Based on recovery results, determine which parameters to fix
# # For example, if envy and guilt are poorly recovered, we might fix them:
# fixed_params <- list(envy=1.0, guilt=0.5)
# 
# # 4. Fit the model with fixed parameters (parallel)
# fit_result <- fit_all_participants_parallel(
#   data,
#   param_fixed=fixed_params,
#   n_multistart=10,
#   n_cores=4  # Adjust based on your computer
# )
# 
# # 5. Or perform out-of-sample testing
# oos_results <- fit_and_test_all_participants(
#   data,
#   param_fixed=fixed_params,
#   n_multistart=10,
#   n_cores=4,
#   train_cutoff=20  # Use first 20 rounds for training
# )
# 
# # 6. Or use the complete analysis pipeline
# full_results <- run_full_analysis(
#   data,
#   n_recovery=100,
#   do_out_of_sample=TRUE,
#   train_rounds=20,
#   n_cores=8,
#   verbose=TRUE
# )
# 
# 
# 
# 
# ######
# # 7. Save results
# write.csv(fit_result, "MFRL3_7_fit_results.csv", row.names=FALSE)

# 8. Visualize parameter distributions
# hist(fit_result$alpha, main="Distribution of Learning Rate", xlab="Alpha", breaks=20)
# hist(fit_result$temp, main="Distribution of Temperature", xlab="Temperature", breaks=20)
```

```{r}

# Run the recovery analysis with parallel processing and safe plotting
recovery_results <- run_recovery_analysis_safe(
  n_sims = 500,              # Number of simulations
  game_size = 25,           # Number of rounds per game
  n_cores = 8,              # Number of CPU cores to use (adjust as needed)
  verbose = TRUE,           # Print progress
  save_plots = TRUE,        # Save plots to files
  display_plots = FALSE,    # Don't try to display plots (safer)
  output_dir = "recovery_plots"  # Directory for saved plots
)


# Access correlations from the initial run (all parameters free)
initial_correlations <- recovery_results$all_free_recovery$correlations
print("Initial correlations (all parameters free):")
print(initial_correlations)

# Access correlations from the run with fixed parameters
fixed_correlations <- recovery_results$fixed_recovery$correlations
print("Correlations after fixing parameters:")
print(fixed_correlations)
```

```{r}
# 3. Based on recovery results, determine which parameters to fix
# For example, if envy and guilt are poorly recovered, we might fix them:
fixed_params <- list(temp=1.5, envy=1)

# 4. Fit the model with fixed parameters (parallel)
fit_result_MFRL_v37 <- fit_all_participants_parallel(
  final_data,
  param_fixed=fixed_params,
  n_multistart=10,
  verbose=TRUE
)

# Save the results
write.csv(fit_result_MFRL_v37 , "fit_result_MFRL_v37.csv", row.names = FALSE)

# View summary of fitted parameters
summary(fit_result_MFRL_v37[, c("alpha", "temp", "envy", "guilt")])

```

```{r}
# 5. Or perform out-of-sample testing
oos_results <- fit_and_test_all_participants(
  test_data2,
  param_fixed=fixed_params,
  n_multistart=10,
  n_cores=8,
  train_cutoff=20  # Use first 20 rounds for training
)

cat("\nOut-of-Sample Testing Results:\n")
cat("-----------------------------\n")
cat("Average bin prediction accuracy:", mean(oos_results$bin_accuracy, na.rm=TRUE), "\n")
cat("Convergence rate:", mean(!is.na(oos_results$training_fit_nll)), "\n")

# Print parameter summaries
for (param in c("alpha", "temp", "envy", "guilt")) {
  if (param %in% names(fixed_params)) {
    cat(param, "was fixed at", fixed_params[[param]], "\n")
  } else {
    cat(param, "mean:", mean(oos_results[[param]], na.rm=TRUE), 
        "SD:", sd(oos_results[[param]], na.rm=TRUE), "\n")
  }
}
```

```{r}
# Merge with payoff/opponent data
results_features_MFRL37 <- fit_result_MFRL_v37 %>%
  left_join(
    payoff_data_mean, 
    by = c( "playerId")
  )

library(ggplot2)
library(ggcorrplot)
library(GGally)


vars_of_interest_MFRL37 <- results_features_MFRL37 %>%
  dplyr::select(alpha, guilt, mean_payoff, cal_scaled, dec_scaled, sad_scaled, vin_scaled)

# Focus on key parameters (adjust as needed)
ggpairs(
  vars_of_interest_MFRL37,
  columns = c("alpha", "guilt", "mean_payoff", "cal_scaled","dec_scaled", "sad_scaled", "vin_scaled" ),
  title = "Pairwise Parameter Relationships"
)
```

```{r}
# Model alpha as a function of ( d_factor subscales and payoff, etc.)
mod_alpha_mfrl <- lm( alpha ~ cal_scaled + dec_scaled + sad_scaled + vin_scaled + mean_payoff, data = results_features_MFRL37)
summary(mod_alpha_mfrl)


# Model guilt 
mod_guilt_mfrl <- lm( guilt ~ cal_scaled + dec_scaled + sad_scaled + vin_scaled + mean_payoff, data = results_features_MFRL37)
summary(mod_guilt_mfrl)

```


# Conclusion

This R Markdown document provides a comprehensive toolbox for fitting and analyzing reinforcement learning models in trust game data. The key features are:

1. **Robust Parameter Estimation**: Multiple optimization methods and careful parameter transformations improve numerical stability and avoid boundary issues.

2. **Parameter Recovery Testing**: Methods to determine which parameters can be reliably recovered from the data.

3. **Parallel Processing**: Efficient parallel implementation for fitting models to multiple participants.

4. **Out-of-Sample Testing**: Cross-validation to test model generalization to unseen data.

5. **Diagnostic Tools**: Functions to analyze model fit and parameter identifiability.

The most common issue with RL model fitting is poor parameter recovery, particularly for social preference parameters like envy and guilt. The recommended workflow is:

1. First test parameter recovery with simulated data
2. Fix parameters that cannot be reliably recovered
3. Fit the model to real data with appropriate parameters fixed
4. Validate model fits using out-of-sample testing

This approach ensures that you only estimate parameters that are identifiable from your data, reducing overfitting and improving the interpretability of your results.