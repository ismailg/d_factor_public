---
title: "MFRL_param_analysis"
author: "Ismail Guennouni"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
###############################################################################
# 0) Libraries
###############################################################################
library(tidyverse)
library(optimx)
library(lhs)
library(parallel)
library(pbapply)

###############################################################################
# 1) Basic Helper Functions
###############################################################################
# ----- Discretization helpers for investment & return -----

get_investment_bin <- function(investment) {
  if (investment <= 7)   return(1)
  if (investment <= 14)  return(2)
  return(3)
}

get_return_bin <- function(return_prop) {
  if (return_prop < 0 || return_prop > 1) 
    stop("Return proportion must be between 0 and 1.")
  # 6 bins in [0,1]
  return(min(floor(return_prop * 6) + 1, 6))
}

# ----- Fehr–Schmidt utility function -----
calculate_fs_utility <- function(own_payoff, other_payoff, envy, guilt) {
  # Disadvantageous inequality:
  disadv <- max(other_payoff - own_payoff, 0)
  # Advantageous inequality:
  adv    <- max(own_payoff - other_payoff, 0)
  return( own_payoff - envy * disadv - guilt * adv )
}

# ----- Investor's HMM states + bin mapping -----
state_to_bin <- function(state) {
  if (state == "unhappy") return(1)
  if (state == "neutral") return(2)
  if (state == "happy")   return(3)
  stop("state_to_bin: unknown state")
}

bin_to_investment <- function(s_bin) {
  # 1 => invests 4, 2 => invests 11, 3 => invests 17
  if (s_bin == 1) return(4)
  if (s_bin == 2) return(11)
  if (s_bin == 3) return(17)
  stop("Invalid s_bin in bin_to_investment()")
}

bin_to_return_prop <- function(a_bin) {
  # midpoints of 6 equal bins in [0,1]: (2*a_bin - 1)/12
  return((2 * a_bin - 1) / 12)
}

###############################################################################
# 2) Investor's HMM Transition Functions
###############################################################################
# These update the investor's internal state based on the net payoff (PnL).

updateState <- function(state, PnL) {
  if (state == "unhappy") {
    mod <- c(
      exp( 0.0 + 0.0 * PnL),
      exp(-3.366027  + 0.40910797 * PnL),
      exp(-3.572619  - 0.08137274 * PnL)
    )
  } else if (state == "neutral") {
    mod <- c(
      exp(0.0 + 0.0 * PnL),
      exp(3.3142637  + 0.3763408  * PnL),
      exp(0.9169736  + 0.4502838  * PnL)
    )
  } else if (state == "happy") {
    mod <- c(
      exp(0.0 + 0.0 * PnL),
      exp(0.7134085  + 0.02101626 * PnL),
      exp(2.2215478  + 0.16162964 * PnL)
    )
  } else {
    stop("updateState: unknown current state.")
  }
  mod <- mod / sum(mod)
  new_states <- c("unhappy","neutral","happy")
  return(new_states[sample(seq_along(mod), 1, prob = mod)])
}

updateState_vol <- function(state, PnL) {
  if (state == "unhappy") {
    mod <- c(
      exp(0.0 + 0.0 * PnL),
      exp(-3.366027  + 0.40910797 * PnL),
      exp(-3.572619  - 0.08137274 * PnL)
    )
  } else if (state == "neutral") {
    # Example alternative transitions. You can customize.
    mod <- c(
      exp(0.0 + 0.0 * PnL),
      exp(1 + 0.27 * PnL),
      exp(-4 + 0.75 * PnL)
    )
  } else if (state == "happy") {
    mod <- c(
      exp(0.0 + 0.0 * PnL),
      exp(0.7134085  + 0.02101626 * PnL),
      exp(2.2215478  + 0.16162964 * PnL)
    )
  } else {
    stop("updateState_vol: unknown current state.")
  }
  mod <- mod / sum(mod)
  new_states <- c("unhappy","neutral","happy")
  return(new_states[sample(seq_along(mod), 1, prob = mod)])
}

###############################################################################
# 3) Simulation: Single-alpha, Single-temperature Q–Learning + Investor HMM
###############################################################################
# The investor's state transitions as provided. 
# The trustee has 4 parameters: alpha, temp, envy, guilt.
# We do 2 games of size `game_size`, each starting from 'neutral' investor state.

simulate_2games_data_mf_hmm <- function(params_trustee, game_size = 25, playerId = 1) {
  # params_trustee = c(alpha, temp, envy, guilt)
  if (length(params_trustee) != 4) {
    stop("simulate_2games_data_mf_hmm expects 4 trustee parameters: alpha, temp, envy, guilt")
  }
  alpha <- params_trustee[1]
  temp  <- params_trustee[2]
  envy  <- params_trustee[3]
  guilt <- params_trustee[4]
  
  total_rounds <- 2 * game_size
  
  df <- data.frame(
    trial      = 1:total_rounds,
    investment = rep(NA, total_rounds),
    return     = rep(NA, total_rounds),
    gameNum.f  = factor(rep("first game", total_rounds),
                        levels = c("first game", "second game"))
  )
  df$gameNum.f[(game_size + 1):total_rounds] <- "second game"
  
  # Start each game in the 'neutral' state for the investor
  current_state <- "neutral"
  
  # Trustee Q-values: 3 states x 6 actions
  Q <- matrix(0, nrow = 3, ncol = 6)
  gamma <- 1
  
  for (t in 1:total_rounds) {
    # Reinitialize Q and investor state at the start of game 2
    if (t == (game_size + 1)) {
      Q            <- matrix(0, nrow = 3, ncol = 6)
      current_state<- "neutral"
    }
    
    # 1) Investor invests based on their current state
    s_bin          <- state_to_bin(current_state)
    invest_amt     <- bin_to_investment(s_bin)
    df$investment[t] <- invest_amt
    
    # 2) Trustee chooses action from Q–learning's softmax
    Q_s       <- Q[s_bin, ]
    Q_shifted <- Q_s - max(Q_s)
    probs     <- exp(Q_shifted / temp)
    probs     <- pmax(probs, 1e-12)
    probs     <- probs / sum(probs)
    
    a_bin  <- sample(1:6, 1, prob = probs)
    ret_prop <- bin_to_return_prop(a_bin)
    ret_amt  <- round(ret_prop * (3 * invest_amt))
    df$return[t] <- ret_amt
    
    # 3) Trustee payoff and investor payoff
    trustee_payoff  <- 3 * invest_amt - ret_amt
    investor_payoff <- ret_amt - invest_amt
    
    # Fehr–Schmidt utility for trustee
    rew <- calculate_fs_utility(trustee_payoff, investor_payoff, envy, guilt)
    
    # 4) Q–update
    if (t < total_rounds) {
      # Next investor state depends on whether it's game1 or game2
      if (df$gameNum.f[t] == "first game") {
        updateFunc <- updateState
      } else {
        updateFunc <- updateState_vol
      }
      PnL <- investor_payoff  # (ret_amt - invest_amt)
      next_state   <- updateFunc(current_state, PnL)
      s_bin_next   <- state_to_bin(next_state)
      
      td_err <- rew + gamma * max(Q[s_bin_next, ]) - Q[s_bin, a_bin]
      Q[s_bin, a_bin] <- Q[s_bin, a_bin] + alpha * td_err
      
      current_state <- next_state
    } else {
      # final round
      td_err <- rew - Q[s_bin, a_bin]
      Q[s_bin, a_bin] <- Q[s_bin, a_bin] + alpha * td_err
    }
  }
  
  df$playerId <- playerId
  return(df)
}


###############################################################################
# 4) Single-Alpha / Single-Temp Q–Learning Model (Trustee)
###############################################################################
# We keep the structure from "direct_learning_model2" but unify alpha and temp.

direct_learning_model <- function(params_free, data, param_fixed = list()) {
  # param_fixed can have any of: alpha, temp, envy, guilt
  # if not NULL, that param is fixed; otherwise we read from params_free in order
  
  # 1) Reconstruct full parameter set: alpha, temp, envy, guilt
  all_names <- c("alpha","temp","envy","guilt")
  par_vals  <- numeric(length(all_names))
  
  idx_free <- 1
  for (i in seq_along(all_names)) {
    nm <- all_names[i]
    if (!is.null(param_fixed[[nm]])) {
      # fixed
      par_vals[i] <- param_fixed[[nm]]
    } else {
      # take next from params_free
      par_vals[i] <- params_free[idx_free]
      idx_free <- idx_free + 1
    }
  }
  alpha <- par_vals[1]
  temp  <- par_vals[2]
  envy  <- par_vals[3]
  guilt <- par_vals[4]
  
  gamma     <- 1
  n_actions <- 6
  Q_values  <- matrix(0, nrow=3, ncol=n_actions)
  
  n_trials  <- nrow(data)
  neg_log_lik <- 0
  
  # Track the current game
  current_game <- data$gameNum.f[1]
  
  for (t in seq_len(n_trials)) {
    invest_amt    <- data$investment[t]
    actual_return <- data$return[t]
    
    if (is.na(invest_amt) || is.na(actual_return) || invest_amt == 0) 
      next
    
    # Reset Q-values at the start of a new game
    if (t > 1 && data$gameNum.f[t] != current_game) {
      Q_values <- matrix(0, nrow=3, ncol=6)
      current_game <- data$gameNum.f[t]
    }
    
    # state bin
    s_bin <- get_investment_bin(invest_amt)
    
    # Trustee softmax
    Q_s    <- Q_values[s_bin,]
    shift  <- Q_s - max(Q_s)
    probs  <- exp(shift / temp)
    probs  <- pmax(probs, 1e-12)
    probs  <- probs / sum(probs)
    
    # chosen action is the actual bin
    actual_prop <- actual_return / (3 * invest_amt)
    chosen_bin  <- get_return_bin(actual_prop)
    
    neg_log_lik <- neg_log_lik - log(probs[chosen_bin])
    
    # payoff
    trustee_payoff  <- 3 * invest_amt - actual_return
    investor_payoff <- actual_return - invest_amt
    reward          <- calculate_fs_utility(trustee_payoff, investor_payoff, envy, guilt)
    
    # Next-state estimate
    if (t < n_trials) {
      next_invest <- data$investment[t + 1]
      if (!is.na(next_invest) && next_invest > 0) {
        next_s_bin <- get_investment_bin(next_invest)
        future_val <- max(Q_values[next_s_bin,])
      } else {
        future_val <- 0
      }
    } else {
      future_val <- 0
    }
    
    pe <- reward + gamma*future_val - Q_values[s_bin, chosen_bin]
    Q_values[s_bin, chosen_bin] <- Q_values[s_bin, chosen_bin] + alpha*pe
  }
  
  return(neg_log_lik)
}


```

```{r}

# For parameters needing both lower and upper bounds (envy/guilt)
transform_bounded <- function(x, lb, ub) {
  lb + (ub - lb) * (1/(1 + exp(-x))) # Logistic transform
}

inverse_bounded <- function(y, lb, ub) {
  -log((ub - lb)/(y - lb) - 1)
}

###############################################################################
# 5) Fitting a Single Participant with Some Fixed Parameters
###############################################################################
# Enhanced optimization with parameter transformation
fit_direct_model_single_improved <- function(participant_data,
                                   param_fixed = list(alpha=NULL, temp=NULL, envy=NULL, guilt=NULL),
                                   n_multistart = 10) {
  # For convenience, create roundNum if not present
  if (!"roundNum" %in% names(participant_data)) {
    participant_data <- participant_data %>%
      group_by(gameNum.f, playerId) %>%
      mutate(roundNum = row_number()) %>%
      ungroup()
  }
  
  # bounds for free parameters
  bounds_list <- list(
    alpha = c(0.0001, 0.9999),  # Avoid exact 0,1 boundaries
    temp  = c(0.01, 15),
    envy  = c(0, 5),
    guilt = c(0, 2)
  )
  
  all_names <- c("alpha", "temp", "envy", "guilt")
  
  # Identify which parameters are free
  free_names <- c()
  lower <- c()
  upper <- c()
  
  for (nm in all_names) {
    if (is.null(param_fixed[[nm]])) {
      free_names <- c(free_names, nm)
      lower <- c(lower, bounds_list[[nm]][1])
      upper <- c(upper, bounds_list[[nm]][2])
    }
  }
  
  # If all are fixed, just evaluate the negative LL with no optimization:
  if (length(free_names) == 0) {
    nll_val <- direct_learning_model(params_free=numeric(0),
                                   data=participant_data,
                                   param_fixed=param_fixed)
    return(list(params=param_fixed,
              neg_log_lik=nll_val,
              aic=NA, bic=NA,
              converged=TRUE,
              message="All parameters fixed; no optimization done."))
  }
  
  best_nll <- Inf
  best_par <- NULL
  
  # Parameter transformation function for optimization
  transform_params <- function(unconstrained_params) {
    constrained <- numeric(length(unconstrained_params))
    idx <- 1
    for (i in seq_along(free_names)) {
      nm <- free_names[i]
      if (nm == "alpha") {
        # Logit transformation for alpha in (0,1)
        constrained[i] <- 1/(1+exp(-unconstrained_params[i]))
      } else if (nm == "temp") {
        # Exp transformation for positive temp
        constrained[i] <- exp(unconstrained_params[i])
      } else if (nm == "envy") {
        constrained[i] <- transform_bounded(unconstrained_params[i], 0, 5)
      } else if (nm == "guilt") {
        constrained[i] <- transform_bounded(unconstrained_params[i], 0, 2)
      }
    }
    return(constrained)
  }

  # Inverse transformation to get unconstrained parameters
  inverse_transform <- function(constrained_params) {
    unconstrained <- numeric(length(constrained_params))
    for (i in seq_along(free_names)) {
      nm <- free_names[i]
      if (nm == "alpha") {
        # Inverse logit
        unconstrained[i] <- log(constrained_params[i]/(1-constrained_params[i]))
      } else if (nm == "temp") {
        # Log transformation
        unconstrained[i] <- log(constrained_params[i])
      } else if (nm == "envy") {
        unconstrained[i] <- inverse_bounded(constrained_params[i], 0, 5)
      } else if (nm == "guilt") {
        unconstrained[i] <- inverse_bounded(constrained_params[i], 0, 2)
      }
    }
    return(unconstrained)
  }
  
  
  # Wrapped objective function with transformation
  objective_transformed <- function(unconstrained_params) {
    constrained_params <- transform_params(unconstrained_params)
    return(direct_learning_model(constrained_params, participant_data, param_fixed))
  }
  
  # Enhanced initialization with LHS and theoretically expected values
  n_free <- length(free_names)
  lhs_samples <- randomLHS(n_multistart, n_free)
  
  # Add theoretical expectations to initialization
  init_list <- lapply(seq_len(n_multistart), function(i) {
    if (i == 1 && "alpha" %in% free_names && "temp" %in% free_names) {
      # First initialization based on theoretical expectations
      idx_alpha <- which(free_names == "alpha")
      idx_temp <- which(free_names == "temp")
      
      init <- lower + (upper - lower) * lhs_samples[i,]
      # Set alpha close to midpoint and temp relatively low
      init[idx_alpha] <- 0.3  # Common learning rate value
      init[idx_temp] <- 1.0   # Moderate exploration
      
      # Transform to unconstrained space
      return(inverse_transform(init))
    } else {
      # Other initializations from LHS
      init <- lower + (upper - lower) * lhs_samples[i,]
      return(inverse_transform(init))
    }
  })
  
  # Try multiple optimization approaches for each initialization
  for (init in init_list) {
    # First try simulated annealing for global search
    fit_global <- tryCatch({
      optim(par = init,
            fn = objective_transformed,
            method = "SANN",
            control = list(maxit = 2000, temp = 10, tmax = 10))
    }, error = function(e) NULL)
    
    if (is.null(fit_global)) next
    
    # Then refine with L-BFGS-B - no bounds needed due to transformation
    fit <- tryCatch({
      optimx(par = fit_global$par,
             fn = objective_transformed,
             method = "L-BFGS-B",
             control = list(maxit=1000, dowarn=FALSE))
    }, error = function(e) NULL)
    
    if (!is.null(fit)) {
      val <- fit$value[1]
      if (val < best_nll) {
        best_nll <- val
        best_par_transformed <- as.numeric(fit[1, 1:n_free])
        best_par <- transform_params(best_par_transformed)
      }
    }
  }
  
  if (is.null(best_par)) {
    return(list(params=NA, neg_log_lik=NA, aic=NA, bic=NA,
              converged=FALSE, message="Fitting failed."))
  }
  
  # Reconstruct the full param set
  final_par <- param_fixed
  idx <- 1
  for (nm in all_names) {
    if (is.null(final_par[[nm]])) {
      final_par[[nm]] <- best_par[idx]
      idx <- idx + 1
    }
  }
  
  # Compute AIC & BIC
  n_obs <- sum(!is.na(participant_data$investment) & participant_data$investment > 0)
  n_par <- length(free_names)
  aic <- 2*best_nll + 2*n_par
  bic <- 2*best_nll + log(n_obs)*n_par
  
  list(params = final_par,
     neg_log_lik = best_nll,
     aic = aic,
     bic = bic,
     converged = TRUE,
     message = "OK")
}


```

```{r}
fit_direct_model_single(test_data1,
                                    param_fixed = list(alpha=NULL, temp=NULL, envy=NULL, guilt=NULL),
                                    n_multistart = 5)
```


```{r}
fit_direct_model_single_improved(test_data1,
                                    param_fixed = list(alpha=NULL, temp=NULL, envy=NULL, guilt=NULL),
                                    n_multistart = 5)
```




```{r}
###############################################################################
# 6) Parallel Fitting for All Participants
###############################################################################
fit_all_participants_direct_model <- function(full_data,
                                              param_fixed = list(alpha=NULL, temp=NULL, envy=NULL, guilt=NULL),
                                              n_multistart = 5, n_cores = 8) {
  participants <- split(full_data, full_data$playerId)
  
  cl <- makeCluster(n_cores)
  
  # Export necessary functions/objects
  clusterExport(cl, varlist=c(
    "direct_learning_model", "fit_direct_model_single",
    "get_investment_bin", "get_return_bin", "calculate_fs_utility",
    "param_fixed",  # might want to pass it explicitly
    "randomLHS"     # from lhs package
  ), envir = environment())
  
  clusterEvalQ(cl, library(tidyverse))
  clusterEvalQ(cl, library(optimx))
  clusterEvalQ(cl, library(lhs))
  
  results_list <- parLapplyLB(cl, participants, function(p_data) {
    tryCatch({
      fit_res <- fit_direct_model_single(p_data, param_fixed=param_fixed, n_multistart=n_multistart)
      data.frame(
        playerId    = unique(p_data$playerId),
        neg_log_lik = fit_res$neg_log_lik,
        aic         = fit_res$aic,
        bic         = fit_res$bic,
        alpha       = ifelse(is.null(fit_res$params$alpha), NA, fit_res$params$alpha),
        temp        = ifelse(is.null(fit_res$params$temp),  NA, fit_res$params$temp),
        envy        = ifelse(is.null(fit_res$params$envy),  NA, fit_res$params$envy),
        guilt       = ifelse(is.null(fit_res$params$guilt), NA, fit_res$params$guilt),
        converged   = fit_res$converged,
        message     = fit_res$message,
        stringsAsFactors=FALSE
      )
    }, error = function(e) {
      data.frame(playerId   = unique(p_data$playerId),
                 neg_log_lik=NA, aic=NA, bic=NA,
                 alpha=NA, temp=NA, envy=NA, guilt=NA,
                 converged=FALSE, message=e$message,
                 stringsAsFactors=FALSE)
    })
  })
  stopCluster(cl)
  
  # Combine results
  results_df <- do.call(rbind, results_list)
  return(results_df)
}


```

```{r}
fit_all_participants_direct_model(test_data2,param_fixed = list(alpha=NULL, temp=NULL, envy=NULL, guilt=NULL),
                                              n_multistart = 5, n_cores = 8)
```




```{r}
###############################################################################
# 7) (Optional) Out-of–Sample Prediction
###############################################################################
# We adapt the prior OOS code to single alpha, single temp.

simulate_direct_model_game <- function(game_data, params, Q_init = NULL) {
  # params = c(alpha, temp, envy, guilt)
  alpha <- params[1]
  temp  <- params[2]
  envy  <- params[3]
  guilt <- params[4]
  gamma <- 1
  
  n_trials <- nrow(game_data)
  n_actions<- 6
  nll      <- 0
  
  # Keep track of predictions
  predictions <- data.frame(round=integer(), observed_bin=integer(), 
                            predicted_bin=integer(), predicted_prob=numeric())
  
  # Q init
  if (is.null(Q_init)) {
    Q_values <- matrix(0, nrow=3, ncol=n_actions)
  } else {
    Q_values <- Q_init
  }
  
  # Only one game in game_data
  current_game <- unique(game_data$gameNum.f)
  if (length(current_game) != 1) 
    stop("simulate_direct_model_game: game_data must contain exactly one game")
  
  for (t in seq_len(n_trials)) {
    invest_amt    <- game_data$investment[t]
    actual_return <- game_data$return[t]
    if (is.na(invest_amt) || is.na(actual_return) || invest_amt == 0) 
      next
    
    s_bin <- get_investment_bin(invest_amt)
    
    # Trustee's policy
    Q_s     <- Q_values[s_bin,]
    shift   <- Q_s - max(Q_s)
    probs   <- exp(shift / temp)
    probs   <- pmax(probs, 1e-12)
    probs   <- probs / sum(probs)
    
    actual_prop  <- actual_return / (3*invest_amt)
    observed_bin <- get_return_bin(actual_prop)
    predicted_bin<- which.max(probs)
    
    # Store prediction
    predictions <- rbind(predictions, data.frame(
      round         = t,
      observed_bin  = observed_bin,
      predicted_bin = predicted_bin,
      predicted_prob= probs[observed_bin]
    ))
    # accumulate NLL
    nll <- nll - log(probs[observed_bin])
    
    # Fehr–Schmidt payoff
    trustee_payoff  <- 3*invest_amt - actual_return
    investor_payoff <- actual_return - invest_amt
    rew             <- calculate_fs_utility(trustee_payoff, investor_payoff, envy, guilt)
    
    # Next state
    if (t < n_trials) {
      next_invest <- game_data$investment[t+1]
      if (!is.na(next_invest) && next_invest > 0) {
        next_s_bin <- get_investment_bin(next_invest)
        future_val <- max(Q_values[next_s_bin,])
      } else {
        future_val <- 0
      }
    } else {
      future_val <- 0
    }
    
    pe <- rew + gamma*future_val - Q_values[s_bin, observed_bin]
    Q_values[s_bin, observed_bin] <- Q_values[s_bin, observed_bin] + alpha*pe
  }
  list(nll=nll, Q_values=Q_values, predictions=predictions)
}

get_training_Q_direct_model <- function(training_data, params) {
  # For each game in training data, simulate to get final Q
  games <- unique(training_data$gameNum.f)
  Q_list <- list()
  for (g in games) {
    g_data   <- training_data %>% filter(gameNum.f == g)
    sim_res  <- simulate_direct_model_game(g_data, params, Q_init=NULL)
    Q_list[[g]] <- sim_res$Q_values
  }
  Q_list
}

simulate_test_direct_model <- function(test_data, params, training_Q_list) {
  games      <- unique(test_data$gameNum.f)
  total_nll  <- 0
  details    <- list()
  for (g in games) {
    g_data <- test_data %>% filter(gameNum.f == g)
    if (is.null(training_Q_list[[g]])) {
      warning(paste("No training Q-values found for game", g))
      next
    }
    Q_init   <- training_Q_list[[g]]
    sim_res  <- simulate_direct_model_game(g_data, params, Q_init)
    total_nll<- total_nll + sim_res$nll
    details[[g]] <- sim_res
  }
  list(total_nll = total_nll, details = details)
}

fit_and_test_participant_direct_model <- function(participant_data,
                                                  param_fixed = list(),
                                                  n_multistart = 5,
                                                  train_cutoff = 20) {
  # train on first `train_cutoff` rounds, test on subsequent
  if (!"roundNum" %in% names(participant_data)) {
    participant_data <- participant_data %>%
      group_by(gameNum.f, playerId) %>%
      mutate(roundNum = row_number()) %>%
      ungroup()
  }
  training_data <- participant_data %>% filter(roundNum <= train_cutoff)
  test_data     <- participant_data %>% filter(roundNum > train_cutoff)
  
  # fit
  fit_res <- fit_direct_model_single(training_data, param_fixed, n_multistart)
  if (!is.null(fit_res$message) && fit_res$message == "Fitting failed.") {
    return(list(playerId = unique(participant_data$playerId),
                fit_error = "Fitting error",
                test_nll = NA,
                bin_accuracy = NA,
                parameters = NA,
                training_fit_nll = NA))
  }
  
  # simulate on test
  par_vec  <- c(fit_res$params$alpha,
                fit_res$params$temp,
                fit_res$params$envy,
                fit_res$params$guilt)
  
  train_Q_list <- get_training_Q_direct_model(training_data, par_vec)
  test_sim      <- simulate_test_direct_model(test_data, par_vec, train_Q_list)
  
  # compute bin accuracy
  all_predictions <- do.call(rbind, lapply(test_sim$details, function(x) x$predictions))
  if (is.null(all_predictions) || nrow(all_predictions) == 0) {
    bin_acc <- NA
  } else {
    bin_acc <- mean(all_predictions$observed_bin == all_predictions$predicted_bin)
  }
  
  list(playerId         = unique(participant_data$playerId),
       fit_error        = NA,
       test_nll         = test_sim$total_nll,
       bin_accuracy     = bin_acc,
       parameters       = fit_res$params,
       training_fit_nll = fit_res$neg_log_lik)
}

fit_and_test_all_participants_direct_model <- function(final_data,
                                                       param_fixed = list(),
                                                       n_multistart = 5,
                                                       n_cores = 8,
                                                       train_cutoff = 20) {
  if (!"roundNum" %in% names(final_data)) {
    final_data <- final_data %>%
      group_by(gameNum.f, playerId) %>%
      mutate(roundNum = row_number()) %>%
      ungroup()
  }
  
  participants <- split(final_data, final_data$playerId)
  
  cl <- makeCluster(n_cores)
  clusterExport(cl, varlist = c(
    "fit_and_test_participant_direct_model",
    "fit_direct_model_single", "direct_learning_model",
    "simulate_direct_model_game", "get_training_Q_direct_model", 
    "simulate_test_direct_model",
    "get_investment_bin", "get_return_bin", "calculate_fs_utility",
    "param_fixed", "n_multistart"
  ), envir=environment())
  
  clusterEvalQ(cl, { library(tidyverse); library(optimx); library(lhs) })
  
  results_list <- parLapplyLB(cl, participants, function(p_data) {
    tryCatch({
      res <- fit_and_test_participant_direct_model(
        p_data,
        param_fixed = param_fixed,
        n_multistart = n_multistart,
        train_cutoff = train_cutoff
      )
      data.frame(
        playerId         = res$playerId,
        training_negLL   = res$training_fit_nll,
        test_negLL       = res$test_nll,
        bin_accuracy     = res$bin_accuracy,
        alpha            = ifelse(is.null(res$parameters$alpha), NA, res$parameters$alpha),
        temp             = ifelse(is.null(res$parameters$temp),  NA, res$parameters$temp),
        envy             = ifelse(is.null(res$parameters$envy),  NA, res$parameters$envy),
        guilt            = ifelse(is.null(res$parameters$guilt), NA, res$parameters$guilt),
        fit_error        = res$fit_error,
        stringsAsFactors = FALSE
      )
    }, error = function(e) {
      data.frame(
        playerId       = unique(p_data$playerId),
        training_negLL = NA,
        test_negLL     = NA,
        bin_accuracy   = NA,
        alpha=NA, temp=NA, envy=NA, guilt=NA,
        fit_error      = e$message,
        stringsAsFactors=FALSE
      )
    })
  })
  stopCluster(cl)
  
  results_df <- do.call(rbind, results_list)
  return(results_df)
}

```

```{r}
fit_and_test_all_participants_direct_model(test_data2,
                                                       param_fixed = list(),
                                                       n_multistart = 5,
                                                       n_cores = 8,
                                                       train_cutoff = 20) 
```




```{r}

###############################################################################
# 8) Parameter Recovery Experiment
###############################################################################
# Example that uses the investor HMM transitions. 
# We fix the trustee to single alpha/temp and envy/guilt.
# Then we fit the model to see if we recover them.

param_recovery_experiment_mf <- function(n_sims=10, game_size=25) {
  results <- data.frame()
  
  for (i in seq_len(n_sims)) {
    # draw random 'true' trustee parameters
    alpha <- runif(1, 0.01, 0.9)
    temp  <- runif(1, 0.1, 5.0)
    envy  <- runif(1, 0.0,  2.0)
    guilt <- runif(1, 0.0,  1.5)
    params_true <- c(alpha, temp, envy, guilt)
    
    # simulate data using investor HMM
    sim_data <- simulate_2games_data_mf_hmm(params_true, game_size=game_size, playerId=i)
    
    # fit
    fitres <- fit_direct_model_single(sim_data, param_fixed=list(), n_multistart=10)
    
    # record
    if (!is.na(fitres$neg_log_lik)) {
      fitted <- fitres$params
      results <- rbind(results, data.frame(
        sim_id          = i,
        true_alpha      = alpha,
        fit_alpha       = fitted$alpha,
        true_temp       = temp,
        fit_temp        = fitted$temp,
        true_envy       = envy,
        fit_envy        = fitted$envy,
        true_guilt      = guilt,
        fit_guilt       = fitted$guilt,
        neg_log_lik     = fitres$neg_log_lik,
        stringsAsFactors=FALSE
      ))
    } else {
      results <- rbind(results, data.frame(
        sim_id=i,
        true_alpha=alpha, fit_alpha=NA,
        true_temp=temp,   fit_temp=NA,
        true_envy=envy,   fit_envy=NA,
        true_guilt=guilt, fit_guilt=NA,
        neg_log_lik=NA,   stringsAsFactors=FALSE
      ))
    }
  }
  return(results)
}
```

```{r}
param_recovery_experiment_mf()
```



```{r}

###############################################################################
# 9) Optional: Approx Fisher Information via Finite Differences
###############################################################################
# If you want to see which parameters are strongly identified, you can 
# approximate the Hessian of negative log-likelihood.

fisher_info_fd <- function(data, par_est, param_fixed=list(), h=1e-4) {
  # par_est is a numeric vector of the free parameters, in the order (alpha,temp,envy,guilt)
  # minus any fixed ones. So we must be consistent with how we feed it to direct_learning_model.
  
  # We'll build a function that merges param_fixed with x for the free params:
  free_names <- c()
  all_names  <- c("alpha","temp","envy","guilt")
  for (nm in all_names) {
    if (is.null(param_fixed[[nm]])) {
      free_names <- c(free_names, nm)
    }
  }
  
  negLL_fn <- function(x) direct_learning_model(x, data, param_fixed)
  
  n <- length(par_est)
  H <- matrix(0, n, n)
  
  for (i in seq_len(n)) {
    for (j in seq(i, n)) {
      if (i == j) {
        # second derivative w.r.t. param i
        x1 <- par_est; x1[i] <- x1[i] + h
        x2 <- par_est; x2[i] <- x2[i] - h
        f1 <- negLL_fn(x1)
        f2 <- negLL_fn(x2)
        f0 <- negLL_fn(par_est)
        H[i,i] <- (f1 - 2*f0 + f2)/(h^2)
      } else {
        # cross partial
        x_pp <- par_est; x_pp[i] <- x_pp[i] + h; x_pp[j] <- x_pp[j] + h
        x_pm <- par_est; x_pm[i] <- x_pm[i] + h; x_pm[j] <- x_pm[j] - h
        x_mp <- par_est; x_mp[i] <- x_mp[i] - h; x_mp[j] <- x_mp[j] + h
        x_mm <- par_est; x_mm[i] <- x_mm[i] - h; x_mm[j] <- x_mm[j] - h
        
        f_pp <- negLL_fn(x_pp)
        f_pm <- negLL_fn(x_pm)
        f_mp <- negLL_fn(x_mp)
        f_mm <- negLL_fn(x_mm)
        
        val <- (f_pp - f_pm - f_mp + f_mm)/(4*h^2)
        H[i,j] <- val
        H[j,i] <- val
      }
    }
  }
  return(H)
}

```



```{r}
###############################################################################
# EXAMPLE USAGE:
###############################################################################
# 1) Parameter Recovery
   result <- param_recovery_experiment_mf(n_sims=10, game_size=25)
   head(result)

# 2) Fitting multiple participants in parallel:
   # Suppose we have final_data with columns (playerId, gameNum.f, investment, return, etc.)
   res_par <- fit_all_participants_direct_model(final_data,
                                                param_fixed=list(temp=2.0),
                                                n_multistart=5,
                                                n_cores=4)
   # This would fix temp=2.0 and estimate alpha/envy/guilt.

# 3) Out-of-sample:
   res_test <- fit_and_test_all_participants_direct_model(final_data,
                                                          param_fixed=list(),
                                                          n_multistart=5,
                                                          n_cores=8,
                                                          train_cutoff=20)
   head(res_test)

# 4) Fisher Info:
   # After fitting one participant, we can approximate Hessian at the best fit:
   # e.g. par_est = c(alpha, temp, envy, guilt)
   H = fisher_info_fd(test_data1, NULL, param_fixed=list(), h=1e-4)
   Cov = solve(H) # approximate covariance matrix



```


###################### 3.7 

```{r}
# Enhanced parameter recovery - with slices and diagnostics
param_recovery_experiment_enhanced <- function(n_sims=20, game_size=25, param_fixed=list()) {
  results <- data.frame()
  
  # Create fixed grids for parameters when needed
  if (is.null(param_fixed$alpha)) {
    alpha_grid <- seq(0.05, 0.9, length.out=5)
  } else {
    alpha_grid <- param_fixed$alpha
  }
  
  if (is.null(param_fixed$temp)) {
    temp_grid <- c(0.5, 1, 2, 4)
  } else {
    temp_grid <- param_fixed$temp
  }
  
  if (is.null(param_fixed$envy)) {
    envy_grid <- c(0.2, 1, 2)
  } else {
    envy_grid <- param_fixed$envy
  }
  
  if (is.null(param_fixed$guilt)) {
    guilt_grid <- c(0.2, 0.5, 1)
  } else {
    guilt_grid <- param_fixed$guilt
  }
  
  # Create a grid of parameters to test
  param_grid <- expand.grid(
    alpha = alpha_grid,
    temp = temp_grid,
    envy = envy_grid,
    guilt = guilt_grid
  )
  
  # Limit to n_sims combinations
  param_grid <- param_grid[sample(nrow(param_grid), min(n_sims, nrow(param_grid))), ]
  
  for (i in 1:nrow(param_grid)) {
    # Use systematic parameter combinations
    alpha <- param_grid$alpha[i]
    temp <- param_grid$temp[i]
    envy <- param_grid$envy[i]
    guilt <- param_grid$guilt[i]
    
    # Override with fixed parameters when provided
    if (!is.null(param_fixed$alpha)) alpha <- param_fixed$alpha
    if (!is.null(param_fixed$temp)) temp <- param_fixed$temp
    if (!is.null(param_fixed$envy)) envy <- param_fixed$envy
    if (!is.null(param_fixed$guilt)) guilt <- param_fixed$guilt
    
    params_true <- c(alpha, temp, envy, guilt)
    
    # simulate data using investor HMM
    sim_data <- simulate_2games_data_mf_hmm(params_true, game_size=game_size, playerId=i)
    
    # fit with our improved function
    fitres <- fit_direct_model_single_improved(sim_data, param_fixed=param_fixed, n_multistart=10)
    
    # record
    if (!is.na(fitres$neg_log_lik)) {
      fitted <- fitres$params
      
      # Calculate parameter errors
      alpha_error <- if (is.null(param_fixed$alpha)) abs(alpha - fitted$alpha) else NA
      temp_error <- if (is.null(param_fixed$temp)) abs(temp - fitted$temp) else NA
      envy_error <- if (is.null(param_fixed$envy)) abs(envy - fitted$envy) else NA
      guilt_error <- if (is.null(param_fixed$guilt)) abs(guilt - fitted$guilt) else NA
      
      # Calculate relative errors
      alpha_rel_error <- if (is.null(param_fixed$alpha) && alpha != 0) alpha_error/alpha else NA
      temp_rel_error <- if (is.null(param_fixed$temp) && temp != 0) temp_error/temp else NA
      envy_rel_error <- if (is.null(param_fixed$envy) && envy != 0) envy_error/envy else NA
      guilt_rel_error <- if (is.null(param_fixed$guilt) && guilt != 0) guilt_error/guilt else NA
      
      results <- rbind(results, data.frame(
        sim_id = i,
        true_alpha = alpha,
        fit_alpha = fitted$alpha,
        alpha_error = alpha_error,
        alpha_rel_error = alpha_rel_error,
        true_temp = temp,
        fit_temp = fitted$temp,
        temp_error = temp_error,
        temp_rel_error = temp_rel_error,
        true_envy = envy,
        fit_envy = fitted$envy,
        envy_error = envy_error,
        envy_rel_error = envy_rel_error,
        true_guilt = guilt,
        fit_guilt = fitted$guilt,
        guilt_error = guilt_error,
        guilt_rel_error = guilt_rel_error,
        neg_log_lik = fitres$neg_log_lik,
        stringsAsFactors=FALSE
      ))
    } else {
      # Handle failed fits
      results <- rbind(results, data.frame(
        sim_id=i,
        true_alpha=alpha, fit_alpha=NA, alpha_error=NA, alpha_rel_error=NA,
        true_temp=temp, fit_temp=NA, temp_error=NA, temp_rel_error=NA,
        true_envy=envy, fit_envy=NA, envy_error=NA, envy_rel_error=NA,
        true_guilt=guilt, fit_guilt=NA, guilt_error=NA, guilt_rel_error=NA,
        neg_log_lik=NA, stringsAsFactors=FALSE
      ))
    }
  }
  
  # Add summary statistics
  summary_stats <- data.frame(
    param = c("alpha", "temp", "envy", "guilt"),
    mean_error = c(
      mean(results$alpha_error, na.rm=TRUE),
      mean(results$temp_error, na.rm=TRUE),
      mean(results$envy_error, na.rm=TRUE),
      mean(results$guilt_error, na.rm=TRUE)
    ),
    mean_rel_error = c(
      mean(results$alpha_rel_error, na.rm=TRUE),
      mean(results$temp_rel_error, na.rm=TRUE),
      mean(results$envy_rel_error, na.rm=TRUE),
      mean(results$guilt_rel_error, na.rm=TRUE)
    ),
    correlation = c(
      cor(results$true_alpha, results$fit_alpha, use="complete.obs"),
      cor(results$true_temp, results$fit_temp, use="complete.obs"),
      cor(results$true_envy, results$fit_envy, use="complete.obs"),
      cor(results$true_guilt, results$fit_guilt, use="complete.obs")
    ),
    stringsAsFactors=FALSE
  )
  
  list(
    results = results,
    summary = summary_stats
  )
}

# Improved profile likelihood analysis
profile_likelihood_analysis <- function(best_params, data, param_name, range_multiplier=1.5) {
  # Determine which parameter to profile
  all_params <- c("alpha", "temp", "envy", "guilt")
  param_idx <- which(all_params == param_name)
  if (length(param_idx) == 0) stop("Invalid parameter name")
  
  # Create parameter range centered on best estimate
  best_val <- best_params[[param_name]]
  
  # Define appropriate range based on parameter type
  if (param_name == "alpha") {
    # For alpha bounded in [0,1]
    param_range <- seq(max(0.001, best_val/range_multiplier), 
                      min(0.999, best_val*range_multiplier), 
                      length.out=20)
  } else if (param_name == "temp") {
    # For temperature (positive)
    param_range <- seq(max(0.01, best_val/range_multiplier), 
                      best_val*range_multiplier, 
                      length.out=20)
  } else if (param_name %in% c("envy", "guilt")) {
    # For social preference params
    param_range <- seq(max(0, best_val - range_multiplier), 
                      best_val + range_multiplier, 
                      length.out=20)
  }
  
  # Calculate profile likelihood
  profile_nll <- numeric(length(param_range))
  for (i in seq_along(param_range)) {
    # Fix the parameter of interest
    param_fixed <- list()
    param_fixed[[param_name]] <- param_range[i]
    
    # Fix all other parameters to their best values
    for (other_param in all_params) {
      if (other_param != param_name) {
        param_fixed[[other_param]] <- best_params[[other_param]]
      }
    }
    
    # Calculate NLL with all but one parameter fixed
    profile_nll[i] <- direct_learning_model(numeric(0), data, param_fixed)
  }
  
  # Find confidence interval (based on chi-square distribution)
  min_nll <- min(profile_nll)
  threshold_95pct <- min_nll + qchisq(0.95, df=1)/2
  in_ci <- profile_nll <= threshold_95pct
  
  # Return results
  list(
    parameter = param_name,
    values = param_range,
    nll = profile_nll,
    min_idx = which.min(profile_nll),
    min_value = param_range[which.min(profile_nll)],
    ci_95pct_idx = which(in_ci),
    ci_95pct_range = range(param_range[in_ci])
  )
}

# Function to run profile likelihood for all parameters
analyze_all_profiles <- function(best_params, data) {
  all_params <- c("alpha", "temp", "envy", "guilt")
  profiles <- list()
  
  for (param in all_params) {
    profiles[[param]] <- profile_likelihood_analysis(best_params, data, param)
  }
  
  return(profiles)
}

# Summary function for parameter recovery experiments
param_recovery_summary <- function(recovery_results) {
  # Extract results table
  results <- recovery_results$results
  
  # Calculate additional recovery metrics
  alpha_recovery <- with(results, {
    data.frame(
      parameter = "alpha",
      correlation = cor(true_alpha, fit_alpha, use="complete.obs"),
      mean_abs_error = mean(abs(true_alpha - fit_alpha), na.rm=TRUE),
      median_abs_error = median(abs(true_alpha - fit_alpha), na.rm=TRUE),
      mean_rel_error = mean(abs(true_alpha - fit_alpha)/true_alpha, na.rm=TRUE),
      recovery_ratio = mean(fit_alpha/true_alpha, na.rm=TRUE),
      bias = mean(fit_alpha - true_alpha, na.rm=TRUE),
      success_rate = mean(!is.na(fit_alpha))
    )
  })
  
  temp_recovery <- with(results, {
    data.frame(
      parameter = "temp",
      correlation = cor(true_temp, fit_temp, use="complete.obs"),
      mean_abs_error = mean(abs(true_temp - fit_temp), na.rm=TRUE),
      median_abs_error = median(abs(true_temp - fit_temp), na.rm=TRUE),
      mean_rel_error = mean(abs(true_temp - fit_temp)/true_temp, na.rm=TRUE),
      recovery_ratio = mean(fit_temp/true_temp, na.rm=TRUE),
      bias = mean(fit_temp - true_temp, na.rm=TRUE),
      success_rate = mean(!is.na(fit_temp))
    )
  })
  
  envy_recovery <- with(results, {
    data.frame(
      parameter = "envy",
      correlation = cor(true_envy, fit_envy, use="complete.obs"),
      mean_abs_error = mean(abs(true_envy - fit_envy), na.rm=TRUE),
      median_abs_error = median(abs(true_envy - fit_envy), na.rm=TRUE),
      mean_rel_error = mean(abs(true_envy - fit_envy)/(true_envy+0.01), na.rm=TRUE),
      recovery_ratio = mean(fit_envy/(true_envy+0.01), na.rm=TRUE),
      bias = mean(fit_envy - true_envy, na.rm=TRUE),
      success_rate = mean(!is.na(fit_envy))
    )
  })
  
  guilt_recovery <- with(results, {
    data.frame(
      parameter = "guilt",
      correlation = cor(true_guilt, fit_guilt, use="complete.obs"),
      mean_abs_error = mean(abs(true_guilt - fit_guilt), na.rm=TRUE),
      median_abs_error = median(abs(true_guilt - fit_guilt), na.rm=TRUE),
      mean_rel_error = mean(abs(true_guilt - fit_guilt)/(true_guilt+0.01), na.rm=TRUE),
      recovery_ratio = mean(fit_guilt/(true_guilt+0.01), na.rm=TRUE),
      bias = mean(fit_guilt - true_guilt, na.rm=TRUE),
      success_rate = mean(!is.na(fit_guilt))
    )
  })
  
  # Combine all metrics
  recovery_metrics <- rbind(alpha_recovery, temp_recovery, envy_recovery, guilt_recovery)
  
  # Return structured output
  list(
    recovery_metrics = recovery_metrics,
    best_recovered = recovery_metrics$parameter[which.max(recovery_metrics$correlation)],
    worst_recovered = recovery_metrics$parameter[which.min(recovery_metrics$correlation)],
    success_rate = mean(c(
      mean(!is.na(results$fit_alpha)),
      mean(!is.na(results$fit_temp)),
      mean(!is.na(results$fit_envy)),
      mean(!is.na(results$fit_guilt))
    ))
  )
}

# Function to analyze and visualize which parameters are recoverable
analyze_parameter_recoverability <- function() {
  # 1. Full recovery experiment
  cat("Running full parameter recovery...\n")
  full_recovery <- param_recovery_experiment_enhanced(n_sims=20)
  full_summary <- param_recovery_summary(full_recovery)
  print(full_summary$recovery_metrics)
  
  # 2. Sequential one-parameter-at-a-time recovery
  cat("Running alpha-only recovery...\n")
  alpha_recovery <- param_recovery_experiment_enhanced(
    n_sims=15, 
    param_fixed=list(temp=1.5, envy=1.0, guilt=0.5)
  )
  alpha_summary <- param_recovery_summary(alpha_recovery)
  
  cat("Running temp-only recovery...\n")
  temp_recovery <- param_recovery_experiment_enhanced(
    n_sims=15, 
    param_fixed=list(alpha=0.3, envy=1.0, guilt=0.5)
  )
  temp_summary <- param_recovery_summary(temp_recovery)
  
  cat("Running envy-only recovery...\n")
  envy_recovery <- param_recovery_experiment_enhanced(
    n_sims=15, 
    param_fixed=list(alpha=0.3, temp=1.5, guilt=0.5)
  )
  envy_summary <- param_recovery_summary(envy_recovery)
  
  cat("Running guilt-only recovery...\n")
  guilt_recovery <- param_recovery_experiment_enhanced(
    n_sims=15, 
    param_fixed=list(alpha=0.3, temp=1.5, envy=1.0)
  )
  guilt_summary <- param_recovery_summary(guilt_recovery)
  
  # 3. Two-parameter-at-a-time recovery
  cat("Running alpha-temp recovery...\n")
  alpha_temp_recovery <- param_recovery_experiment_enhanced(
    n_sims=15, 
    param_fixed=list(envy=1.0, guilt=0.5)
  )
  alpha_temp_summary <- param_recovery_summary(alpha_temp_recovery)
  
  cat("Running envy-guilt recovery...\n")
  envy_guilt_recovery <- param_recovery_experiment_enhanced(
    n_sims=15, 
    param_fixed=list(alpha=0.3, temp=1.5)
  )
  envy_guilt_summary <- param_recovery_summary(envy_guilt_recovery)
  
  # Combine all results
  combined_results <- list(
    full = full_summary,
    alpha_only = alpha_summary,
    temp_only = temp_summary,
    envy_only = envy_summary,
    guilt_only = guilt_summary,
    alpha_temp = alpha_temp_summary,
    envy_guilt = envy_guilt_summary
  )
  
  # Create parameter recoverability table
  recovery_table <- data.frame(
    parameter = c("alpha", "temp", "envy", "guilt"),
    full_recovery_corr = c(
      full_summary$recovery_metrics[1, "correlation"],
      full_summary$recovery_metrics[2, "correlation"],
      full_summary$recovery_metrics[3, "correlation"],
      full_summary$recovery_metrics[4, "correlation"]
    ),
    isolated_recovery_corr = c(
      alpha_summary$recovery_metrics[1, "correlation"],
      temp_summary$recovery_metrics[2, "correlation"],
      envy_summary$recovery_metrics[3, "correlation"],
      guilt_summary$recovery_metrics[4, "correlation"]
    ),
    paired_recovery_corr = c(
      alpha_temp_summary$recovery_metrics[1, "correlation"],
      alpha_temp_summary$recovery_metrics[2, "correlation"],
      envy_guilt_summary$recovery_metrics[3, "correlation"],
      envy_guilt_summary$recovery_metrics[4, "correlation"]
    )
  )
  
  list(
    combined_results = combined_results,
    recovery_table = recovery_table
  )
}
```

```{r}
param_recovery_experiment_enhanced(n_sims=5, game_size=5, param_fixed=list())
```



```{r}
###############################################################################
# Parameter Recoverability Analysis Framework
###############################################################################

library(ggplot2)
library(gridExtra)

# 1. Parameter Identifiability Visualization
plot_param_recovery <- function(recovery_results, param_name) {
  results <- recovery_results$results
  
  # Get true and fitted parameter columns
  true_col <- paste0("true_", param_name)
  fit_col <- paste0("fit_", param_name)
  
  # Extract data
  true_values <- results[[true_col]]
  fit_values <- results[[fit_col]]
  valid_idx <- !is.na(true_values) & !is.na(fit_values)
  
  if (sum(valid_idx) < 3) {
    warning("Not enough valid data points to create plot for ", param_name)
    return(NULL)
  }
  
  # Create plot
  p <- ggplot(data.frame(true = true_values[valid_idx], 
                         fit = fit_values[valid_idx]), 
             aes(x = true, y = fit)) +
    geom_point(alpha = 0.7) +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
    geom_smooth(method = "lm", se = TRUE, color = "blue", formula = y ~ x) +
    labs(title = paste("Recovery of", param_name),
         x = paste("True", param_name),
         y = paste("Fitted", param_name)) +
    theme_minimal() +
    annotate("text", x = min(true_values[valid_idx]), 
             y = max(fit_values[valid_idx]), 
             label = paste("r =", round(cor(true_values[valid_idx], 
                                            fit_values[valid_idx]), 3)),
             hjust = 0, vjust = 1)
  
  return(p)
}

# 2. Model Sensitivty Analysis Function
analyze_model_sensitivity <- function() {
  # Fixed parameter values for baseline
  baseline_params <- c(alpha = 0.3, temp = 1.5, envy = 1.0, guilt = 0.5)
  
  # Create parameter ranges to test
  param_ranges <- list(
    alpha = seq(0.05, 0.9, by = 0.05),
    temp = seq(0.2, 5, length.out = 20),
    envy = seq(0, 3, by = 0.2),
    guilt = seq(0, 1.5, by = 0.1)
  )
  
  # Function to calculate model predictions varying only one parameter
  calculate_sensitivity <- function(param_name) {
    param_values <- param_ranges[[param_name]]
    results <- data.frame(
      param_value = param_values,
      avg_return_prop = numeric(length(param_values)),
      unhappy_return = numeric(length(param_values)),
      neutral_return = numeric(length(param_values)),
      happy_return = numeric(length(param_values))
    )
    
    for (i in seq_along(param_values)) {
      # Set current parameter value, keeping others at baseline
      current_params <- baseline_params
      current_params[param_name] <- param_values[i]
      
      # Simulate data with these parameters (multiple runs to average)
      n_runs <- 5
      all_returns <- list()
      state_returns <- list(unhappy = c(), neutral = c(), happy = c())
      
      for (run in 1:n_runs) {
        sim_data <- simulate_2games_data_mf_hmm(
          current_params, game_size = 25, playerId = run)
        
        # Calculate average return proportion
        avg_return <- mean(sim_data$return / (3 * sim_data$investment), na.rm = TRUE)
        all_returns[[run]] <- avg_return
        
        # Track returns by investor state - this requires extracting states
        # This would need to be implemented based on how your simulation works
        # This is a placeholder assuming you have a way to get investor states
        # unhappy_returns <- sim_data$return[investor_states == "unhappy"] / ...
        # neutral_returns <- ...
        # happy_returns <- ...
      }
      
      results$avg_return_prop[i] <- mean(unlist(all_returns))
      # results$unhappy_return[i] <- mean(state_returns$unhappy)
      # results$neutral_return[i] <- mean(state_returns$neutral)
      # results$happy_return[i] <- mean(state_returns$happy)
    }
    
    return(results)
  }
  
  # Calculate sensitivity for each parameter
  sensitivity_results <- list(
    alpha = calculate_sensitivity("alpha"),
    temp = calculate_sensitivity("temp"),
    envy = calculate_sensitivity("envy"),
    guilt = calculate_sensitivity("guilt")
  )
  
  # Plot sensitivity results
  plot_sensitivity <- function(sensitivity_data, param_name) {
    ggplot(sensitivity_data, aes(x = param_value, y = avg_return_prop)) +
      geom_line(size = 1) +
      geom_point() +
      labs(title = paste("Model Sensitivity to", param_name),
           x = param_name,
           y = "Average Return Proportion") +
      theme_minimal()
  }
  
  sensitivity_plots <- lapply(names(sensitivity_results), function(param) {
    plot_sensitivity(sensitivity_results[[param]], param)
  })
  
  # Return both data and plots
  list(
    data = sensitivity_results,
    plots = sensitivity_plots
  )
}

# 3. Parameter Interaction Analysis
analyze_parameter_interaction <- function() {
  # Choose two parameters to analyze interaction
  param1 <- "alpha"
  param2 <- "temp"
  
  # Create grid of values
  param1_values <- seq(0.1, 0.9, by = 0.1)
  param2_values <- seq(0.5, 4, by = 0.5)
  
  # Fixed values for other parameters
  fixed_envy <- 1.0
  fixed_guilt <- 0.5
  
  # Create grid for interaction analysis
  grid_size <- length(param1_values) * length(param2_values)
  interaction_grid <- expand.grid(
    alpha = param1_values,
    temp = param2_values
  )
  
  # Initialize results
  interaction_grid$avg_return <- numeric(nrow(interaction_grid))
  interaction_grid$recovery_success <- numeric(nrow(interaction_grid))
  
  # For each parameter combination:
  for (i in 1:nrow(interaction_grid)) {
    # Set parameter values
    true_params <- c(
      alpha = interaction_grid$alpha[i],
      temp = interaction_grid$temp[i],
      envy = fixed_envy,
      guilt = fixed_guilt
    )
    
    # Simulate data
    sim_data <- simulate_2games_data_mf_hmm(
      true_params, game_size = 25, playerId = i)
    
    # Calculate average return
    interaction_grid$avg_return[i] <- mean(sim_data$return / (3 * sim_data$investment), 
                                         na.rm = TRUE)
    
    # Optionally - try to recover parameters
    # This is computationally intensive, so you might want to do this
    # for a smaller subset of the grid
    if (i %% 5 == 0) {  # Only test every 5th point
      fit_result <- fit_direct_model_single_improved(
        sim_data, 
        param_fixed = list(envy = fixed_envy, guilt = fixed_guilt),
        n_multistart = 5
      )
      
      if (!is.null(fit_result$params) && !is.na(fit_result$params$alpha)) {
        # Calculate recovery error
        alpha_error <- abs(true_params["alpha"] - fit_result$params$alpha)
        temp_error <- abs(true_params["temp"] - fit_result$params$temp)
        
        # Consider recovery successful if errors are small
        recovery_success <- (alpha_error < 0.1) && (temp_error < 0.5)
        interaction_grid$recovery_success[i] <- as.numeric(recovery_success)
      }
    }
  }
  
  # Plot interaction effects on model output
  output_plot <- ggplot(interaction_grid, aes(x = alpha, y = temp, fill = avg_return)) +
    geom_tile() +
    scale_fill_viridis_c() +
    labs(title = "Interaction Effects on Return Proportion",
         x = "Learning Rate (alpha)",
         y = "Temperature",
         fill = "Avg Return") +
    theme_minimal()
  
  # Plot parameter recovery success (if available)
  if (sum(!is.na(interaction_grid$recovery_success)) > 0) {
    recovery_data <- interaction_grid[!is.na(interaction_grid$recovery_success),]
    recovery_plot <- ggplot(recovery_data, 
                         aes(x = alpha, y = temp, color = factor(recovery_success))) +
      geom_point(size = 3) +
      scale_color_manual(values = c("0" = "red", "1" = "green")) +
      labs(title = "Parameter Recovery Success",
           x = "True Alpha",
           y = "True Temperature",
           color = "Recovery\nSuccess") +
      theme_minimal()
  } else {
    recovery_plot <- NULL
  }
  
  list(
    data = interaction_grid,
    output_plot = output_plot,
    recovery_plot = recovery_plot
  )
}

# 4. Compute Approximate Parameter Identifiability Scores
compute_identifiability_scores <- function() {
  # Run multiple recovery experiments with different parameter fixations
  
  # 1. All parameters free
  cat("Running full parameter recovery test...\n")
  full_recovery <- param_recovery_experiment_enhanced(n_sims = 15)
  
  # 2. One parameter free at a time
  cat("Testing individual parameter recovery...\n")
  alpha_only <- param_recovery_experiment_enhanced(
    n_sims = 10, 
    param_fixed = list(temp = 1.5, envy = 1.0, guilt = 0.5)
  )
  
  temp_only <- param_recovery_experiment_enhanced(
    n_sims = 10, 
    param_fixed = list(alpha = 0.3, envy = 1.0, guilt = 0.5)
  )
  
  envy_only <- param_recovery_experiment_enhanced(
    n_sims = 10, 
    param_fixed = list(alpha = 0.3, temp = 1.5, guilt = 0.5)
  )
  
  guilt_only <- param_recovery_experiment_enhanced(
    n_sims = 10, 
    param_fixed = list(alpha = 0.3, temp = 1.5, envy = 1.0)
  )
  
  # Calculate identifiability scores
  identifiability_scores <- data.frame(
    parameter = c("alpha", "temp", "envy", "guilt"),
    full_recovery_r = c(
      cor(full_recovery$results$true_alpha, full_recovery$results$fit_alpha, use="complete.obs"),
      cor(full_recovery$results$true_temp, full_recovery$results$fit_temp, use="complete.obs"),
      cor(full_recovery$results$true_envy, full_recovery$results$fit_envy, use="complete.obs"),
      cor(full_recovery$results$true_guilt, full_recovery$results$fit_guilt, use="complete.obs")
    ),
    individual_recovery_r = c(
      cor(alpha_only$results$true_alpha, alpha_only$results$fit_alpha, use="complete.obs"),
      cor(temp_only$results$true_temp, temp_only$results$fit_temp, use="complete.obs"),
      cor(envy_only$results$true_envy, envy_only$results$fit_envy, use="complete.obs"),
      cor(guilt_only$results$true_guilt, guilt_only$results$fit_guilt, use="complete.obs")
    )
  )
  
  # Calculate ratio between individual recovery and full recovery
  identifiability_scores$recovery_ratio <- identifiability_scores$individual_recovery_r / 
                                         identifiability_scores$full_recovery_r
  
  # Compute a simple identifiability score
  identifiability_scores$identifiability_score <- (
    identifiability_scores$individual_recovery_r * identifiability_scores$recovery_ratio
  )
  
  # Normalize scores
  max_score <- max(identifiability_scores$identifiability_score)
  identifiability_scores$normalized_score <- identifiability_scores$identifiability_score / max_score
  
  # Return results
  return(identifiability_scores)
}

# 5. Full Workflow for Parameter Analysis
full_parameter_analysis <- function() {
  # Step 1: Compute identifiability scores
  cat("Computing parameter identifiability scores...\n")
  id_scores <- compute_identifiability_scores()
  print(id_scores)
  
  # Step 2: Run model sensitivity analysis
  cat("Running model sensitivity analysis...\n")
  sensitivity <- analyze_model_sensitivity()
  
  # Step 3: Analyze parameter interactions for the most identifiable parameters
  cat("Analyzing parameter interactions...\n")
  top_params <- id_scores$parameter[order(id_scores$normalized_score, decreasing = TRUE)[1:2]]
  interactions <- analyze_parameter_interaction()
  
  # Step 4: Run profile likelihood for a sample dataset
  cat("Running profile likelihood analysis...\n")
  # Generate sample data with known parameters
  true_params <- list(alpha = 0.3, temp = 1.5, envy = 1.0, guilt = 0.5)
  sample_data <- simulate_2games_data_mf_hmm(
    unlist(true_params), game_size = 25, playerId = 1)
  
  # Fit model
  fit_result <- fit_direct_model_single_improved(sample_data, param_fixed = list())
  
  # Get profile likelihoods
  profiles <- analyze_all_profiles(fit_result$params, sample_data)
  
  # Return comprehensive results
  list(
    identifiability = id_scores,
    sensitivity = sensitivity,
    interactions = interactions,
    profiles = profiles,
    recommendation = data.frame(
      parameter = id_scores$parameter,
      normalized_score = id_scores$normalized_score,
      recommendation = ifelse(
        id_scores$normalized_score > 0.7,
        "Keep as free parameter",
        ifelse(
          id_scores$normalized_score > 0.4,
          "Consider fixing or constraining",
          "Fix to literature value"
        )
      )
    )
  )
}
```

```{r}
# Example of how to run the full analysis
results <- full_parameter_analysis()
print(results$recommendation)
```


