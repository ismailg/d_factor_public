---
title: "DFP RTG"
author:
  "Ismail Guennouni^1,2,3,4^*, Christoph Korn^4^, Georgia Koppe^1,2,3^"
abstract: |
bibliography: "bib/DFP.bib"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    latex_engine: xelatex 
header-includes:
  - \usepackage{pdflscape}
  - \usepackage{graphicx}
---
\small

^1^ *Department of Psychiatry and Psychotherapy, Central Institute of
Mental Health, Medical Faculty Mannheim, Heidelberg University,
Mannheim, Germany*

^2^ *Interdisciplinary Center for Scientific Computing, Faculty of
Mathematics and Computer Science, Heidelberg University, Heidelberg,
Germany*

^3^ *Hector Institute for AI in Psychiatry, Central Institute of Mental
Health, Medical Faculty Mannheim, Heidelberg University, Mannheim
Germany*

^4^ *Department of General Psychiatry, Section Social Neuroscience,
Heidelberg University, Germany*


^\*^ *Corresponding author. Address: Central institute of Mental Health,
J5, Mannheim, Germany. Email:
[ismail.guennouni\@zi-mannheim.de](mailto:ismail.guennouni@iwr.uni-heidelberg.de){.email}*

**Abstract:**


\pagebreak



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include=FALSE, warning = FALSE)
```


# Introduction 

<!-- Trust and cooperation are fundamental to human social interaction and economic exchange (Berg et al., 1995). The trust game, particularly in its repeated form, has emerged as a powerful tool for investigating the dynamics of trust and reciprocity in controlled settings (Camerer, 2003). While numerous studies have explored various personality traits as predictors of behavior in trust games, recent developments in personality psychology offer new avenues for understanding the underlying factors that influence trustworthiness. -->

<!-- The Dark Factor of Personality (D-factor), proposed by Moshagen et al. (2018), represents a unified construct encompassing various malevolent personality traits. Defined as the general tendency to maximize one's utility at the expense of others, accompanied by beliefs that serve as justifications, the D-factor offers a comprehensive framework for understanding antisocial tendencies. This construct incorporates elements of Machiavellianism, Narcissism, and Psychopathy - traits previously linked to reduced trustworthiness in economic games (Ibáñez et al., 2016; Gunnthorsdottir et al., 2002). -->

<!-- Research has consistently demonstrated negative correlations between dark personality traits and cooperative behavior in various economic games. A meta-analysis by Zhao and Smillie (2015) found that dark triad traits negatively predict cooperation across different economic paradigms. Similarly, Thielmann and Hilbig (2019) observed that dark personality traits predict dishonest behavior in economic interactions. These findings suggest that the D-factor, as a unifying construct, may serve as a potent predictor of untrustworthy behavior in trust games. -->

<!-- While the D-factor has shown associations with selfish behavior in dictator games (Moshagen et al., 2020) and lower levels of honesty-humility (Zettler et al., 2021), its specific impact on trustworthiness in repeated trust games remains unexplored. This gap is particularly notable given the unique features of the repeated trust game, which allows for the development of reputation and the potential for strategic behavior over multiple interactions (Bohnet & Huck, 2004). -->
<!-- The repeated nature of the game introduces complexity not present in one-shot interactions. Individuals with high D-factor scores may exhibit different patterns of behavior over repeated rounds, potentially engaging in strategic trust-building before exploitation. This dynamic aligns with the Machiavellian aspect of the D-factor, which involves a strategic, long-term orientation to personal gain (Jones & Paulhus, 2009). -->

<!-- A notable exception is the study by Gong et al. (2019), which examined the relationship between psychopathic traits and behavior in a modified trust game. However, their design involved multiple different partners rather than repeated interactions with the same opponent. Similarly, Rosenberger et al. (2019) examined fairness norm violations in violent offenders during a repeated trust game, finding that antisocial traits (Factor 2 of psychopathy) rather than interpersonal/affective traits (Factor 1) were associated with reduced reciprocity. However, this study focused on clinical psychopathy in offenders rather than the D-factor in the general population. -->

<!-- The present study addresses several crucial gaps in our understanding of how dark personality traits influence economic behavior. First, by using a repeated trust game paradigm with 25 rounds, we can examine whether high D-factor individuals demonstrate strategic patterns that evolve over time, such as initial trust-building followed by exploitation. Second, by manipulating opponent predictability through the use of different Hidden Markov Model (HMM) agents—one "human-like" and one more "volatile"—we can assess whether the behavioral manifestation of dark personality traits varies based on environmental stability. This approach allows us to test whether high D-factor individuals demonstrate sophisticated social intelligence by adapting their strategies to different counterparts. -->
<!-- The use of HMM agents as opponents provides significant methodological advantages for studying dark personality traits. These computational models, trained on real human behavior data, allow us to create standardized yet responsive interaction partners whose strategies can be precisely characterized and manipulated. This approach combines ecological validity (as the agents mimic actual human behavior) with experimental control, allowing us to isolate the effects of personality while maintaining the dynamic nature of trust interactions. -->

<!-- Understanding the relationship between the D-factor and trustworthiness in repeated interactions has significant implications. From an academic perspective, it would bridge the gap between personality psychology and behavioral economics, offering insights into the stability of dark personality influences across repeated social interactions. Practically, such understanding could inform strategies and interventions to promote more cooperative outcomes for people with high D-factor scores. -->

<!-- The present study aims to investigate the predictive power of the Dark Factor of Personality on trustworthiness in the repeated trust game. We hypothesize that individuals scoring higher on the D-factor will exhibit less trustworthy behavior as trustees, particularly in later rounds of the game. Additionally, we expect high D-factor individuals to show greater strategic adaptation to opponent type, with more pronounced exploitation of predictable opponents compared to volatile ones. Finally, we explore whether these behavioral patterns are accompanied by systematic differences in perception of opponents, with high D-factor individuals potentially showing more negative evaluations regardless of opponent behavior. -->

Trust and cooperation are fundamental to human social interaction and economic exchange [@Berg1995]. The trust game, particularly in its repeated form, has emerged as a powerful tool for investigating the dynamics of trust and reciprocity in controlled settings [@Camerer2003]. While numerous studies have explored various personality traits as predictors of behavior in trust games, recent developments in personality psychology offer new avenues for understanding the underlying factors that influence trustworthiness.

The Dark Factor of Personality (D-factor), proposed by @Moshagen2018, represents a unified construct encompassing various malevolent personality traits. Defined as the general tendency to maximize one's utility at the expense of others, accompanied by beliefs that serve as justifications, the D-factor offers a comprehensive framework for understanding antisocial tendencies. This construct incorporates elements of Machiavellianism, Narcissism, and Psychopathy - traits previously linked to reduced trustworthiness in economic games [@Ibanez2016; @Gunnthorsdottir2002].

Research has consistently demonstrated negative correlations between dark personality traits and cooperative behavior in various economic games. A meta-analysis by @Zhao2015 found that dark triad traits negatively predict cooperation across different economic paradigms. Similarly, @Thielmann2019 observed that dark personality traits predict dishonest behavior in economic interactions. These findings suggest that the D-factor, as a unifying construct, may serve as a potent predictor of untrustworthy behavior in trust games.

While the D-factor has shown associations with selfish behavior in dictator games [@Moshagen2020] and lower levels of honesty-humility [@Zettler2021], its specific impact on trustworthiness in repeated trust games remains unexplored. This gap is particularly notable given the unique features of the repeated trust game, which allows for the development of reputation and the potential for strategic behavior over multiple interactions [@Bohnet2004].
The repeated nature of the game introduces complexity not present in one-shot interactions. Individuals with high D-factor scores may exhibit different patterns of behavior over repeated rounds, potentially engaging in strategic trust-building before exploitation. This dynamic aligns with the Machiavellian aspect of the D-factor, which involves a strategic, long-term orientation to personal gain [@Jones2009].

A notable exception is the study by @Gong2019, which examined the relationship between psychopathic traits and behavior in a modified trust game. However, their design involved multiple different partners rather than repeated interactions with the same opponent. Similarly, @Rosenberger2019 examined fairness norm violations in violent offenders during a repeated trust game, finding that antisocial traits (Factor 2 of psychopathy) rather than interpersonal/affective traits (Factor 1) were associated with reduced reciprocity. However, this study focused on clinical psychopathy in offenders rather than the D-factor in the general population.

The present study addresses several crucial gaps in our understanding of how dark personality traits influence economic behavior. First, by using a repeated trust game paradigm with 25 rounds, we can examine whether high D-factor individuals demonstrate strategic patterns that evolve over time, such as initial trust-building followed by exploitation. Second, by manipulating opponent predictability through the use of different Hidden Markov Model (HMM) agents—one "human-like" and one more "volatile"—we can assess whether the behavioral manifestation of dark personality traits varies based on environmental stability. This approach allows us to test whether high D-factor individuals demonstrate sophisticated social intelligence by adapting their strategies to different counterparts.
The use of HMM agents as opponents provides significant methodological advantages for studying dark personality traits. These computational models, trained on real human behavior data, allow us to create standardized yet responsive interaction partners whose strategies can be precisely characterized and manipulated. This approach combines ecological validity (as the agents mimic actual human behavior) with experimental control, allowing us to isolate the effects of personality while maintaining the dynamic nature of trust interactions.

Understanding the relationship between the D-factor and trustworthiness in repeated interactions has significant implications. From an academic perspective, it would bridge the gap between personality psychology and behavioral economics, offering insights into the stability of dark personality influences across repeated social interactions. Practically, such understanding could inform strategies and interventions to promote more cooperative outcomes for people with high D-factor scores.

The present study aims to investigate the predictive power of the Dark Factor of Personality on trustworthiness in the repeated trust game. We hypothesize that individuals scoring higher on the D-factor will exhibit less trustworthy behavior as trustees, particularly in later rounds of the game. Additionally, we expect high D-factor individuals to show greater strategic adaptation to opponent type, with more pronounced exploitation of predictable opponents compared to volatile ones. Finally, we explore whether these behavioral patterns are accompanied by systematic differences in perception of opponents, with high D-factor individuals potentially showing more negative evaluations regardless of opponent behavior.


# Methods 



```{r load-packages05}
library(papaja)
library(kableExtra)
require(knitr)

# using some functions dplyr, ggpubr, PairedData and sjPlot. Need to be loaded. 
library(tidyverse)
library(afex)
library(PairedData)
library(multcompView)
library(lsmeans)
library(depmixS4)
library(flextable)
library(grid)
library(gridExtra)
library(forcats)
library(ggsignif)
library(magick)

```



```{r, include=FALSE}
Anti_social <-  c(0.1025436430408, 0.1221931236853, 0.1345215238995,
0.1368182252617, 0.1285592471751, 0.1116014322677, 0.0895041220882,
0.0663166721334, 0.0453950277118, 0.0287077419587, 0.0167723588011,
0.0090530028158, 0.0045143317507, 0.0020796744990, 0.0008851094702,
0.0003480141146, 0.0001264134789, 0.0000424213859, 0.0000131513231,
0.0000037665630, 0.0000009965755)

Neutral <- c(0.003393529, 0.006930874, 0.013053553, 0.022671228,
0.036310144, 0.053627606, 0.073039389, 0.091734929, 0.106248217,
0.113479701, 0.111769796, 0.101517390, 0.085028780, 0.065675083,
0.046778251, 0.030725245, 0.018610323, 0.010394861, 0.005354126,
0.002543094, 0.001113881)

Pro_social <- c(0.003162697, 0.001057162, 0.001410197, 0.001881016,
0.002508877, 0.003346113, 0.004462480, 0.005950950, 0.007935434,
0.010581067, 0.014107909, 0.018809194, 0.025075644, 0.033427845,
0.044559370, 0.059394206, 0.079163228, 0.105506029, 0.140606514,
0.187373417, 0.249680651)

investment <- seq(0:20) -1

response_probs <- as.data.frame(cbind(investment,Anti_social,Neutral,Pro_social)) %>% 
  rename("low-trust" = "Anti_social", "medium-trust"="Neutral", "high-trust" = "Pro_social") %>%
  pivot_longer(cols=c("low-trust","medium-trust","high-trust"),
                    names_to='Investor_state',
                    values_to='probability') %>% 
   mutate(across(Investor_state, factor, levels=c("low-trust","medium-trust","high-trust")))
```

```{r}

plotinvHMM <- ggplot(response_probs,                            
       aes(x = investment,
           y = probability,
           fill = Investor_state)) +
  geom_bar(stat = "identity",
           position = "dodge") + 
  labs(fill='Latent investor state', x = "Investment", y= "Probability") + 
  theme_bw() + 
  theme(legend.position = "bottom",  legend.text = element_text(size = 10),  legend.title = element_text(size = 10))
  
plotinvHMM
```


```{r}
# Parameters for HMM human-like Transition Function
unhappy_pars <- rbind(c(0,0), c(-3.366027, 0.40910797 ), c(-3.572619,0.08137274)) 
neutral_pars <- rbind(c(0,0), c(3.3142637, 0.3763408), c(0.9169736, 0.4502838))
happy_pars   <- rbind(c(0,0), c(0.7134085, 0.02101626), c(2.2215478 ,0.16162964))

pars_inv <- list(unhappy_pars, neutral_pars, happy_pars)

```



```{r}
plot_HMM_transitions <- function(ns, pars_mat) {

  trans_prob <- data.frame(
    from = rep(1:ns, each=100*ns),
    to = rep(1:ns, each=100),
    ret = seq(-20,60,length=100),
    probs = 0
  )
  
  
  y <- matrix(0.0,ncol=ns, nrow=100)
  
  for(from in 1:ns) {
  pars <- matrix(pars_mat[[from]], ncol=2)
  # print(pars)
  
    for(to in 1:ns) {
        x <- trans_prob[trans_prob$from == from & trans_prob$to == to,"ret"]
        y[,to] <- exp(pars[to,1] + pars[to,2]*x)
    }
    y <- y/rowSums(y)

    
    for(to in 1:ns) {
      trans_prob$probs[trans_prob$from == from & trans_prob$to == to] <- y[,to]
    }
  }
  
  df <- as.data.frame(trans_prob) %>% 
    mutate(from = recode(from, "1" = "low-trust", "2" = "medium-trust", "3" = "high-trust"),
           to = recode(to, "1" = "low-trust", "2" = "medium-trust", "3" = "high-trust") ) %>% 
    mutate(across(from, factor, levels=c("low-trust","medium-trust","high-trust"))) %>% 
    mutate(across(to, factor, levels=c("low-trust","medium-trust","high-trust")))
                                    
  
    # Create a separate data frame with the background colors
  bg_colors <- data.frame(
    from = factor(c("low-trust", "medium-trust", "high-trust"), levels=c("low-trust","medium-trust","high-trust"))
  )
  
  # plotting code...
  ggplot() +
    geom_rect(data = bg_colors, aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, fill = from), alpha = 0.1) +
    geom_line(data = df, aes(x = ret, y = probs, colour = as.factor(to))) +
    facet_wrap(~from, labeller = labeller(from = function(x) paste("From", x, "state on trial t"))) +
    ylim(c(0,1)) +
    scale_fill_manual(values = c("low-trust" = "red", "medium-trust" = "green", "high-trust" = "blue"),
                    name = "From state") +  # Changed legend title for 'fill' here
    scale_color_manual(values = c("low-trust" = "red", "medium-trust" = "green", "high-trust" = "blue"),
                       labels = c("low-trust", "medium-trust", "high-trust"),
                       name = "State transitioned to") +
    labs(x = "Investor's net return on trial t", y = "Transition probability to \nState on trial t+1", color = 'State transitioned to') +
    theme_bw() +
    theme(legend.position = "bottom",
          legend.text = element_text(size = 10),
          legend.key.size = unit(1, 'lines'),
          legend.spacing.x = unit(0.1, 'in'),
          legend.title = element_text(size = 10),
          legend.margin = margin(t = 0.2, b = 0, unit = 'cm'),
          plot.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "cm"),
          strip.text = element_text(size = 10),
          legend.box = "vertical" # Arrange legends vertically
    ) +
    guides(fill = guide_legend(order = 1, title.position = "left", title.hjust = 0.3),
           color = guide_legend(order = 2, title.position = "left", title.hjust = 0.3))
}
```


```{r}

# Parameters for HMM human-like Transition Function
unhappy_pars <- rbind(c(0,0), c(-3.366027, 0.40910797 ), c(-3.572619,0.08137274)) 
neutral_pars <- rbind(c(0,0), c(3.3142637, 0.3763408), c(0.9169736, 0.4502838))
happy_pars   <- rbind(c(0,0), c(0.7134085, 0.02101626), c(2.2215478 ,0.16162964))

pars_inv <- list(unhappy_pars, neutral_pars, happy_pars)
plotInvTran <- plot_HMM_transitions(3, pars_inv) 
print(plotInvTran)


unhappy_pars_vol <- rbind(c(0,0), c(-3.366027, 0.40910797 ), c(-3.572619,0.08137274)) 
neutral_pars_vol <- rbind(c(0,0), c(1.0,0.27), c(-4, 0.75))
happy_pars_vol   <- rbind(c(0,0), c(0.7134085, 0.02101626), c(2.2215478 ,0.16162964))

pars_inv_vol <- list(unhappy_pars_vol, neutral_pars_vol, happy_pars_vol)
plotInvVol <- plot_HMM_transitions(3, pars_inv_vol) 
print(plotInvVol)


```

## Participants


<!-- Load preprocessed data -->
```{r}
final_data <- read_csv("data/final_data.csv")

num_participants <- length(unique(final_data$playerId))
cat("Number of participants: ", num_participants)

# Count D factor groups
d_factor_counts <- final_data %>%
  dplyr::select(playerId, d_level) %>%
  distinct() %>%
  count(d_level) %>%
  print()

# Count order of play (volatile first vs HMM first)
order_counts <- final_data %>%
  dplyr::select(playerId, volatile_first) %>%
  distinct() %>%
  count(volatile_first) %>%
  print()
```



```{r modAllReturns}

final_data <- final_data %>% mutate(ret_pct_na = ifelse(investment==0,NA,return/(3*investment)),
                                    roundPayoff = 3*investment - return,
                                    opponent.f = factor(gameOpponent, levels = c("AI_HMM", "AI_HMM_vol")),
                                    investorState.f = factor(investorState, levels = c("unhappy","neutral","happy")),
                                    d_level = as.factor(d_level),
                                    roundNum = as.numeric(as.character(roundNum)),
                                    inv_scaled = as.vector(scale(investment)),
                                    # Centering the subscales scores for regression analysis
                                    cal_scaled = as.vector(scale(callous_score,scale=FALSE)),
                                    sad_scaled = as.vector(scale(sadism_score,scale=FALSE)),
                                    vin_scaled = as.vector(scale(vindict_score,scale=FALSE)),
                                    dec_scaled = as.vector(scale(deceit_score,scale=FALSE))) %>% 
                             dplyr::select(-c("gameOpponent","investorState"))

# index players
final_data <- final_data %>%
  group_by(playerId) %>%
  mutate(player_index = cur_group_id()) %>%
  ungroup() %>%
  arrange(player_index)


# anonym_data <- final_data %>%  dplyr::select(playerId, gameNum.f,volatile_first, roundNum, investment, return)
# write.csv(anonym_data, "anonym_RTG_data.csv")
```

```{r}
demographics <- read.csv("data/demographic_data.csv")
# demographics - contains demographic data with Participant.id, Age, Sex, etc.
# final_data - contains other data with playerId column

# Extract demographic information for participants in final_data
matching_participants <- demographics[demographics$Participant.id %in% final_data$id, ]

# Select only the relevant columns we need
demographic_subset <- matching_participants[, c("Participant.id", "Age", "Sex", "Country.of.birth", "Ethnicity.simplified")]

# Calculate gender proportions
gender_counts <- table(demographic_subset$Sex)
gender_proportions <- prop.table(gender_counts) * 100

# Calculate mean age
mean_age <- mean(as.numeric(demographic_subset$Age), na.rm = TRUE)
sd_age <- sd(as.numeric(demographic_subset$Age), na.rm = TRUE)

# Print results
print("Gender Distribution:")
print(gender_counts)
print(paste0("Proportion of Male participants: ", round(gender_proportions["Male"], 1), "%"))
print(paste0("Proportion of Female participants: ", round(gender_proportions["Female"], 1), "%"))
print(paste0("Mean age: ", round(mean_age, 1), " years"))
print(paste0("SD age: ", round(sd_age, 1), " years"))

# Optional: Create a bar plot for gender distribution
barplot(gender_counts, main="Gender Distribution", 
        col=c("lightblue", "pink"), 
        ylab="Number of Participants")
```


To have participants with large differences in the D factor of personality, a total of 1243
participants were pre-screened on the Prolific Academic platform
(prolific.co) using the 16 item Dark Factor of Personality Questionnaire (D16) to
finally select two similarly sized groups: One with high D factor scores (90th percentile or higher, D score
\> 42, N=91) and the other with low D factor scores (10th percentile,  score \< 22, N=92)
totalling 183 participants (44% female). These were then invited through
prolific to take part in the main experiment. 

To determine the appropriate sample size, we conducted an a priori power analysis using Monte Carlo simulations with the *simr* package in R. The analysis specifically targeted the three-way interaction between d-score, opponent type (stable vs. volatile), and investment level. Parameters for the simulation were based on previous studies, with an expected effect size of $-0.1$ (correlation between d-score and returns), alpha level of $0.05$, and desired power of $0.90$. Starting with 50 participants, we iteratively generated synthetic data for a task with $25$ rounds per condition and fitted linear mixed-effects models with random intercepts for participants. The simulations incorporated realistic parameter estimates and fixed effects derived from previous research using the same paradigm. This analysis indicated that a sample of 180 participants would provide sufficient power ( more than $90%$) to detect the hypothesized three-way interaction.

```{r}
# Identify ethnic distribution and country of birth from demographics data

# Calculate ethnicity distribution
ethnicity_counts <- table(demographic_subset$Ethnicity.simplified)
ethnicity_percentages <- prop.table(ethnicity_counts) * 100

# Print ethnicity results
print("Ethnicity Distribution:")
print(ethnicity_counts)
print(paste0("Proportion of White participants: ", round(ethnicity_percentages["White"], 1), "%"))

# Assuming there's a column named "Country.of.birth" or similar in your data
# If the column has a different name, replace it accordingly
country_counts <- table(demographic_subset$Country.of.birth)
country_percentages <- prop.table(country_counts) * 100

# Sort countries by frequency in descending order
sorted_countries <- sort(country_counts, decreasing = TRUE)
sorted_percentages <- prop.table(sorted_countries) * 100

# Get number of unique countries
unique_countries <- length(country_counts)

# Print country of birth results
print(paste0("Number of unique countries of birth: ", unique_countries))
print("Top countries of birth:")
for (i in 1:min(5, length(sorted_countries))) {
  country_name <- names(sorted_countries)[i]
  country_percent <- sorted_percentages[country_name]
  print(paste0(country_name, ": ", round(country_percent, 1), "%"))
}

```


The mean age of participants was $33.1$ years, with an $9.7$ years standard deviation. The majority of participants identified ethnically as White ($57$\%). The online cohort registered $38$ unique countries of birth with the most frequent being South Africa ($24$\%), the U.K ($20$\%) followed by Poland ($5$\%) and Greece ($4$\%). Participants were paid a fixed fee of £4 plus a bonus payment dependent on their performance that averaged £$0.5$. Data was collected over multiple sessions between October and November 2024.



\begin{landscape}
```{r combinedPlots,include=F, out.width='1\\linewidth', out.height='1\\textheight', fig.align='center'}
# Ensure necessary packages are loaded
library(ggplot2)
library(patchwork)
library(magick)
library(grid) # Needed for rasterGrob

# --- Your Code to Generate Plots (cleaned) ---

# Parameters for HMM human-like Transition Function
unhappy_pars <- rbind(c(0,0), c(-3.366027, 0.40910797 ), c(-3.572619,0.08137274))
neutral_pars <- rbind(c(0,0), c(3.3142637, 0.3763408), c(0.9169736, 0.4502838))
happy_pars   <- rbind(c(0,0), c(0.7134085, 0.02101626), c(2.2215478 ,0.16162964))

pars_inv <- list(unhappy_pars, neutral_pars, happy_pars)
# Assuming plot_HMM_transitions returns a ggplot object
plotInvTran <- plot_HMM_transitions(3, pars_inv)

# Parameters for Volatile HMM
unhappy_pars_vol <- rbind(c(0,0), c(-3.366027, 0.40910797 ), c(-3.572619,0.08137274))
neutral_pars_vol <- rbind(c(0,0), c(1.0,0.27), c(-4, 0.75))
happy_pars_vol   <- rbind(c(0,0), c(0.7134085, 0.02101626), c(2.2215478 ,0.16162964))

pars_inv_vol <- list(unhappy_pars_vol, neutral_pars_vol, happy_pars_vol)
# Assuming plot_HMM_transitions returns a ggplot object
plotInvVol <- plot_HMM_transitions(3, pars_inv_vol)

# Assuming 'response_probs' dataframe exists in your environment
plotinvHMM <- ggplot(response_probs,
                    aes(x = investment,
                        y = probability,
                        fill = Investor_state)) +
  geom_bar(stat = "identity",
           position = "dodge") +
  labs(fill='Latent investor state', x = "Investment", y= "Probability") +
  theme_bw() +
  theme(legend.position = "bottom", legend.text = element_text(size = 10), legend.title = element_text(size = 10))

# --- Code to Read and Prepare the Image ---

# Define the path to your image file (make sure this path is correct relative to your .Rmd file)
image_path <- "plots/experimentDesign.png"

# Read the image using magick
img <- image_read(image_path)

# Convert the magick image to a raster grob (graphical object)
img_grob <- grid::rasterGrob(img, interpolate=FALSE)

# Wrap the grob so patchwork can use it
img_panel <- wrap_elements(img_grob)

# --- Combine Plots and Image using Patchwork ---

# Arrange in a 2x2 grid:
# ( Plot A + Plot B ) /
# ( Plot C + Image D )
combined_figure <- (img_panel + plotinvHMM) / (plotInvTran + plotInvVol)


# --- Apply Layout Controls and Annotation ---
final_plot <- combined_figure + plot_annotation(tag_levels = 'A') 

# Save the plot with a simple name that avoids underscores
ggsave("figure1.pdf", final_plot, width = 11, height = 8, dpi = 300)
  
```
\end{landscape}


\begin{landscape}
\begin{figure}[htbp]
\centering
\includegraphics[width=\linewidth]{figure1.pdf}
\caption{\small{Panel A: A timeline of the experiment. The RTG is played in dyads, with participants always assigned the role of the trustee and the HMM agent that of the investor. The investor is endowed with 20 units at the start of each round. They need to decide how much of that endowment they want to invest with the trustee. The investment is then multiplied by a factor of 3 and sent to the trustee who needs to decide how much of the multiplied investment they want to send back to the investor. The difference between phases is the type of agents participants are facing. Panels B - C: We construct the artificial investor agent by fitting a three-state hidden Markov model to data of human investors engaged in the 10 round RTG. From the fitted HMM, we get the distribution of investments by the human-like agent, conditional on its latent state as shown in Panel B. The fitted HMM also yields the transition probability of the agent to a state on trial t+1 as a function of the net return (difference between the investment sent and the amount received in return) on trial t as shown in Panel C. Each plot in Panel C represents a different starting latent state on trial t, and each line represents the probability of transitioning to a particular state in trial t+1. Panel D shows the transition probabilities of the volatile HMM agent. Unlike the human-like HMM, the volatile HMM is much more likely to transition out of the mid-trust state. Transitions in the medium and high trust states were identical for both agents.}}
\label{fig:combined}
\end{figure}
\end{landscape}



## Design and Procedure

The experiment employed a 2 (HMM Type: Human-like or Volatile) × 2 (D-Factor: High or Low) mixed design, with repeated measures on the HMM Type factor. Participants were pre-screened using the 16-item Dark Personality Factor Questionnaire, with individuals classified as either High D or Low D. Participants completed two phases of a Repeated Trust Game (RTG), playing 25 rounds in each phase against different Hidden Markov Model (HMM) investors: a "Human-like" HMM and a more "Responsive" Volatile HMM, with the order counterbalanced across participants. After each RTG phase, participants completed investor evaluations. The experiment concluded with a Turing test to assess perceived humanness of the AI partners, open-ended questions about the interaction, and a final debrief. The experimental interface was designed and implemented online using Empirica v1 [@Almaatouq2021], with an estimated completion time of 30 minutes per participant. The study received approval from the University of Heidelberg's Medical Faculty ethics commission (ID:S-708/2023) and the experiment was performed in accordance with the ethics board guidelines and regulations. All participants provided informed consent prior to their participation.


## Tasks and Measures

### Repeated Trust Game and HMM Investor

Participants played a 25-round RTG [@Berg1995] in the trustee
role against a computer-programmed investor. On each round the investor
is endowed with 20 units and decides how much of that endowment to
invest. This investment is tripled and the trustee then decides how to
split this tripled amount between them and the investor. If the trustee
returns more than one third of the amount, the investor makes a gain.
Each player was represented with an icon with the participant always on
the left of the screen and the co-player on the right. The participants
were able to choose the icon that represents them at the start of the
experiment. The icon representing the co-player changed at the start of
each new game, to simulate a new interaction partner. Participants were
not told they were facing computerised co-players. We chose to simulate
the behavior of a human interaction partner through allowing for a delay
whilst pairing with new opponents as the start of each game as well as
programming the agents to respond during each round after a varying time
lapse (randomly chosen between 5 and 10 seconds).

The computerised investor consisted of a hidden Markov model (HMM)
trained on an independent existing behavioral RTG data set of human
investors. This data-driven approach thus sought to learn an investor
strategy that mimics human-like interactions. The data set used for
training consists of 388 ten round games with the same player (full
details can be found in the Supplementary Information). On this data
set, the HMM was inferred with three latent states that could be
interpreted as reflecting a “low-trust”, a “medium-trust”, and a
“high-trust” state. A separate output distribution, that maps each HMM
state onto possible investments from 0 to 20 separately, is learned
(Figure \@ref(fig:HMMPanels).B). In analogy to the latent states, these
distributions can be interpreted as reflecting “low-trust”,
“medium-trust”, or “high-trust” dispositions. Finally, the HMM is
specified by transition probabilities that describe the transition
between states. The probability of these transitions was modelled as a
function of their net return (i.e return - investment) in the previous
round (see Figure \@ref(fig:HMMPanels).C)). The initial state for the
HMM investor in each instance of the game was set to the “mid-trust”
state. Details on how the HMM state conditional probabilities and
transition functions are specified can be found in the supplement.

On all rounds, the investor’s actions were
determined by randomly drawing an investment from the state-conditional
distribution, with the state over rounds determined by randomly drawing
the next state from the state-transition distribution as determined from
the net return on the previous round (disregarding the net return
immediately after the pre-programmed low investment rounds).

### Investor types

In addition to the human-like HMM resulting from fitting to existing datasets of dyadic play 1 , we created a more volatile HMM. This was achieved by adjusting the parameters of the human-like HMM to alter the state transition probabilities. Specifically, the transition probability for remaining in the “medium-trust” state was set to zero when net returns were singificantly non-nil. The resulting transition function is illustrated in Figure @ref(fig:HMMPanels).D. The state-conditional policies and the transition function in the other latent states remained unchanged.


## Procedure

At the start of the experiment, participants provided informed consent
and were instructed the study would consist of three phases in which
they would face a different other player. Participants were told their
goal was to maximise the number of points in all phases. They were not
told the number of rounds of each phase. Participants were randomly
assigned to either face the Human-like of Volatile HMM first. The timeline of
the experiment is shown in Figure \@ref(fig:HMMPanels).A. Game one
consisted of a 25 round RTG in which participants took the role
of trustee, facing the same investor over all 25 rounds. On each round,
after being informed about the amount sent by the investor participants
decided how much of the tripled investment to return to the investor,
before continuing to the next round. Game 2 consisted of the exact same set up 
as in game 1, except for the opponent faced.

At the beginning of each game participants were
told they would face a new player and had to wait to be paired with an
available co-player. This simulated the waiting time in real social
interaction tasks. After completing each RTG in each phase, participants
rated how cooperative and trusting they perceived the co-player to be,
and whether they would like to play with them again (all on a scale from
1 to 10 with 10 being the most positive rating). After completing the
two games, participants were asked whether
they thought the other players were human or computer agents, to probe
how well the agent can mimic human behavior, then asked to describe their 
strategy for both games and finally debriefed and thanked for their participation.


## Statistical Analysis

To test whether participants behaved differently in the RTG depending on their D-factor group and opponent faced, we model the percentage
return (percentage of tripled investment returned to investor) using a linear mixed effects model to participants returns, with Opponent (Human-like vs. Volatile HMM), The order of opponents (Volatile first = True or false), Investment, round number and D-factor (High vs Low D-factor group) as well as their interactions as fixed effects, and player-wise random intercepts and slopes for the Investment variable. The full specification of the statistical model can be found in the supplement. 

The model was estimated using the `afex` package [@Singmann2022]
in R. More complex models with additional random effects could not be
estimated reliably, and as such the estimated model can be considered to
include the optimal random effects structure
[@Matuschek2017]. A similar process was used to establish the
random effects structures of linear mixed-effects models used to analyse
the HMM agent investments as well as the participants' ratings of the
co-players. There is no agreed upon way to calculate effect sizes for
mixed effects models. Instead, we will report on testing differences in
marginal means. For the $F$-tests, we used the Kenward-Roger
approximation to the degrees of freedom, as implemented in the R package
"afex". We Z-transform the Investment variable (subtract the overall
investment mean and divide by overall standard deviation) as centering
is beneficial to interpreting the main effects more easily in the
presence of interactions. To probe significant interactions, we
conducted planned contrasts using the `emmeans` package in R. Given that
we were testing multiple pre-planned comparisons, we applied the "Sidak"
correction to control for familywise error rate while maintaining
reasonable statistical power. This approach allowed us to investigate
specific hypotheses about the differential effects of our manipulation
across phases and DFP groups, while protecting against inflated Type I
error rates.


# Results


<!-- ### Distribution of D factor and its subscales scores:  -->

```{r}
library(stringr)
create_distribution_plot <- function(data, column_name) {
  # Convert column name to symbol for evaluation
  col_sym <- sym(column_name)
  
  # Calculate statistics
  mean_val <- mean(pull(data, !!col_sym), na.rm = TRUE)
  sd_val <- sd(pull(data, !!col_sym), na.rm = TRUE)
  n_val <- nrow(data)
  
  # Get column range for x-axis breaks
  col_min <- floor(min(pull(data, !!col_sym), na.rm = TRUE))
  col_max <- ceiling(max(pull(data, !!col_sym), na.rm = TRUE))
  break_seq <- seq(col_min, col_max, by = 2)
  
  # Create the plot
  p <- ggplot(data, aes(x = !!col_sym)) +
    # Add histogram
    geom_histogram(aes(y = after_stat(density)), 
                  binwidth = 2, 
                  fill = "lightblue", 
                  color = "black", 
                  alpha = 0.7) +
    # Add density curve
    geom_density(color = "darkred", size = 1) +
    # Add mean line
    geom_vline(aes(xintercept = mean_val), 
               color = "darkred", 
               linetype = "dashed", 
               size = 1) +
    # Customize theme and labels
    theme_minimal() +
    labs(
      title = paste("Distribution of", gsub("_", " ", column_name)),
      subtitle = sprintf("Mean = %.2f, SD = %.2f, N = %d", 
                        mean_val, sd_val, n_val),
      x = gsub("_", " ", str_to_title(column_name)),
      y = "Density"
    ) +
    # Basic theme customization
    theme(
      plot.title = element_text(face = "bold", size = 14),
      plot.subtitle = element_text(size = 11),
      panel.grid.minor = element_blank()
    ) +
    # Set x-axis breaks
    scale_x_continuous(breaks = break_seq)
  
  return(p)
}

```

```{r}
# For your original example
plot_total <- create_distribution_plot(final_data, "total_score")
print(plot_total)
```


```{r}
# For your original example
plot_vin <- create_distribution_plot(final_data, "vindict_score")
print(plot_vin)
```

```{r}
# For your original example
plot_dec <- create_distribution_plot(final_data, "deceit_score")
print(plot_dec)
```

```{r}
# For your original example
plot_cal <- create_distribution_plot(final_data, "callous_score")
print(plot_cal)
```

```{r}
# For your original example
plot_sad <- create_distribution_plot(final_data, "sadism_score")
print(plot_sad)
```







```{r}
# correlate d_levels and other subscores 
sub_scores <- final_data %>% group_by(d_level) %>% summarise (mean_cal = mean(callous_score),
                                                mean_dec = mean(deceit_score),
                                                mean_sad = mean(sadism_score),
                                                mean_vin = mean(vindict_score))

sub_scores
```

### Mean investment and return per round



```{r}
library(dplyr)
library(tidyr)
library(lme4)
library(broom.mixed)
library(ggplot2)

# 1. Overall differences between high and low D-factor participants
summary_stats <- final_data %>%
  group_by(d_level) %>%
  summarise(
    mean_investment = mean(investment, na.rm = TRUE),
    sd_investment = sd(investment, na.rm = TRUE),
    mean_return = mean(return, na.rm = TRUE),
    sd_return = sd(return, na.rm = TRUE),
    mean_return_pct = mean(return_pct, na.rm = TRUE),
    sd_return_pct = sd(return_pct, na.rm = TRUE),
    n = n()
  )

print("Overall Summary Statistics by D-factor Level:")
print(summary_stats)

# Simple t-tests for overall differences
t_test_investment <- t.test(investment ~ d_level, data = final_data)
t_test_return <- t.test(return ~ d_level, data = final_data)
t_test_return_pct <- t.test(return_pct ~ d_level, data = final_data)

print("T-test for Investment by D-factor:")
print(t_test_investment)

print("T-test for Return by D-factor:")
print(t_test_return)

print("T-test for Return Percentage by D-factor:")
print(t_test_return_pct)

```

```{r}
library(lme4)
library(lmerTest)
library(emmeans)


# Test if differences increase in later rounds
# Create early vs late game periods (excluding end-game)
final_data <- final_data %>%
  mutate(game_period = case_when(
    roundNum <= 8 ~ "early",
    roundNum > 8 & roundNum <= 16 ~ "mid",
    roundNum > 16 ~ "late"
  ))



# Create factor variables 
final_data$game_period <- factor(final_data$game_period, levels = c("early", "mid", "late"))
final_data$d_level <- factor(final_data$d_level)

# Remove last round as it is a different game: 

data24 <- final_data %>% filter (roundNum < 25)

# For HMM investments
investment_means <- data24 %>%
  group_by(d_level, game_period) %>%
  summarize(
    mean_investment = mean(investment, na.rm = TRUE),
    sd_investment = sd(investment, na.rm = TRUE),
    n = n(),
    se_investment = sd_investment / sqrt(n)
  )

# For absolute returns
return_means <- data24 %>%
  group_by(d_level, game_period) %>%
  summarize(
    mean_return = mean(return, na.rm = TRUE),
    sd_return = sd(return, na.rm = TRUE),
    n = n(),
    se_return = sd_return / sqrt(n)
  )

# For percentage returns
pct_return_means <- data24 %>%
  group_by(d_level, game_period) %>%
  summarize(
    mean_pct_return = mean(return_pct, na.rm = TRUE),
    sd_pct_return = sd(return_pct, na.rm = TRUE),
    n = n(),
    se_pct_return = sd_pct_return / sqrt(n)
  )

# T-tests for each period
t_test_results <- list()
for(period in c("early", "mid", "late")) {
  # Investment t-test
  inv_data <- data24 %>% filter(game_period == period)
  t_inv <- t.test(investment ~ d_level, data = inv_data)
  
  # Return t-test
  ret_data <- data24 %>% filter(game_period == period)
  t_ret <- t.test(return ~ d_level, data = ret_data)
  
  # Percent return t-test
  pct_data <- data24 %>% filter(game_period == period)
  t_pct <- t.test(return_pct ~ d_level, data = pct_data)
  
  t_test_results[[period]] <- list(
    investment = t_inv,
    return = t_ret,
    pct_return = t_pct
  )
}

# Print results
print(investment_means)
print(return_means)
print(pct_return_means)
print(t_test_results)

```





On average, investments and returns, as shown in Figure \@ref(fig:XXXX), fell within the documented range of 40-60% of the endowment for investments and 35-50% of the total yield for returns, as reported in previous studies [@Charness2008; @Fiedler2011].


Comparing high versus low D-factor participants across all rounds, we observed several behavioral differences. High D-factor participants received lower investments (`r papaja::apa_print(t_test_investment)$statistic`) and consistently returned less money to investors (`r papaja::apa_print(t_test_return)$statistic`). The difference in return percentage was statistically significant (`r papaja::apa_print(t_test_return_pct)$statistic`), with high D-factor participants returning approximately 2-4 percentage points less of the tripled investment. 


We then examined differences in trust game behavior between participants with high and low Dark Factor of Personality (D-factor) scores across three game periods: early (rounds 1-8), mid (rounds 9-16), and late (rounds 17+ excluding the alst round). We compared HMM investments, absolute returns, and percentage returns between the two groups using Welch's t-tests. We excluded the last round and analysed that data separately as participants were told it was the last interaction in that round. 

Whilst there were no significant difference in investment received and percentage returns sent by the participants  between high_D and low_D groups during early and mid periods, significant differences emerged for all three measures during the late period. The HMM invested significantly *less* in high_D participants than low_D participants (`r sprintf("t(%1.2f) = %1.2f, p = %1.3e", t_test_results$late$investment$parameter, t_test_results$late$investment$statistic, t_test_results$late$investment$p.value)`). Furthermore, high_D participants sent back significantly lower absolute returns (`r sprintf("t(%1.2f) = %1.2f, p = %1.3e", t_test_results$late$return$parameter, t_test_results$late$return$statistic, t_test_results$late$return$p.value)`) and lower percentage returns (`r sprintf("t(%1.2f) = %1.2f, p = %1.3e", t_test_results$late$pct_return$parameter, t_test_results$late$pct_return$statistic, t_test_results$late$pct_return$p.value)`) compared to low_D participants.













```{r, include=T}
library(dplyr)
library(ggplot2)
library(tidyr)

# Calculate percentage return and add game period
data_with_pct <- data24 %>%
  mutate(
    return_pct = return / (3 * investment),
    # Categorize rounds into early, middle, and late periods
    game_period = case_when(
      roundNum <= 8 ~ "Early\n(1-8)",
      roundNum > 8 & roundNum <= 16 ~ "Middle\n(9-16)",
      roundNum > 16 ~ "Late\n(17-25)"
    ),
    # Convert to factor to preserve order
    game_period = factor(game_period, levels = c("Early\n(1-8)", "Middle\n(9-16)", "Late\n(17-25)"))
  )

# Calculate aggregated statistics for each period
period_stats <- data_with_pct %>%
  group_by(d_level, game_period) %>%
  summarise(
    mean_return_pct = mean(return_pct, na.rm = TRUE),
    se_return_pct = sd(return_pct, na.rm = TRUE) / sqrt(n()),
    .groups = 'drop'
  )

# Calculate differences for annotations
diff_stats <- period_stats %>%
  pivot_wider(
    id_cols = game_period,
    names_from = d_level,
    values_from = c(mean_return_pct, se_return_pct)
  ) %>%
  mutate(
    diff_value = mean_return_pct_low_D - mean_return_pct_high_D
  )

# Define improved colors with better contrast
high_d_color <- "#E64B35"  # red
low_d_color <- "#4DBBD5"   # blue

# Create connected scatter plot with enhanced annotations
ggplot() +
  # Add connecting lines between points
  geom_line(data = period_stats, 
            aes(x = game_period, y = mean_return_pct, 
                color = d_level, group = d_level),
            size = 1.5) +

  # Add error bars
  geom_errorbar(data = period_stats,
                aes(x = game_period, 
                    ymin = mean_return_pct - se_return_pct, 
                    ymax = mean_return_pct + se_return_pct,
                    color = d_level),
                width = 0.25, size = 0.8) +
  scale_color_manual(values = c("low_D" = low_d_color, "high_D" = high_d_color),
                    labels = c("low_D" = "Low D-factor", "high_D" = "High D-factor")) +
  scale_shape_manual(values = c("low_D" = 16, "high_D" = 17),
                    labels = c("low_D" = "Low D-factor", "high_D" = "High D-factor")) +
  # Set y-axis limits to make differences visible
  scale_y_continuous(limits = c(0.41, 0.5), 
                     breaks = seq(0.41, 0.49, 0.02)) +
  # Labels
  labs(
    x = NULL,
    y = "Return Percentage (of 3x investment)",
    color = "D-factor Level",
    shape = "D-factor Level"
  ) +
  # Theme
  theme_minimal() +
  theme(
    legend.position = "bottom",
    panel.grid.major.y = element_line(color = "gray90"),
    panel.grid.minor.y = element_blank(),
    panel.grid.major.x = element_blank(),
    axis.title.y = element_text(face = "bold", size = 12),
    axis.text = element_text(size = 11),
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11, face = "italic"),
    legend.title = element_text(face = "bold", size = 11),
    legend.text = element_text(size = 10)
  )
```





<!-- ### Last round analysis  -->



```{r}
# Get last round returns
last_round_data <- final_data %>%
  filter(isLastRound == TRUE) %>%
  dplyr::select(playerId, d_level, callous_score, deceit_score, sadism_score, vindict_score,  investment,return, return_pct)

# Calculate means by D-factor group
means <- last_round_data %>%
  group_by(d_level) %>%
  summarise(
    n = n(),
    mean_return = mean(return),
    sd_return = sd(return)
  )
print("Means by D-factor group:")
print(means)


# For absolute returns
t.test(return ~ d_level, data = last_round_data)

# For return percentages
t.test(return_pct ~ d_level, data = last_round_data)

# Mann-Whitney U tests (non-parametric alternative)
# For absolute returns
wilcox.test(return ~ d_level, data = last_round_data)

# For return percentages
 wilcox.test(return_pct ~ d_level, data = last_round_data)
 

```

### Last Round Analysis

We conducted a separate analysis focusing solely on the final round of each game, where participants knew there would be no further interactions. This allows us to examine behavior in a context resembling a dictator game. We compared absolute returns and percentage returns between high_D and low_D groups. We used both Welch's t-tests and Wilcoxon rank-sum tests (also known as Mann-Whitney U tests). The Wilcoxon test is a non-parametric test that does not assume normality, making it a more robust choice if the data are not normally distributed, which is often the case with economic game data, especially in smaller samples or with outliers.

In the last round, high_D participants sent back significantly lower absolute returns than low_D participants (`r sprintf("t(%1.2f) = %1.2f, p = %1.3f", t.test(return ~ d_level, data = last_round_data)$parameter, t.test(return ~ d_level, data = last_round_data)$statistic, t.test(return ~ d_level, data = last_round_data)$p.value)`); `r sprintf("Wilcoxon W = %1.0f, p = %1.3f", wilcox.test(return ~ d_level, data = last_round_data)$statistic, wilcox.test(return ~ d_level, data = last_round_data)$p.value)`). Similarly, high_D participants sent back a significantly lower percentage of the tripled investment (`r sprintf("t(%1.2f) = %1.2f, p = %1.3f", t.test(return_pct ~ d_level, data = last_round_data)$parameter, t.test(return_pct ~ d_level, data = last_round_data)$statistic, t.test(return_pct ~ d_level, data = last_round_data)$p.value)`); `r sprintf("Wilcoxon W = %1.0f, p = %1.3f", wilcox.test(return_pct ~ d_level, data = last_round_data)$statistic, wilcox.test(return_pct ~ d_level, data = last_round_data)$p.value)`). Both parametric (t-test) and non parametric tests (Wilcoxon) show significant differences.

<!-- ### proportion of states by round and opponent  -->
```{r}
# Calculate proportions of states for each round and opponent
state_props <- final_data %>%
  group_by(opponent.f, roundNum, investorState.f, d_level) %>%
  summarise(count = n(), .groups = 'drop') %>%
  group_by(opponent.f, roundNum) %>%
  mutate(proportion = count / sum(count))

# Create stacked bar plot
ggplot(state_props, aes(x = roundNum, y = proportion, fill = investorState.f)) +
  geom_bar(stat = "identity") +
  facet_wrap(~opponent.f*d_level) +
  scale_fill_manual(values = c("unhappy" = "red", "neutral" = "green", "happy" = "blue")) +
  labs(x = "Round Number", 
       y = "Proportion",
       title = "Distribution of Investor States by Round and Opponent Type",
       fill = "Investor State") +
  theme_minimal()
```

### Total Payoff Analysis


```{r}
# Reshape data to get one row per game per participant
payoff_data <- final_data  %>%
  dplyr::select(playerId, d_level,cal_scaled, dec_scaled, sad_scaled, vin_scaled, opponent.f, gameNum.f, volatile_first, payoffTrust1, payoffTrust2,) %>%
  distinct() %>%
   mutate(
      payoff = case_when(
        gameNum.f == "first game" ~ payoffTrust1,
        gameNum.f == "second game" ~ payoffTrust2
      )
    ) %>%
    dplyr::select(-payoffTrust1, -payoffTrust2)  # Remove unused columns


# Calculate total payoff per participant
total_payoffs <- payoff_data %>%
  group_by(playerId, d_level) %>%
  summarise(total_payoff = sum(payoff, na.rm = TRUE))

# T-test
t_test_payoff <- t.test(total_payoff ~ d_level, data = total_payoffs)

# Wilcoxon test
wilcoxon_test_payoff <- wilcox.test(total_payoff ~ d_level, data = total_payoffs)
```




Finally, we analyzed the total payoffs earned by participants across both games, comparing high_D and low_D individuals. This analysis aimed to determine whether differences in strategy observed during the game (particularly in the later periods) translated into overall differences in earnings. We used a Welch's t-test and a Wilcoxon rank-sum test.

The results showed no significant difference in total payoffs between high_D and low_D participants (`r sprintf("t(%1.2f) = %1.2f, p = %1.3f", t_test_payoff$parameter, t_test_payoff$statistic, t_test_payoff$p.value)`; `r sprintf("Wilcoxon W = %1.0f, p = %1.3f", wilcoxon_test_payoff$statistic, wilcoxon_test_payoff$p.value)`).

Although high-D participants sent back lower returns in the late period of the trust game, their total accumulated payoff across all rounds was not significantly different from that of low-D participants.  This seemingly paradoxical result can be explained by the adaptive behavior of the HMM opponent.  While high-D individuals adopted a less cooperative strategy in later rounds, keeping a larger portion of the returns for themselves, the HMM responded by reducing its investments in these individuals.  Therefore, the higher proportion kept by high-D participants was offset by a reduction in the amount they received, leading to similar overall earnings compared to the more cooperative low-D participants.


<!-- #### Payoff regression with sub-scales of D factor -->

```{r}
mod_payoffs_cal <- mixed( payoff ~ opponent.f*cal_scaled*volatile_first + (1| playerId), payoff_data, REML= TRUE, method="KR")
anova(mod_payoffs_cal)

mod_payoffs_sad <- mixed( payoff ~ opponent.f*sad_scaled*volatile_first + (1| playerId), payoff_data, REML= TRUE, method="KR")
anova(mod_payoffs_sad)

mod_payoffs_dec <- mixed( payoff ~ opponent.f*dec_scaled*volatile_first + (1| playerId), payoff_data, REML= TRUE, method="KR")
anova(mod_payoffs_dec)

mod_payoffs_vin <- mixed( payoff ~ opponent.f*vin_scaled*volatile_first + (1| playerId), payoff_data, REML= TRUE, method="KR")
anova(mod_payoffs_vin)


```

```{r}
# Split data by opponent type and run correlation between vin_scaled and payoff
by(payoff_data, payoff_data$opponent.f, function(x) {
    cor.test(x$vin_scaled, x$payoff)
})

# Create simple scatter plots
library(ggplot2)
ggplot(payoff_data, aes(x = vin_scaled, y = payoff, color = opponent.f)) +
    geom_point() +
    geom_smooth(method = "lm") +
    facet_wrap(~opponent.f)
```

```{r}
# For simple slopes analysis for interaction between vindictiveness and Opponent type 
library(emmeans)

# Get marginal means at ±1 SD of vindictiveness for each opponent
emm <- emmeans(mod_payoffs_vin, 
               ~ opponent.f | vin_scaled, 
               at = list(vin_scaled = c(-1, 0, 1)))  # -1/+1 SD and mean
pairs(emm)

# Look at opponent effect at different levels of vindictiveness
emm_slopes <- emtrends(mod_payoffs_vin, 
                       ~ opponent.f, 
                       var = "vin_scaled")
pairs(emm_slopes)
```

## Round by round analysis 

```{r lmem, cache=T}
# Maximal random effect structure
mod_return_pct <- afex::mixed(ret_pct_na ~ opponent.f*inv_scaled*d_level*volatile_first*roundNum + 
      (1 + opponent.f + inv_scaled | playerId), 
      data = data24, 
      REML = TRUE, 
      method = "KR")

anova(mod_return_pct)

```


To analyse participants behavior on a round by round basis, we look at the fit results from the linear mixed effects model of participant percentage returns detailed in the methods section.



#### Main effects

We found a significant main effect of investment amount (`r papaja::apa_print(mod_return_pct)$full_result$inv_scaled`), with participants returning higher percentages when they received larger investments, demonstrating positive reciprocity. We also found a significant main effect of round number (`r papaja::apa_print(mod_return_pct)$full_result$roundNum`), showing that return percentages generally decreased over time as the game progressed.


#### D-Factor by Round Number interaction

```{r}
# Analyze slope differences by D-factor level
d_level_trends <- emmeans::emtrends(mod_return_pct, ~ d_level, var = "roundNum")
d_level_trends_test <- summary(d_level_trends)
d_level_trends_contrast <- contrast(d_level_trends, "pairwise")

d_level_trends 
d_level_trends_test 
d_level_trends_contrast 

# Generate predicted data for plotting
round_range <- 1:24
c<- emmeans::emmip(
  mod_return_pct,
  d_level ~ roundNum,
  at = list(roundNum = round_range),
  type = "response",
  CIs = TRUE,
  plotit = FALSE
)

```

```{r}
# Generate predictions across a range of roundNum values, say from 1 to 24
#   (the length of your experiment). You can vary this sequence as needed.
round_range <- 1:24

# We use emmip to predict how ret_pct_na changes over roundNum by d_level
plot_data <- emmip(
  mod_return_pct,
  d_level ~ roundNum,
  at = list(roundNum = round_range),
  type = "response",   # 'response' will back-transform if link functions are involved
  CIs = TRUE,
  plotit = FALSE
)

# Inspect the data frame of predicted values
head(plot_data)

# Now, plot using ggplot2
ggplot(plot_data, aes(x = roundNum, y = yvar, color = d_level, group = d_level)) +
  geom_line(size = 1.2) +
  geom_ribbon(aes(ymin = LCL, ymax = UCL, fill = d_level),
              alpha = 0.2, color = NA) +
  labs(
    x = "Round Number",
    y = "Predicted Return Proportion",
    color = "D-level",
    fill = "D-level",
    title = "Effect of Round Number by D-level on Return Proportion"
  ) +
  theme_minimal(base_size = 14)

```
We found a significant interaction between D-factor and round number (`r papaja::apa_print(mod_return_pct)$full_result$d_level_roundNum`). Participants with high D-factor scores demonstrated a significant negative slope in their return proportions as the game progressed, indicating a systematic decrease in reciprocity over time (slope = `r sprintf("%.4f", d_level_trends_test$roundNum.trend[1])`, 95% CI [`r sprintf("%.4f", d_level_trends_test$asymp.LCL[1])`, `r sprintf("%.4f", d_level_trends_test$asymp.UCL[1])`]). In contrast, participants with low D-factor scores maintained relatively stable return rates across rounds, with a slope not significantly different from zero. The difference between these slopes was statistically significant (`r sprintf("z = %.2f, p = %.3f", summary(d_level_trends_contrast)$z.ratio, summary(d_level_trends_contrast)$p.value)`).


#### Opponent Type, Investment, and D-factor Interaction

```{r}
# Get the investment slopes for each combination
slopes <- emtrends(mod_return_pct, 
                  ~ d_level*opponent.f, 
                  var = "inv_scaled")

# Convert to data frame to get the slope values
slope_data <- as.data.frame(slopes)

# Create sequence of investment values
inv_range <- seq(-2, 2, by = 0.1)
predicted_data <- expand.grid(
  inv_scaled = inv_range,
  d_level = levels(slope_data$d_level),
  opponent.f = levels(slope_data$opponent.f)
)

# Join the slopes with the predicted data and calculate return rates
predicted_data <- predicted_data %>%
  left_join(
    slope_data %>% 
      dplyr::select(d_level, opponent.f, inv_scaled.trend),
    by = c("d_level", "opponent.f")
  ) %>%
  mutate(
    # Using 0.3 as intercept like in original code, but you might want to extract this from model too
    return_rate = 0.3 + (inv_scaled.trend * inv_scaled)
  )

# Create the plot
ggplot(predicted_data, aes(x = inv_scaled, y = return_rate, 
                          color = d_level, linetype = opponent.f)) +
  geom_line(size = 1) +
  scale_color_manual(values = c("high_D" = "red", "low_D" = "blue"),
                    labels = c("High D", "Low D")) +
  scale_linetype_manual(values = c("solid", "dashed"),
                       labels = c("Stable", "Volatile")) +
  labs(x = "Investment (standardized)",
       y = "Return Rate",
       color = "D-Level",
       linetype = "Opponent Type",
       title = "Investment-Return Slopes by D-Level and Opponent Type") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

```{r emtrends_calcs, include=FALSE}
library(emmeans)
# Get the slopes (effects of investment) for each combination
slopes <- emtrends(mod_return_pct, ~ opponent.f * d_level, var = "inv_scaled")
slopes_summary <- summary(slopes, infer = TRUE)
slopes_summary 

# # Define the contrasts
# contrasts <- list(
#   "Investment effect: High vs Low D in Human-like HMM" = c(-1, 1, 0, 0),
#   "Investment effect: High vs Low D in Volatile HMM" = c(0, 0, -1, 1),
#   "Opponent effect: Human vs Volatile in Low D" = c(-1, 0, 1, 0),
#   "Opponent effect: Human vs Volatile in High D" = c(0, -1, 0, 1)
# )
# 
# # Test the contrasts with multiple comparison correction
# results_3w <- contrast(slopes, method = contrasts, adjust = "sidak")
# results_3w
```



<!-- Participants with low D-factor scores showed significant positive reciprocity with both opponent types, as indicated by positive slopes with confidence intervals that do not include zero. For these participants, a one-unit increase in investment was associated with an increase in return percentage of approximately $2.0%$  when facing the human-like HMM opponent and $3.1%$ when facing the volatile HMM opponent. In contrast, participants with high D-factor scores did not show significant reciprocity with either opponent type, as their confidence intervals include zero. This suggests that high D-factor participants' return decisions were less influenced by the magnitude of investment they received. -->



<!-- Analysis of the interaction between opponent type, investment, and D-factor revealed differing reciprocity patterns. We used `emtrends` to calculate simple slopes of return percentage on investment for each opponent type and D-factor group. -->

Low D-factor participants showed significant positive reciprocity with both opponents: a one-unit increase in investment led to a significant increase in return percentage for both the human-like HMM (`r sprintf("%.1f%%", 100*slopes_summary$inv_scaled.trend[3])``r ifelse(slopes_summary$p.value[3] < 0.001, "***", ifelse(slopes_summary$p.value[3] < 0.01, "**", ifelse(slopes_summary$p.value[3] < 0.05, "*", "")))`, *p* = `r sprintf("%.3f", slopes_summary$p.value[3])`) and the volatile HMM (`r sprintf("%.1f%%", 100*slopes_summary$inv_scaled.trend[4])``r ifelse(slopes_summary$p.value[4] < 0.001, "***", ifelse(slopes_summary$p.value[4] < 0.01, "**", ifelse(slopes_summary$p.value[4] < 0.05, "*", "")))`, *p* = `r sprintf("%.3f", slopes_summary$p.value[4])`).

In contrast, high D-factor participants did *not* show significant reciprocity with either the human-like HMM (slope = `r sprintf("%.3f", slopes_summary$inv_scaled.trend[1])`, *p* = `r sprintf("%.3f", slopes_summary$p.value[1])`) or the volatile HMM (slope = `r sprintf("%.3f", slopes_summary$inv_scaled.trend[2])`, *p* = `r sprintf("%.3f", slopes_summary$p.value[2])`), indicating their returns were less influenced by investment amount.





<!-- Low D individuals show significant reciprocity (positive slopes) with both opponents. Low D individuals show stronger reciprocity with the volatile opponent -->

<!-- High D individuals show no significant reciprocity with either opponent type -->

<!-- The largest difference in reciprocity is between high and low D individuals when facing the volatile opponent -->

<!-- This suggests that Low D individuals are more responsive to the level of investment they receive, especially in volatile interactions, while High D individuals maintain more stable return rates regardless of investment received. This could indicate that High D individuals are less influenced by their partner's behavior, while Low D individuals adjust their behavior more in response to their partner's actions. -->


```{r}
# Define a range of 'inv_scaled' values.
inv_seq <- seq(-1.5, 1.5, by = 0.1)

# Pick a mid-round value (e.g., round = 12 or the mean), 
# and hold volatile_first to a single level if appropriate.
plot_data <- emmip(
  mod_return_pct,
  # Formula: "opponent.f ~ inv_scaled | d_level" means:
  #   - x-axis will be inv_scaled
  #   - lines will be opponent.f
  #   - separate facets for d_level
  opponent.f ~ inv_scaled | d_level,  
  at = list(inv_scaled = inv_seq,
            roundNum   = 12,        
            volatile_first = FALSE),  
  type = "response",  # get predictions on the original scale (ret_pct_na proportion)
  CIs = TRUE,         # get confidence intervals
  plotit = FALSE      # return data instead of plotting
)

# Inspect the first few rows
head(plot_data)

```

```{r}
ggplot(plot_data, aes(x = inv_scaled, y = yvar,
                      color = opponent.f, group = opponent.f)) +
  # Add a line for each level of opponent.f
  geom_line(size = 1.2) +
  # Add ribbons for CI 
  geom_ribbon(
    aes(ymin = LCL, ymax = UCL, fill = opponent.f),
    alpha = 0.15, color = NA
  ) +
  # Facet by d_level (High vs. Low)
  facet_wrap(~ d_level) +
  labs(
    x = "Scaled Investment (inv_scaled)",
    y = "Predicted Return Proportion",
    color = "Opponent",
    fill  = "Opponent",
    title = "Opponent x Investment x D-level Interaction"
  ) +
  theme_minimal(base_size = 14)

```

```{r}
# Obtain the slopes for inv_scaled for each combination of opponent.f and d_level
inv_slopes <- emtrends(
  mod_return_pct,
  pairwise ~ opponent.f * d_level,  # or simply ~ opponent.f:d_level
  var = "inv_scaled",
  adjust = "tukey"  # or "tukey", "fdr", "none", etc.
)

# Show summary of slopes for each condition
summary(inv_slopes$emtrends)

# Show pairwise tests among those slopes (with chosen correction)
inv_slopes$contrasts

```


#### Four-Way Interaction: Opponent, Investment, D-factor, and Round Number



```{r}
# Look at investment slopes at different time points
emtrends(mod_return_pct, 
         ~ d_level*opponent.f, 
         var = "inv_scaled",
         at = list(roundNum = seq(1, 20, by = 5)))  # Examine trend across multiple rounds
```

```{r}
# Look at round slopes at different investment levels
# Get slopes at different investment levels
emtrends(mod_return_pct, 
         ~ d_level*opponent.f*inv_scaled, 
         var = "roundNum",
         at = list(inv_scaled = c(-1, 0, 1)))
```

```{r}
# Test whether slopes differ between investment levels
emtrends_round <- emtrends(mod_return_pct, 
         pairwise ~ inv_scaled | d_level*opponent.f, 
         var = "roundNum",
         at = list(inv_scaled = c(-1, 0, 1)))

emtrends_round 

relevant_contrast <- summary(emtrends_round$contrasts, infer = TRUE)[1,]
relevant_contrast

# Get the slopes and CIs for high-D, human-like, high and low investment
high_d_human_slopes <- summary(emtrends_round$emtrends, infer = TRUE)
high_d_human_high_inv <- high_d_human_slopes[3,] #high inv
high_d_human_low_inv <- high_d_human_slopes[1,] #low inv

```


```{r}
# Get the emtrends results
trends <- emtrends(mod_return_pct, 
                  ~ d_level*opponent.f*inv_scaled, 
                  var = "roundNum",
                  at = list(inv_scaled = c(-1, 0, 1)))

# Convert to data frame and organize
trend_data <- as.data.frame(trends) %>%
  mutate(
    d_level = factor(d_level),
    opponent = opponent.f,
    inv_level = factor(case_when(
      inv_scaled == -1 ~ "Low (-1 SD)",
      inv_scaled == 0 ~ "Medium (0)",
      inv_scaled == 1 ~ "High (+1 SD)"
    ), levels = c("Low (-1 SD)", "Medium (0)", "High (+1 SD)")),
    lower = roundNum.trend - (1.96 * SE),
    upper = roundNum.trend + (1.96 * SE)
  ) %>%
  rename(slope = roundNum.trend)


```

```{r, include=T, fig.pos='H', fig.cap="Averages and standard errors of thange in returns per round of...",fig.align="center", fig.width=10, fig.height = 6}
# Create plot
ggplot(trend_data, aes(x = inv_level, y = slope, fill = opponent)) +
  geom_bar(stat = "identity", position = position_dodge(), alpha = 0.7) +
  geom_errorbar(aes(ymin = lower, ymax = upper), 
                position = position_dodge(width = 0.9),
                width = 0.2) +
  facet_wrap(~d_level) +
  scale_fill_manual(values = c("AI_HMM" = "blue", "AI_HMM_vol" = "red")) +
  labs(x = "Investment Level",
       y = "Change in Return Rate per Round",
       fill = "Opponent Type",
       title = "Learning Trends by Investment Level and Opponent Type") +
  theme_minimal() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 45, hjust = 1))
```

Analysis of the significant four-way interaction (`r papaja::apa_print(mod_return_pct)$full_result$opponent_f_inv_scaled_d_level_roundNum`) revealed that only high D-factor participants facing the human-like opponent showed investment-dependent changes in behavior across rounds (`r sprintf("p = %.3f", relevant_contrast$p.value)`). For these participants, returns decreased significantly across rounds with high investments (slope = `r sprintf("%.5f", high_d_human_high_inv$roundNum.trend)`, 95% CI [`r sprintf("%.5f", high_d_human_high_inv$asymp.LCL)`, `r sprintf("%.5f", high_d_human_high_inv$asymp.UCL)`]), but remained stable with low investments (slope = `r sprintf("%.5f", high_d_human_low_inv$roundNum.trend)`, 95% CI [`r sprintf("%.5f", high_d_human_low_inv$asymp.LCL)`, `r sprintf("%.5f", high_d_human_low_inv$asymp.UCL)`]), a significant difference in slopes (`r sprintf("p = %.3f", relevant_contrast$p.value)`).

Neither low D-factor participants nor high D-factor participants facing the volatile opponent showed this strategic pattern. This suggests high D-factor participants specifically exploit predictable opponents by systematically reducing reciprocity over time on high-investment trials.

<!-- #### Investment by order by d_level by rounNumber  interaction -->


<!-- The significant four-way interaction between investment, order, D-factor, and round number (`r papaja::apa_print(mod_return_pct)$full_result$inv_scaled_d_level_volatile_first_roundNum`) revealed that investment level moderated how participants' return behavior changed over rounds, with patterns differing by D-factor and order condition. -->

<!-- High D-factor participants who faced the stable opponent first showed a strategic pattern: they significantly decreased returns over rounds for high investments ($p < .0001$) and medium investments ($p = .0001$), but not for low investments ($p = .84$). This suggests calculated exploitation specifically targeting more exploitable partners. In contrast, high D-factor participants who faced the volatile opponent first showed the opposite pattern: significant decreases for low investments ($p = .007$) and medium investments ($p = .007$), but not for high investments ($p = .63$). -->

<!-- Low D-factor participants displayed fundamentally different behavior:  they showed no significant changes in returns across investments.  -->

```{r}
# Get slopes across finer gradient of investment values
trends_continuous <- emtrends(mod_return_pct, 
                            ~ d_level*volatile_first*inv_scaled, 
                            var = "roundNum",
                            at = list(inv_scaled = seq(-1, 1, by = 0.1)))

# Convert to data frame for plotting
trend_data <- as.data.frame(trends_continuous) %>%
  mutate(
    d_level = factor(d_level),
    volatile_first = factor(volatile_first, labels = c("Stable First", "Volatile First")),
    lower = roundNum.trend - (1.96 * SE),
    upper = roundNum.trend + (1.96 * SE)
  )


```

```{r, include=T}
# Create plot
ggplot(trend_data, aes(x = inv_scaled, y = roundNum.trend, color = volatile_first)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = lower, ymax = upper, fill = volatile_first), alpha = 0.2) +
  facet_wrap(~d_level) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  scale_color_manual(values = c("darkgreen", "orange")) +
  scale_fill_manual(values = c("darkgreen", "orange")) +
  labs(x = "Investment Level (Standardized)",
       y = "Change in Return Rate per Round",
       color = "Order Condition",
       fill = "Order Condition",
       title = "Continuous Analysis of Learning Trends by Investment Level and Order") +
  theme_minimal() +
  theme(legend.position = "bottom")
```


#### Four-Way Interaction: Investment, Order, D-factor, and Round Number

The significant four-way interaction involving investment amount, order of opponent presentation (volatile first or stable/human-like first), D-factor, and round number (`r papaja::apa_print(mod_return_pct)$full_result$inv_scaled_d_level_volatile_first_roundNum`) reveals a complex interplay of factors influencing return behavior. The key finding is that the *order* in which participants faced the opponents, combined with their D-factor level, influenced how their returns changed over time *depending on the investment level*.

<!-- To disentangle this interaction, we used `emtrends` to examine the simple slopes of return percentage over rounds, for each combination of D-factor, order condition, and investment level. We then used `test()` to determine if these slopes were significantly different from zero. -->

```{r four_way_inv_order_calcs, include=FALSE}
library(emmeans)

# Slopes of return percentage over rounds for each investment level,
#  D-factor, and order condition.
round_slopes <- emtrends(
  mod_return_pct,
  ~ inv_scaled | d_level * volatile_first,
  var = "roundNum",
  at = list(inv_scaled = c(-1, 0, 1))
)

# Test if slopes differ from zero, with Sidak correction for multiple comparisons.
round_slopes_test <- test(round_slopes, null = 0, adjust = "sidak")

get_slope_and_p <- function(test_object, d_level_val, volatile_first_val, inv_scaled_val) {
  # Convert to data frame for easier manipulation
  df <- as.data.frame(test_object)
  
  # Filter for the specific combination
  result_row <- df[df$d_level == d_level_val & 
                  df$volatile_first == volatile_first_val & 
                  df$inv_scaled == inv_scaled_val, ]
  
  # Check if we found a matching row
  if(nrow(result_row) == 0) {
    warning("No matching combination found")
    return(list(slope = NA, p_value = NA))
  }
  
  # Return both the slope and p-value
  return(list(
    slope = result_row$roundNum.trend,
    p_value = result_row$p.value
  ))
}

# Get values for high-D, stable-first
high_D_stable_high <- get_slope_and_p(round_slopes_test, "high_D", FALSE, 1)

high_D_stable_high <- get_slope_and_p(round_slopes_test, "high_D", FALSE, 1)
high_D_stable_med <- get_slope_and_p(round_slopes_test, "high_D", FALSE, 0)
high_D_stable_low <- get_slope_and_p(round_slopes_test, "high_D", FALSE, -1)

# Get values for high-D, volatile-first
high_D_volatile_high <- get_slope_and_p(round_slopes_test, "high_D", TRUE, 1)
high_D_volatile_med <- get_slope_and_p(round_slopes_test, "high_D", TRUE, 0)
high_D_volatile_low <- get_slope_and_p(round_slopes_test, "high_D", TRUE, -1)

# Get values for low-D, stable-first
low_D_stable_high <- get_slope_and_p(round_slopes_test, "low_D", FALSE, 1)
low_D_stable_med <- get_slope_and_p(round_slopes_test, "low_D", FALSE, 0)
low_D_stable_low <- get_slope_and_p(round_slopes_test, "low_D", FALSE, -1)

# Get values for low-D, volatile-first
low_D_volatile_high <- get_slope_and_p(round_slopes_test, "low_D", TRUE, 1)
low_D_volatile_med <- get_slope_and_p(round_slopes_test, "low_D", TRUE, 0)
low_D_volatile_low <- get_slope_and_p(round_slopes_test, "low_D", TRUE, -1)

# Helper function for formatting p-values
format_p <- function(p) {
  if (is.na(p)) {
    return("NA")
  } else if (p < 0.001) {
    return("p < .001")
  } else {
    return(sprintf("p = %.3f", p))
  }
}

```

<!-- High-D participants who faced the *stable (human-like)* opponent *first* showed a strategic pattern: they significantly decreased their returns over rounds for *high* (slope = `r sprintf("%.5f", high_D_stable_high$slope)`, *p* = `r sprintf("%.3f", high_D_stable_high$p_value)`) and *medium* investments (slope = `r sprintf("%.5f", high_D_stable_med$slope)`, *p* = `r sprintf("%.3f", high_D_stable_med$p_value)`), but not for low investments (slope = `r sprintf("%.5f", high_D_stable_low$slope)`, *p* = `r sprintf("%.3f", high_D_stable_low$p_value)`). This reinforces the idea that high-D individuals are more likely to reduce cooperation when they perceive an opportunity for greater gain (higher investments) and a predictable partner. In contrast, high-D participants who faced the *volatile* opponent *first* showed the *opposite* pattern: decreasing returns for *low* (slope = `r sprintf("%.5f", high_D_volatile_low$slope)`, *p* = `r sprintf("%.3f", high_D_volatile_low$p_value)`) and *medium* investments (slope = `r sprintf("%.5f", high_D_volatile_med$slope)`, *p* = `r sprintf("%.3f", high_D_volatile_med$p_value)`), but not for high investments (slope = `r sprintf("%.5f", high_D_volatile_high$slope)`, *p* = `r sprintf("%.3f", high_D_volatile_high$p_value)`) -->


High-D participants who faced the *stable* (human-like) *opponent* *first* showed a strategic pattern: they significantly decreased their returns over rounds for *high* (slope = `r sprintf("%.5f", high_D_stable_high$slope)`, `r format_p(high_D_stable_high$p_value)`) and *medium* investments (slope = `r sprintf("%.5f", high_D_stable_med$slope)`, `r format_p(high_D_stable_med$p_value)`), but not for low investments (slope = `r sprintf("%.5f", high_D_stable_low$slope)`, `r format_p(high_D_stable_low$p_value)`). This reinforces the idea that high-D individuals are more likely to reduce cooperation when they perceive an opportunity for greater gain (higher investments) and a predictable partner. In contrast, high-D participants who faced the *volatile* *opponent* *first* showed the *opposite* pattern: decreasing returns for *low* (slope = `r sprintf("%.5f", high_D_volatile_low$slope)`, `r format_p(high_D_volatile_low$p_value)`) and *medium* investments (slope = `r sprintf("%.5f", high_D_volatile_med$slope)`, `r format_p(high_D_volatile_med$p_value)`), but not for high investments (slope = `r sprintf("%.5f", high_D_volatile_high$slope)`, `r format_p(high_D_volatile_high$p_value)`).

Low-D participants, regardless of the order in which they faced the opponents, did *not* show significant changes in their returns across rounds for any investment level.

<!-- *Stable First*: low investments (slope = `r sprintf("%.5f", low_D_stable_low$slope)`, `r format_p(low_D_stable_low$p_value)`), medium investments (slope = `r sprintf("%.5f", low_D_stable_med$slope)`, `r format_p(low_D_stable_med$p_value)`), high investments (slope = `r sprintf("%.5f", low_D_stable_high$slope)`, `r format_p(low_D_stable_high$p_value)`). *Volatile First*: low investments (slope = `r sprintf("%.5f", low_D_volatile_low$slope)`, `r format_p(low_D_volatile_low$p_value)`), medium investments (slope = `r sprintf("%.5f", low_D_volatile_med$slope)`, `r format_p(low_D_volatile_med$p_value)`), high investments (slope = `r sprintf("%.5f", low_D_volatile_high$slope)`, `r format_p(low_D_volatile_high$p_value)`). -->


<!-- All of this supports the notion that higher levels of the Dark Factor are associated with more consistent declines in trust or reciprocity over repeated rounds, whereas lower Dark Factor individuals are more variable and sometimes maintain stable behavior (particularly in volatile-first) -->


```{r}
library(MuMIn)

# Calculate R-squared
r2_pct <- r.squaredGLMM(mod_return_pct$full_model)

cat("Fixed effects explain", round(r2_pct[1]*100, 1), "% of variance\n")
cat("Fixed and random effects together explain", round(r2_pct[2]*100, 1), "% of variance\n")

# Optional: Calculate the variance explained by random effects alone
cat("Random effects alone explain", round((r2_pct[2] - r2_pct[1])*100, 1), "% of variance\n")
```





<!-- ## Pct return model whith latent inv state  -->

```{r}
# Model comparison 

m0_lat <- mixed( ret_pct_na ~ opponent.f*investorState.f*d_level*volatile_first + (1+ opponent.f| playerId), data24, control = lmerControl(optimizer = "bobyqa"))

m1_lat <- mixed( ret_pct_na ~ opponent.f*investorState.f*d_level*volatile_first + roundNum*d_level  + (1+ opponent.f| playerId), data24, control = lmerControl(optimizer = "bobyqa"))

m2_lat <- mixed( ret_pct_na ~ opponent.f*investorState.f*d_level*volatile_first*roundNum  + (1+ opponent.f| playerId), data24,  control = lmerControl(optimizer = "bobyqa"))






# Likelihood ratio test
anova(m1_lat$full_model, m0_lat$full_model)
anova(m1_lat$full_model, m2_lat$full_model)
anova(m0_lat$full_model, m2_lat$full_model)

# we go with m2, it's better 

```

 
```{r}
mod_returns_latent <- mixed( ret_pct_na ~ opponent.f*investorState.f*d_level*volatile_first*roundNum + ( 1 + opponent.f| playerId), data24, REML= TRUE, method="KR",check_contrasts = TRUE )

anova(mod_returns_latent)

```

```{r}
library(MuMIn)

# Calculate R-squared
r2_lat <- r.squaredGLMM(mod_returns_latent$full_model)

# Print results
print(r2_lat)
```

<!-- ### Two way interaction investor State and D_level -->

```{r}
# First get emmeans object for the interaction
emm <- emmeans(mod_returns_latent, ~ investorState.f | d_level)

# Create custom contrasts for state comparisons
# For each D-level we want:
# 1. neutral - unhappy
# 2. happy - unhappy
# 3. happy - neutral

# Define the contrasts
state_contrasts <- list(
  neutral_vs_unhappy = c(-1, 1, 0),  # neutral - unhappy
  happy_vs_unhappy = c(-1, 0, 1),    # happy - unhappy
  happy_vs_neutral = c(0, -1, 1)     # happy - neutral
)

# Apply contrasts within each D-level
results <- contrast(emm, 
                   method = state_contrasts,
                   by = "d_level",
                   adjust = "none")  # No adjustment since these are planned comparisons

# Print results
print("Contrast results within each D-level:")
print(results)

# Test if these contrasts differ between D-levels
contrast_diffs <- contrast(results,
                          method = "revpairwise",
                          by = "contrast",
                          adjust = "none")

print("\nD-level differences in contrasts:")
print(contrast_diffs)

```

```{r}
# Get estimated marginal means
emm <- emmeans(mod_returns_latent, ~ investorState.f * d_level)
emm_df <- as.data.frame(emm)

# Create plot using emmeans
ggplot(emm_df, aes(x = investorState.f, y = emmean, color = d_level, group = d_level)) +
  # Add lines to show pattern
  geom_line(position = position_dodge(width = 0.2)) +
  # Add points
  geom_point(position = position_dodge(width = 0.2), size = 3) +
  # Add error bars using model-based SE
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE),
                width = 0.2, 
                position = position_dodge(width = 0.2)) +
  # Add shaded bands to show overlap
  geom_ribbon(aes(ymin = emmean - SE, 
                  ymax = emmean + SE,
                  fill = d_level,
                  color = NULL),
              alpha = 0.2) +
  # Customize appearance
  labs(x = "Investor State",
       y = "Estimated Marginal Mean Return Proportion",
       color = "D-Factor Level",
       fill = "D-Factor Level") +
  theme_bw() +
  # Use colorblind-friendly colors
  scale_color_manual(values = c("high_D" = "#E69F00", "low_D" = "#56B4E9")) +
  scale_fill_manual(values = c("high_D" = "#E69F00", "low_D" = "#56B4E9")) +
  # Add note about non-significance
  labs(caption = "Note: Overlapping error bands indicate non-significant differences between groups")
```

<!-- The analysis revealed different patterns of responses to investor states between high and low D-factor participants. Low D-factor participants showed significant increases in return rates from unhappy to neutral states (b = 0.033, SE = 0.0075, z = 4.39, p < .001) and from unhappy to happy states (b = 0.057, SE = 0.0081, z = 7.04, p < .001), as well as from neutral to happy states (b = 0.024, SE = 0.0063, z = 3.87, p < .001). In contrast, high D-factor participants showed no significant differences in returns between unhappy and neutral states (b = -0.00005, SE = 0.0072, z = -0.007, p = .994) or unhappy and happy states (b = 0.013, SE = 0.0082, z = 1.53, p = .127), though they showed a marginally significant increase from neutral to happy states (b = 0.013, SE = 0.0065, z = 1.92, p = .054). -->
<!-- Direct comparisons between D-factor groups revealed that low D-factor participants showed significantly stronger positive responses than high D-factor participants between unhappy and neutral states (b = 0.033, SE = 0.0104, z = 3.18, p = .002) and between unhappy and happy states (b = 0.045, SE = 0.0116, z = 3.87, p < .001). However, the groups did not differ significantly in their response to the transition from neutral to happy states (b = 0.012, SE = 0.0091, z = 1.29, p = .196). These results suggest that low D-factor participants were more responsive to improvements in investor state, particularly when recovering from an unhappy state, while high D-factor participants showed more stable returns across investor states. -->



<!-- ### Three way interaction D_level, Investor State and Opponent:  -->
```{r}
# First get emmeans for the three-way interaction
emm_three <- emmeans(mod_returns_latent, ~ investorState.f | d_level | opponent.f)

# Define contrasts for investor states as before
state_contrasts <- list(
  neutral_vs_unhappy = c(-1, 1, 0),  # neutral - unhappy
  happy_vs_unhappy = c(-1, 0, 1),    # happy - unhappy
  happy_vs_neutral = c(0, -1, 1)     # happy - neutral
)

# Apply contrasts within each d_level and opponent combination
results_three <- contrast(emm_three,
                         method = state_contrasts,
                         by = c("d_level", "opponent.f"),
                         adjust = "none")

# Test if these contrasts differ between D-levels for each opponent
contrast_diffs_by_opponent <- contrast(results_three,
                                     method = "revpairwise",
                                     by = c("contrast", "opponent.f"),
                                     adjust = "none")

# Print results
print("Contrast results within each D-level and opponent:")
print(results_three)

print("\nD-level differences in contrasts by opponent:")
print(contrast_diffs_by_opponent)

# Create plot of the three-way interaction
# First get estimated marginal means in a format good for plotting
emm_df <- as.data.frame(emm_three)

#Create plot
ggplot(emm_df, aes(x = investorState.f, y = emmean, color = d_level, group = d_level)) +
  # Add lines
  geom_line(linewidth = 1) +
  # Add ribbons for CI
  geom_ribbon(aes(ymin = emmean - SE*1.96,
                  ymax = emmean + SE*1.96,
                  fill = d_level,
                  color = NULL),
              alpha = 0.2) +
  # Add error bars
  geom_errorbar(aes(ymin = emmean - SE*1.96,
                    ymax = emmean + SE*1.96),
                width = 0.2,
                position = position_dodge(width = 0.2)) +
  # Add points
  geom_point(size = 3, position = position_dodge(width = 0.2)) +
  # Separate by opponent
  facet_wrap(~opponent.f, scales = "free_y",
             labeller = labeller(opponent.f = c("AI_HMM" = "Human-like HMM",
                                              "AI_HMM_vol" = "Volatile HMM"))) +
  # Customize appearance
  scale_color_manual(values = c("high_D" = "#E69F00", "low_D" = "#56B4E9"),
                    name = "D-Factor Level") +
  scale_fill_manual(values = c("high_D" = "#E69F00", "low_D" = "#56B4E9"),
                    name = "D-Factor Level") +
  labs(x = "Investor State",
       y = "Predicted Return Proportion",
       title = "Three-way Interaction: Investor State × D-Level × Opponent",
       subtitle = "Estimated marginal means with 95% confidence intervals",
       caption = "Note: Model controls for volatile_first") +
  theme_minimal() +
  theme(legend.position = "top")

# Create a plot specifically showing the contrasts
contrast_df <- as.data.frame(results_three)

ggplot(contrast_df, aes(x = contrast, y = estimate, color = d_level)) +
  # Add zero reference line first so it's in the background
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(ymin = estimate - SE*1.96, 
                    ymax = estimate + SE*1.96),
                position = position_dodge(width = 0.5),
                width = 0.3) +
  facet_wrap(~opponent.f, scales = "free_y",
             labeller = labeller(opponent.f = c("AI_HMM" = "Human-like HMM",
                                              "AI_HMM_vol" = "Volatile HMM"))) +
  scale_color_manual(values = c("high_D" = "#E69F00", "low_D" = "#56B4E9")) +
  labs(x = "Contrast",
       y = "Contrast Estimate",
       title = "State Contrasts by D-Level and Opponent Type",
       subtitle = "Error bars show 95% confidence intervals",
       caption = "Dashed line at zero. Error bars not crossing line indicate significant differences") +
  theme_minimal() +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 45, hjust = 1))
```
<!-- across investor states, with differences between opponent types. With the human-like HMM opponent, high D-factor participants showed higher returns in happy versus neutral states (b = 0.030, SE = 0.008, z = 3.62, p < .001) and happy versus unhappy states (b = 0.025, SE = 0.012, z = 2.09, p = .036). Low D-factor participants showed higher returns across all state comparisons: neutral versus unhappy (b = 0.028, SE = 0.011, z = 2.42, p = .015), happy versus unhappy (b = 0.047, SE = 0.012, z = 3.76, p < .001), and happy versus neutral (b = 0.019, SE = 0.008, z = 2.22, p = .026). -->

<!-- With the volatile HMM opponent, the pattern diverged markedly. High D-factor participants showed no significant differences in returns between any investor states (all ps > .58). In contrast, low D-factor participants maintained significant differences, with higher returns in neutral versus unhappy states (b = 0.038, SE = 0.009, z = 4.12, p < .001), happy versus unhappy states (b = 0.068, SE = 0.010, z = 6.81, p < .001), and happy versus neutral states (b = 0.030, SE = 0.009, z = 3.22, p = .001). -->
<!-- The differences between D-factor groups were most pronounced with the volatile opponent, where low D-factor participants showed consistently larger differences in returns between states compared to high D-factor participants (neutral vs unhappy: b = 0.033, SE = 0.013, z = 2.55, p = .011; happy vs unhappy: b = 0.068, SE = 0.015, z = 4.65, p < .001; happy vs neutral: b = 0.035, SE = 0.014, z = 2.57, p = .010). -->

```{r}
# Load required libraries
library(dplyr)
library(ggplot2)
library(emmeans)

# Create summary for full interaction including all factors
full_interaction_summary <- final_data %>%
  group_by(investorState.f, opponent.f, volatile_first, d_level) %>%
  summarize(
    mean_return = mean(ret_pct_na, na.rm = TRUE),
    se_return = sd(ret_pct_na, na.rm = TRUE) / sqrt(n()),
    n = n(),
    .groups = "drop"
  )

# Create faceted plot showing all interactions
p_full <- ggplot(full_interaction_summary, 
                 aes(x = investorState.f, y = mean_return, 
                     color = factor(opponent.f), group = opponent.f)) +
  geom_point(size = 1) +
  geom_line(linewidth = 1) +
  geom_errorbar(aes(ymin = mean_return - se_return, 
                    ymax = mean_return + se_return),
                width = 0.2) +
  facet_grid(volatile_first  ~ d_level, 
             labeller = labeller(
               volatile_first = c("FALSE" = "Not Volatile First", 
                                "TRUE" = "Volatile First"),
               d_level = c("low_d" = "Low D", 
                          "high_d" = "High D"))) +
  theme_minimal() +
  theme(
    text = element_text(size = 12),
    panel.grid.minor = element_blank(),
    strip.text = element_text(size = 12, face = "bold"),
    strip.background = element_rect(fill = "lightgray", color = NA)
  ) +
  scale_color_manual(values = c("#1f77b4", "#ff7f0e"),
                    labels = c("First Game", "Second Game")) +
  labs(
    title = "Returns by Investor State, Game Order, Volatility, and D-Level",
    subtitle = "Showing all key interactions from the model",
    x = "Investor State",
    y = "Mean Return Percentage",
    color = "Game"
  )

# Print the plot
print(p_full)

# Calculate some key contrasts for interpretation
emm_full <- emmeans(mod_returns_latent, 
                    ~ investorState.f | opponent.f:volatile_first:d_level)

# Print contrasts within each combination
cat("\nState Contrasts within each Condition Combination:\n")
print(pairs(emm_full))

# Calculate effect sizes for the state differences in each condition
contrasts <- pairs(emm_full)
effect_sizes <- as.data.frame(contrasts) %>%
  mutate(
    effect_size = estimate / SE,
    significant = p.value < 0.05
  )

# Print summary of largest effects
cat("\nLargest State Effects:\n")
print(effect_sizes %>%
  dplyr::arrange(desc(abs(effect_size))) %>%
  head(10))
```



## Analysis of opponent ratings 

```{r}
ratings_data <- final_data %>%
  # Extract only the rows with ratings (typically at the end of each game)
  filter(!is.na(rating_cooperative)) %>%
  # Convert to factors where appropriate
  mutate(
    game_order = factor(gameNum.f, levels = c("first game", "second game")),
    opponent_type = case_when(
      grepl("AI_HMM_vol", opponent.f) ~ "Volatile",
      grepl("AI_HMM", opponent.f) ~ "Human-like"
    ),
    opponent_type = factor(opponent_type),
    d_level = factor(d_level)
  ) %>%
  # Select relevant columns
  dplyr::select(playerId, game_order, opponent_type, d_level, 
         rating_cooperative, rating_trusting, rating_playAgain)%>% 
  unique()
```

```{r}
# Function to create consistent rating plots
create_rating_plot <- function(rating_var, rating_name) {
  ggplot(ratings_data, aes(x = game_order, y = {{rating_var}}, 
                         color = d_level, group = interaction(d_level, opponent_type))) +
    stat_summary(fun = mean, geom = "point", size = 3) +
    stat_summary(fun = mean, geom = "line") +
    stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2) +
    facet_wrap(~opponent_type) +
    labs(title = paste(rating_name, "Ratings by D-level, Game Order, and Opponent Type"),
         x = "Game Order", y = paste(rating_name, "Rating (1-10)"),
         color = "D-level Group") +
    theme_minimal()
}

# Create plots for each rating type
coop_plot <- create_rating_plot(rating_cooperative, "Cooperative")
play_plot <- create_rating_plot(rating_playAgain, "Play Again")
trust_plot <- create_rating_plot(rating_trusting, "Trusting")

# Display plots
print(coop_plot)
print(play_plot)
print(trust_plot)

```


```{r}
# Step 3: Linear mixed-effects models using afex::mixed

# Load required package for improved mixed model analysis
library(afex)

# Model for cooperative ratings
coop_model_afex <- mixed(
  rating_cooperative ~ d_level * game_order * opponent_type + (1 | playerId),
  data = ratings_data,
  method = "KR"  # Kenward-Roger approximation for degrees of freedom
)

# Model for play again ratings
play_model_afex <- mixed(
  rating_playAgain ~ d_level * game_order * opponent_type + (1 | playerId),
  data = ratings_data,
  method = "KR"
)

# Model for trusting ratings
trust_model_afex <- mixed(
  rating_trusting ~ d_level * game_order * opponent_type + (1 | playerId),
  data = ratings_data,
  method = "KR"
)

# Step 4: Summarize model results
cat("ANOVA results for Cooperative ratings:\n")
print(anova(coop_model_afex))

cat("\nANOVA results for Play Again ratings:\n")
print(anova(play_model_afex))

cat("\nANOVA results for Trusting ratings:\n")
print(anova(trust_model_afex))
```




```{r}
library(emmeans)

# COOPERATIVE RATINGS
# 1. Main effect of D-level
coop_d <- emmeans(coop_model_afex, ~ d_level)
pairs(coop_d, adjust = "tukey")

# 2. Main effect of Game Order
coop_game <- emmeans(coop_model_afex, ~ game_order)
pairs(coop_game, adjust = "tukey")

# 3. Main effect of Opponent Type
coop_opp <- emmeans(coop_model_afex, ~ opponent_type)
pairs(coop_opp, adjust = "tukey")

# PLAY AGAIN RATINGS
# 1. Main effect of Game Order
play_game <- emmeans(play_model_afex, ~ game_order)
pairs(play_game, adjust = "tukey")

# 2. D-level × Game Order interaction
# a) D-level effects within each Game Order
play_d_by_game <- emmeans(play_model_afex, ~ d_level | game_order)
pairs(play_d_by_game, adjust = "tukey")

# b) Game Order effects within each D-level
play_game_by_d <- emmeans(play_model_afex, ~ game_order | d_level)
pairs(play_game_by_d, adjust = "tukey")

# TRUSTING RATINGS
# 1. Main effects (similar to cooperative ratings)
trust_d <- emmeans(trust_model_afex, ~ d_level)
pairs(trust_d, adjust = "tukey")

trust_game <- emmeans(trust_model_afex, ~ game_order)
pairs(trust_game, adjust = "tukey")

trust_opp <- emmeans(trust_model_afex, ~ opponent_type)
pairs(trust_opp, adjust = "tukey")

# 2. Three-way interaction
# a) D-level effects for each Game Order × Opponent Type combination
trust_d_by_game_opp <- emmeans(trust_model_afex, ~ d_level | game_order:opponent_type)
pairs(trust_d_by_game_opp, adjust = "tukey")

# b) Game Order effects for each D-level × Opponent Type combination
trust_game_by_d_opp <- emmeans(trust_model_afex, ~ game_order | d_level:opponent_type)
pairs(trust_game_by_d_opp, adjust = "tukey")

# c) Opponent Type effects for each D-level × Game Order combination
trust_opp_by_d_game <- emmeans(trust_model_afex, ~ opponent_type | d_level:game_order)
pairs(trust_opp_by_d_game, adjust = "tukey")
```





```{r}
library(afex)
library(emmeans)
library(papaja)

# --- Data Loading and Model Fitting (Replace with your actual data loading) ---
# Assuming your data is in a dataframe called 'ratings_data'
# and your models are already fit as coop_model_afex, play_model_afex, trust_model_afex

# --- Cooperative Ratings ---

# ANOVA
coop_anova_results <- apa_print(coop_model_afex, es = "pes")

# 1. Main effect of D-level
coop_d <- emmeans(coop_model_afex, ~ d_level)
coop_d_posthoc <- apa_print(pairs(coop_d, adjust = "tukey"))

# 2. Main effect of Game Order
coop_game <- emmeans(coop_model_afex, ~ game_order)
coop_game_posthoc <- apa_print(pairs(coop_game, adjust = "tukey"))

# 3. Main effect of Opponent Type
coop_opp <- emmeans(coop_model_afex, ~ opponent_type)
coop_opp_posthoc <- apa_print(pairs(coop_opp, adjust = "tukey"))

# --- Play Again Ratings ---

# ANOVA
play_anova_results <- apa_print(play_model_afex, es = "pes")

# 1. Main effect of Game Order
play_game <- emmeans(play_model_afex, ~ game_order)
play_game_posthoc <- apa_print(pairs(play_game, adjust = "tukey"))

# 2. D-level × Game Order interaction
# a) D-level effects within each Game Order
play_d_by_game <- emmeans(play_model_afex, ~ d_level | game_order)
play_d_by_game_posthoc <- apa_print(pairs(play_d_by_game, adjust = "tukey"))

# b) Game Order effects within each D-level
play_game_by_d <- emmeans(play_model_afex, ~ game_order | d_level)
play_game_by_d_posthoc <- apa_print(pairs(play_game_by_d, adjust = "tukey"))

# --- Trusting Ratings ---

# ANOVA
trust_anova_results <- apa_print(trust_model_afex, es = "pes")

# 1. Main effects
trust_d <- emmeans(trust_model_afex, ~ d_level)
trust_d_posthoc <- apa_print(pairs(trust_d, adjust = "tukey"))

trust_game <- emmeans(trust_model_afex, ~ game_order)
trust_game_posthoc <- apa_print(pairs(trust_game, adjust = "tukey"))

trust_opp <- emmeans(trust_model_afex, ~ opponent_type)
trust_opp_posthoc <- apa_print(pairs(trust_opp, adjust = "tukey"))

# 2. Three-way interaction
# a) D-level effects for each Game Order × Opponent Type combination
trust_d_by_game_opp <- emmeans(trust_model_afex, ~ d_level | game_order:opponent_type)
trust_d_by_game_opp_posthoc <- apa_print(pairs(trust_d_by_game_opp, adjust = "tukey"))


# b) Game Order effects for each D-level × Opponent Type combination
trust_game_by_d_opp <- emmeans(trust_model_afex, ~ game_order | d_level:opponent_type)
trust_game_by_d_opp_posthoc <- apa_print(pairs(trust_game_by_d_opp, adjust = "tukey"))

# c) Opponent Type effects for each D-level × Game Order combination
trust_opp_by_d_game <- emmeans(trust_model_afex, ~ opponent_type | d_level:game_order)
trust_opp_by_d_game_posthoc <- apa_print(pairs(trust_opp_by_d_game, adjust = "tukey"))
```


### Cooperative Ratings

Linear mixed-effects analysis revealed a significant main effect of D-level (`r coop_anova_results$statistic["d_level"]`), with low D-factor participants rating their opponents as more cooperative than high D-factor participants (`r coop_d_posthoc$statistic[1]`). A significant main effect of game order (`r coop_anova_results$statistic["game_order"]`) indicated participants rated opponents in their first game as more cooperative than those in their second game (`r coop_game_posthoc$statistic[1]`). Additionally, there was a significant main effect of opponent type (`r coop_anova_results$statistic["opponent_type"]`), with Human-like HMM opponents receiving higher cooperative ratings than Volatile opponents (`r coop_opp_posthoc$statistic[1]`).

### Play Again Ratings

Analysis of participants' willingness to play with the same opponent again revealed a significant main effect of game order (`r play_anova_results$statistic["game_order"]`), with participants generally more willing to play again with opponents from their first game (`r play_game_posthoc$statistic[1]`). This main effect was qualified by a significant D-level × Game Order interaction (`r play_anova_results$statistic$d_level_game_order`). Post-hoc analyses revealed that in the first game, high D-factor participants were significantly less willing to play again with their opponents compared to low D-factor participants (`r play_d_by_game_posthoc$statistic[1]`), while no such difference existed in the second game (`r play_d_by_game_posthoc$statistic[2]`). Examining changes across games, low D-factor participants showed a significant decrease in willingness to play again from the first to the second game (`r play_game_by_d_posthoc$statistic[2]`), while high D-factor participants maintained consistent ratings across games (`r play_game_by_d_posthoc$statistic[1]`).

### Trusting Ratings

For trust ratings, significant main effects were observed for D-level (`r trust_anova_results$statistic["d_level"]`), game order (`r trust_anova_results$statistic["game_order"]`), and opponent type (`r trust_anova_results$statistic["opponent_type"]`). These effects were qualified by a significant three-way interaction between D-level, game order, and opponent type (`r trust_anova_results$statistic$d_level_game_order_opponent_type`).

Post-hoc analyses revealed a complex pattern of trust perceptions. High D-factor participants rated Human-like opponents as significantly less trusting than low D-factor participants in the first game (`r trust_d_by_game_opp_posthoc$statistic[1]`). In contrast, high D-factor participants rated Volatile opponents as significantly less trusting than low D-factor participants in the second game (`r trust_d_by_game_opp_posthoc$statistic[4]`). Low D-factor participants showed a significant *increase* in trust ratings for Human-like opponents from the first to the second game (`r trust_game_by_d_opp_posthoc$statistic[2]`), while high D-factor participants showed a significant *decrease* in trust ratings for Volatile opponents from the first to the second game (`r trust_game_by_d_opp_posthoc$statistic[3]`). Additionally, high D-factor participants in the second game differentiated between opponent types, rating Human-like opponents as significantly more trusting than Volatile opponents (`r trust_opp_by_d_game_posthoc$statistic[3]`).

In summary, participants with higher Dark Factor scores demonstrated consistently more negative perceptions of their opponents, particularly regarding cooperation and trust. The pattern of results indicates that individual differences in Dark Factor traits influence not only the overall level of opponent ratings but also how these ratings change across repeated interactions and between different opponent types. Notably, low D-factor participants showed greater sensitivity to game order, with more pronounced decreases in ratings from first to second game, while high D-factor participants demonstrated greater discrimination between opponent types in their trust ratings.




```{r}
library(ggplot2)
library(dplyr)
library(patchwork)
library(cowplot)

create_rating_plots <- function(coop_emm, play_emm, trust_emm, y_limits = c(0, 8.5)) {
  
  # Helper function for significance stars
  get_stars <- function(p) {
    if (p < 0.001) {
      return("***")
    } else if (p < 0.01) {
      return("**")
    } else if (p < 0.05) {
      return("*")
    } else {
      return("")
    }
  }
  
  # Example p-values for each effect (adjust as needed)
  p_coop <- 0.0074
  p_play <- 0.0182
  p_trust_first <- 0.0182
  p_trust_second_volatile <- 0.0073
  p_trust_second_high <- 0.0127
  
  # Color/shape settings for High/Low D
  d_level_colors <- c("high_D" = "red", "low_D" = "green")
  d_level_shapes <- c("high_D" = 24,      # filled triangle
                      "low_D"  = 21)      # filled circle
  
  # Convert emmeans objects to data frames
  coop_data <- as.data.frame(coop_emm) %>% 
    mutate(opponent_type = "Overall", game_order = "Overall")
  play_data <- as.data.frame(play_emm) %>% 
    mutate(opponent_type = "Overall")
  trust_data <- as.data.frame(trust_emm)
  
  # Base plot: single legend for fill and shape
  base_plot <- function(data, plot_title) {
    ggplot(data, aes(x = opponent_type, y = emmean, 
                     fill = d_level, shape = d_level)) +
      geom_point(position = position_dodge(width = 0.6),
                 size = 3, color = "black") +
      geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), 
                    position = position_dodge(width = 0.6),
                    width = 0.2) +
      facet_wrap(~game_order) +
      labs(title = plot_title) +
      theme_classic() +
      theme(
        # Single legend will be placed in coop_plot
        legend.position = "none",
        panel.grid.major.y = element_line(color = "gray90"),
        axis.text = element_text(size = 10, color = "black"),
        axis.title = element_text(size = 12),
        plot.title = element_text(size = 14, hjust = 0.5),
        strip.background = element_rect(fill = "gray90"),
        # Remove bold from facet titles:
        strip.text = element_text(size = 11)
      ) +
      # Combine fill & shape into one legend by giving them the same name, labels, and guide
      scale_fill_manual(
        name = "D-Factor Level",
        labels = c("High D", "Low D"),
        values = d_level_colors,
        guide = "legend"
      ) +
      scale_shape_manual(
        name = "D-Factor Level",
        labels = c("High D", "Low D"),
        values = d_level_shapes,
        guide = "legend"
      ) +
      scale_y_continuous(limits = y_limits)
  }
  
  # Create the three main plots
  coop_plot <- base_plot(coop_data, "Cooperative Ratings")
  play_plot <- base_plot(play_data, "Play Again Ratings")
  trust_plot <- base_plot(trust_data, "Trusting Ratings")
  
  # Minimal axis labeling
  coop_plot <- coop_plot + labs(x = NULL, y = "Mean Rating")
  play_plot <- play_plot + labs(x = "Opponent Type", y = NULL)
  trust_plot <- trust_plot + labs(x = NULL, y = NULL)
  
  # Move the legend inside the Cooperative Ratings panel
  coop_plot <- coop_plot + theme(legend.position = c(0.18, 0.92))
  
  # Offset for horizontal bracket
  offset <- 0.15
  
  # Function to draw a significance bracket with downward ticks only
  draw_bracket <- function(x_center, y_top, star_label, facet_val = "Overall") {
    list(
      # Horizontal line
      geom_segment(data = data.frame(x = x_center - offset, 
                                     xend = x_center + offset, 
                                     y = y_top, yend = y_top,
                                     game_order = facet_val),
                   aes(x = x, xend = xend, y = y, yend = yend),
                   inherit.aes = FALSE),
      # Left vertical tick (downward only)
      geom_segment(data = data.frame(x = x_center - offset, 
                                     xend = x_center - offset, 
                                     y = y_top, yend = y_top - 0.1,
                                     game_order = facet_val),
                   aes(x = x, xend = xend, y = y, yend = yend),
                   inherit.aes = FALSE),
      # Right vertical tick (downward only)
      geom_segment(data = data.frame(x = x_center + offset, 
                                     xend = x_center + offset, 
                                     y = y_top, yend = y_top - 0.1,
                                     game_order = facet_val),
                   aes(x = x, xend = xend, y = y, yend = yend),
                   inherit.aes = FALSE),
      # Star text
      geom_text(data = data.frame(x = x_center, 
                                  y = y_top + 0.1, 
                                  label = star_label,
                                  game_order = facet_val),
                aes(x = x, y = y, label = label),
                inherit.aes = FALSE, size = 4)
    )
  }
  
  # 1. Cooperative Ratings significance
  coop_sig_y <- max(coop_data$emmean + coop_data$SE) + 0.3
  coop_plot <- coop_plot +
    draw_bracket(x_center = 1, 
                 y_top = coop_sig_y, 
                 star_label = get_stars(p_coop), 
                 facet_val = "Overall")
  
  # 2. Play Again Ratings significance (first game)
  play_first <- play_data %>% filter(game_order == "first game")
  if(nrow(play_first) > 0){
    play_sig_y <- max(play_first$emmean + play_first$SE) + 0.2
    play_plot <- play_plot +
      draw_bracket(x_center = 1, 
                   y_top = play_sig_y, 
                   star_label = get_stars(p_play),
                   facet_val = "first game")
  }
  
  # 3. Trusting Ratings significance
  # (a) first game, "Human-like"
  trust_first <- trust_data %>% filter(game_order == "first game", opponent_type == "Human-like")
  if(nrow(trust_first) > 0){
    trust_sig_y1 <- max(trust_first$emmean + trust_first$SE) + 0.3
    trust_plot <- trust_plot +
      list(
        # Horizontal bracket
        geom_segment(data = data.frame(x = 0.85, xend = 1.15, 
                                       y = trust_sig_y1, yend = trust_sig_y1,
                                       game_order = "first game", opponent_type = "Human-like"),
                     aes(x = x, xend = xend, y = y, yend = yend),
                     inherit.aes = FALSE),
        # Left vertical tick (down only)
        geom_segment(data = data.frame(x = 0.85, xend = 0.85, 
                                       y = trust_sig_y1, yend = trust_sig_y1 - 0.1,
                                       game_order = "first game", opponent_type = "Human-like"),
                     aes(x = x, xend = xend, y = y, yend = yend),
                     inherit.aes = FALSE),
        # Right vertical tick (down only)
        geom_segment(data = data.frame(x = 1.15, xend = 1.15, 
                                       y = trust_sig_y1, yend = trust_sig_y1 - 0.1,
                                       game_order = "first game", opponent_type = "Human-like"),
                     aes(x = x, xend = xend, y = y, yend = yend),
                     inherit.aes = FALSE),
        # Star
        geom_text(data = data.frame(x = 1.0, y = trust_sig_y1 + 0.1, 
                                    label = get_stars(p_trust_first),
                                    game_order = "first game", opponent_type = "Human-like"),
                  aes(x = x, y = y, label = label),
                  inherit.aes = FALSE, size = 4)
      )
  }
  
  # (b) second game, "Volatile"
  trust_second_volatile <- trust_data %>% filter(game_order == "second game", opponent_type == "Volatile")
  if(nrow(trust_second_volatile) > 0){
    trust_sig_y2 <- max(trust_second_volatile$emmean + trust_second_volatile$SE) + 0.3
    trust_plot <- trust_plot +
      list(
        geom_segment(data = data.frame(x = 1.85, xend = 2.15, 
                                       y = trust_sig_y2, yend = trust_sig_y2,
                                       game_order = "second game", opponent_type = "Volatile"),
                     aes(x = x, xend = xend, y = y, yend = yend),
                     inherit.aes = FALSE),
        geom_segment(data = data.frame(x = 1.85, xend = 1.85, 
                                       y = trust_sig_y2, yend = trust_sig_y2 - 0.1,
                                       game_order = "second game", opponent_type = "Volatile"),
                     aes(x = x, xend = xend, y = y, yend = yend),
                     inherit.aes = FALSE),
        geom_segment(data = data.frame(x = 2.15, xend = 2.15, 
                                       y = trust_sig_y2, yend = trust_sig_y2 - 0.1,
                                       game_order = "second game", opponent_type = "Volatile"),
                     aes(x = x, xend = xend, y = y, yend = yend),
                     inherit.aes = FALSE),
        geom_text(data = data.frame(x = 2.0, y = trust_sig_y2 + 0.1, 
                                    label = get_stars(p_trust_second_volatile),
                                    game_order = "second game", opponent_type = "Volatile"),
                  aes(x = x, y = y, label = label),
                  inherit.aes = FALSE, size = 4)
      )
  }
  
  # (c) second game, high_D difference
  trust_second_high <- trust_data %>% filter(game_order == "second game", d_level == "high_D")
  if(nrow(trust_second_high) > 0){
    trust_sig_y3 <- max(trust_second_high$emmean + trust_second_high$SE) + 0.3
    trust_plot <- trust_plot +
      list(
        geom_segment(data = data.frame(x = 0.7, xend = 1.7, 
                                       y = trust_sig_y3, yend = trust_sig_y3,
                                       game_order = "second game", d_level = "high_D"),
                     aes(x = x, xend = xend, y = y, yend = yend),
                     inherit.aes = FALSE),
        geom_segment(data = data.frame(x = 0.7, xend = 0.7, 
                                       y = trust_sig_y3, yend = trust_sig_y3 - 0.1,
                                       game_order = "second game", d_level = "high_D"),
                     aes(x = x, xend = xend, y = y, yend = yend),
                     inherit.aes = FALSE),
        geom_segment(data = data.frame(x = 1.7, xend = 1.7, 
                                       y = trust_sig_y3, yend = trust_sig_y3 - 0.1,
                                       game_order = "second game", d_level = "high_D"),
                     aes(x = x, xend = xend, y = y, yend = yend),
                     inherit.aes = FALSE),
        geom_text(data = data.frame(x = 1.2, y = trust_sig_y3 + 0.1, 
                                    label = get_stars(p_trust_second_high),
                                    game_order = "second game", d_level = "high_D"),
                  aes(x = x, y = y, label = label),
                  inherit.aes = FALSE, size = 4)
      )
  }
  
  # Combine the three panels
  final_plot <- coop_plot + play_plot + trust_plot +
    plot_layout(ncol = 3) +
    plot_annotation(
      title = "Participant Ratings by D-Factor Level and Game Type",
      caption = "* p < 0.05; ** p < 0.01; *** p < 0.001",
      theme = theme(
        plot.title = element_text(size = 14, hjust = 0.5),
        plot.caption = element_text(size = 10, hjust = 1)
      )
    )
  
  return(final_plot)
}

```



```{r plotRatings,include=T, echo=FALSE, warning=FALSE, fig.pos='H', fig.cap="Averages and standard errors of the participants ratings of the opponent (y-axis) by each game and d-factor group for each opponent (x-axis). The left panel represents participants' perception of co-player cooperativeness, the right one one indicates perceived co-player trut rating, and the middel panel shows the participants' willingness to play again with the same co-player. Cooperation, trust perception, and willingness to play again ratings were generally lower for the high DFP group",fig.width=10, fig.height=6, fig.align="center"}

final_plot2 <- create_rating_plots(
  coop_emm = emmeans(coop_model_afex, ~ d_level),
  play_emm = emmeans(play_model_afex, ~ d_level | game_order),
  trust_emm = emmeans(trust_model_afex, ~ d_level * opponent_type | game_order),
  y_limits = c(4, 8.5)
)

final_plot2
```























# Debrief questions 

```{r}
library(tidyverse)

# Load your dataset (assuming it's already loaded as `final_data`)

# Summarize Turing test responses
turing_summary <- final_data %>%
  count(Turing.choice) %>%
  mutate(percentage = (n / sum(n)) * 100)

print(turing_summary)

# Plot results for visualization
ggplot(turing_summary, aes(x = Turing.choice, y = n, fill = Turing.choice)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(label = paste0(round(percentage, 1), "%")), vjust = -0.5) +
  labs(title = "Distribution of Turing Test Responses",
       x = "Turing Test Response",
       y = "Count") +
  theme_minimal()

```
Around 57% of participants either thought that they played against a human opponent or were not sure whether the investor was a human or a machine. 


```{r}
# library(httr)
# library(jsonlite)
# 
# # Function to query the OpenAI API
# analyze_with_llm <- function(text, prompt, api_key, model = "gpt-3.5-turbo") {
#   url <- "https://api.openai.com/v1/chat/completions"
#   
#   response <- POST(
#     url,
#     add_headers(
#       Authorization = paste("Bearer", api_key),
#       "Content-Type" = "application/json"
#     ),
#     body = toJSON(list(
#       model = model,
#       messages = list(
#         list(role = "system", content = prompt),
#         list(role = "user", content = text)
#       ),
#       temperature = 0  # deterministic output
#     ), auto_unbox = TRUE)
#   )
#   
#   result <- content(response, as = "parsed")
#   return(result$choices[[1]]$message$content)
# }
# 
# # Define your API key (securely store it, e.g., in environment variables)
# api_key <- Sys.getenv("OPENAI_API_KEY")
# 
# # Define a structured prompt
# strategy_prompt <- "
# You are a research assistant helping to analyze textual responses from participants of an economic trust game experiment. Classify the response into one or more of the following themes:
# 
# 1. Increased trust or generosity.
# 2. Decreased trust or cautiousness.
# 3. No change in behavior.
# 4. Reactive strategy based on opponent's behavior.
# 5. Random or no clear strategy mentioned.
# 6. Maximization of points explicitly mentioned.
# 7. Unclear or ambiguous reasoning.
# 
# Provide your classification as a numbered list based only on the themes above. Provide no additional explanation.
# "
# 
# # Apply the prompt to analyze the DescribeOther responses
# final_data$DescribeOther_Analysis <- sapply(
#   final_data$DescribeOther, 
#   analyze_with_llm, 
#   prompt = strategy_prompt, 
#   api_key = api_key
# )
# 
# # Inspect results
# head(final_data$DescribeOther_Analysis)

```

















# Computational Modelling 


# Model comparison (Simple RL, MBRL, hybrid with planning, POMDP)

```{r}
library(tidyverse)
library(ggplot2)

# 1) Read each CSV
results_simpleRL  <- read.csv("results_simpleRL.csv")
results_MBRL_k    <- read.csv("results_mb_k.csv")
results_pomdp     <- read.csv("results_pomdp.csv")
results_hybrid_k  <- read.csv("results_hybrid_k.csv") # old hybrid with same learning rat in MB and MF
results_hybrid_2a <- read.csv("results_hybrid_2a.csv") # new hybrid with different learning rates for MB and MF models 

# calculte AIC and BIC in planning 
results_pomdp <- results_pomdp %>%
  mutate(
    aic = 2 * 7 + 2 * nll,  # Calculate AIC (7 parameters when you include k)
    bic = 7 * log(50) + 2 * nll  # Calculate BIC (50 gives number of rows)
  )

# 2) Select and rename columns in each results data frame
df_MF <- results_simpleRL %>%
  dplyr::select(playerId, neg_log_lik, aic, bic) %>%
  rename(participant = playerId,
         nll_MF = neg_log_lik,
         aic_MF = aic,
         bic_MF = bic)

df_MB <- results_MBRL_k %>%
  dplyr::select(participant, nll, aic, bic) %>%
  rename(nll_MB = nll,
         aic_MB = aic,
         bic_MB = bic)

df_pomdp <- results_pomdp %>%
  dplyr::select(participant, nll, aic,bic) %>%
  rename(nll_pomdp = nll,
         aic_pomdp = aic,
         bic_pomdp = bic)

df_hybrid <- results_hybrid_k %>%
  dplyr::select(participant, nll, aic, bic) %>%
  rename(nll_hybrid = nll,
         aic_hybrid = aic,
         bic_hybrid = bic)

df_hybrid_2a <- results_hybrid_2a %>%
  dplyr::select(participant, nll, aic, bic) %>%
  rename(nll_hybrid_2a = nll,
         aic_hybrid_2a = aic,
         bic_hybrid_2a = bic)



# 3) Merge them all by participant
final_results <- df_MF %>%
  left_join(df_MB, by = "participant") %>%
  left_join(df_pomdp, by = "participant") %>%
  left_join(df_hybrid, by = "participant") %>%
  left_join(df_hybrid_2a, by = "participant") 



# Step 1: Determine the winning model based on AIC
final_results <- final_results %>%
  rowwise() %>%
  mutate(
    best_fit_aic = case_when(
      aic_MF == min(aic_MF, aic_MB, aic_pomdp, aic_hybrid, aic_hybrid_2a) ~ "MFRL",
      aic_MB == min(aic_MF, aic_MB, aic_pomdp, aic_hybrid, aic_hybrid_2a ) ~ "MBRL_k",
      aic_pomdp == min(aic_MF, aic_MB, aic_pomdp, aic_hybrid, aic_hybrid_2a) ~ "planning",
      aic_hybrid == min(aic_MF, aic_MB, aic_pomdp, aic_hybrid, aic_hybrid_2a) ~ "hybridRL_k",
      aic_hybrid_2a == min(aic_MF, aic_MB, aic_pomdp, aic_hybrid, aic_hybrid_2a) ~ "hybridRL_2a"
    )
  ) %>%
  ungroup()

# Step 2: Flag participants where nll_hybrid is higher than nll_MB or nll_MF
final_results <- final_results %>%
  mutate(
    flag_nll_hybrid = ifelse(nll_hybrid > nll_MB | nll_hybrid > nll_MF, TRUE, FALSE)
  )

# 4) Inspect or write out final_results
head(final_results)

NLL_comp <- final_results %>% dplyr::select(nll_pomdp,nll_MB,nll_MF,nll_hybrid,nll_hybrid_2a )
NLL_comp 

AIC_comp <- final_results %>% dplyr::select(aic_pomdp,aic_MB,aic_MF,aic_hybrid, aic_hybrid_2a )
AIC_comp

BIC_comp <- final_results %>% dplyr::select(bic_pomdp,bic_MB,bic_MF,bic_hybrid, bic_hybrid_2a )
BIC_comp

# Optional: write to CSV if desired
#write.csv(final_results, "merged_model_results_all_fit.csv", row.names = FALSE)

```

## Model comparison, OOF testing

```{r}
# Load required libraries
library(tidyverse)
library(ggplot2)

# 1. Read in the CSV files
results_pomdp_test<- read_csv("results_pomdp_test.csv")
results_hybPlan <- read_csv("results_hybPlan_test.csv")
results_hybPlan_2a <- read_csv("results_hybPlan_test_2a.csv")
#results_hybPlan_2a <- results_hybPlan_test_2a
results_MFRL <- read_csv("results_MFRL_test.csv")
results_MBRL <- read_csv("results_mbPlan_test.csv")

# 2. Add a new column indicating the model name
results_pomdp_test<- results_pomdp_test%>% mutate(model = "POMDP")
results_hybPlan <- results_hybPlan %>% mutate(model = "Hybrid")
results_hybPlan_2a <- results_hybPlan_2a %>% mutate(model = "Hybrid_2a")
results_MFRL <- results_MFRL %>% mutate(model = "MFRL")
results_MBRL <- results_MBRL %>% mutate(model = "MBRL")

# 3. Merge the three data frames into one.
# We assume that each file has one row per participant (or more rows, if there are multiple observations per participant).
# If each CSV file has the same participants, you might eventually merge them by playerId.
# Here we simply bind the rows (i.e. a long-format data frame).
results_all_test <- bind_rows(results_pomdp_test, results_hybPlan, results_hybPlan_2a, results_MFRL, results_MBRL)
results_all_test <- results_all_test %>%
  mutate(across(where(is.numeric), ~ifelse(is.infinite(.), NA, .)))

results_all_test <- results_all_test %>%
  mutate(nparam = case_when(
    model == "MFRL" ~ 6,
    model == "MBRL" ~ 9,
    model == "Hybrid" ~ 10,
    model == "Hybrid_2a" ~ 8,
    model == "POMDP" ~ 7,
    TRUE ~ NA_real_
  ))

# 5. Compute AIC and BIC for test time.
# Here we assume that the test set has 5 rounds per participant.
n_test <- 10

# 4. Model Comparison Based on Bin Accuracy and Test NLL/AIC/BIC
# Note: Typically, AIC = 2 * (# parameters) + 2 * (test_nll) 
#       and BIC = log(n_test) * (# parameters) + 2 * (test_nll)
results_all_test <- results_all_test %>%
  mutate(
    AIC_test = 2 * nparam + 2 * test_nll,
    BIC_test = log(n_test) * nparam + 2 * test_nll
  )

# 6. Print the merged results with the computed AIC and BIC
print(results_all_test)

# 7. Optional: Produce summary statistics and plots for model comparison.
# Summary statistics:

summary_stats <- results_all_test %>%
  group_by(model) %>%
  summarise(
    n = n(),
    mean_bin_accuracy = mean(bin_accuracy, na.rm = TRUE),
    sd_bin_accuracy = sd(bin_accuracy, na.rm = TRUE),
    mean_test_nll = mean(test_nll, na.rm = TRUE),
    sd_test_nll = sd(test_nll, na.rm = TRUE),
    mean_AIC_test = mean(AIC_test, na.rm = TRUE),
    mean_BIC_test = mean(BIC_test, na.rm = TRUE)
  )
print(summary_stats)
# 4b. Boxplots for visual comparison



```

```{r, include=FALSE}
# Boxplot for Bin Accuracy
p1 <- ggplot(results_all_test, aes(x = model, y = bin_accuracy, fill = model)) +
  geom_boxplot() +
  geom_hline(yintercept = 1/6, linetype = "dashed", color = "black") +  # Add dashed black line
  labs(title = "Model Comparison: Bin Accuracy",
       x = "Model",
       y = "Bin Accuracy") +
  theme_minimal() +
  theme(legend.position = "none")
print(p1)

# p1 <- ggplot(results_all_test, aes(x = model, y = bin_accuracy, fill = model)) +
#   geom_violin(alpha = 0.6, width = 0.7) +  # Show distribution shape
#   geom_jitter(width = 0.15, alpha = 0.5, size = 1) +  # Individual points
#   # geom_boxplot(width = 0.2, alpha = 0.7, outlier.shape = NA) +  # Boxplot summary
#   geom_hline(yintercept = 1/6, linetype = "dashed", color = "black") +
#   labs(title = "Model Comparison: Bin Accuracy", 
#        x = "Model", 
#        y = "Bin Accuracy") +
#   theme_minimal() +
#   theme(legend.position = "none")
# print(p1)

# Boxplot for Test Negative Log Likelihood
p2 <- ggplot(results_all_test, aes(x = model, y = AIC_test, fill = model)) +
  geom_boxplot() +
  labs(title = "Model Comparison: Test AIC", 
       x = "Model", 
       y = "Test AIC") +
  theme_minimal() +
  theme(legend.position = "none")
print(p2)

# Optional: Scatter plot showing the trade-off between bin accuracy and test NLL
p3 <- ggplot(results_all_test, aes(x = test_nll, y = bin_accuracy, color = model)) +
  geom_point(size = 3, alpha = 0.8) +
  labs(title = "Model Comparison: Test NLL vs. Bin Accuracy", 
       x = "Test Negative Log Likelihood", 
       y = "Bin Accuracy") +
  theme_minimal()
print(p3)
```


```{r}


df <- results_all_test %>%
  rename(
    subj_id  = playerId,        # or rename to "subj_id" if you want
    accuracy = bin_accuracy # if "test_binaccuracy" is your accuracy measure
  ) %>%
  # keep the columns you'll need
  dplyr::select(subj_id, model, accuracy, test_nll, AIC_test, BIC_test) %>%
  # convert 'model' to a factor (important for ANOVA)
  mutate(model = factor(model))

# Inspect the resulting structure
head(df)
# ------------------------------------------------
# Example: Mixed Model for Accuracy in afex::mixed
# ------------------------------------------------

library(afex)
library(emmeans)

# Suppose df has the columns:
#   subj_id  (participant identifier)
#   model    (factor with levels: e.g., "MFRL", "MBRL", "Hybrid", etc.)
#   accuracy (numeric variable representing out-of-sample accuracy)

# 1) Make sure model is a factor
df$model <- factor(df$model)

# 2) Fit a linear mixed-effects model 
#    Random intercepts by subj_id; you could also allow random slopes for model:
#      (model|subj_id) if it converges and is justified by your design.
mixed_result <- mixed(
  formula = accuracy ~ model + (1 | subj_id),
  data    = df,
  method  = "LRT",   # or "KR", "S" for Kenward-Roger / Satterthwaite
  progress= FALSE, 
  return = "merMod"
)

summary(mixed_result)

# 3) Post-hoc comparisons among model levels:
posthoc <- emmeans(mixed_result, pairwise ~ model)
posthoc

```

### checking model assumptions
```{r}
# library(performance)
# library(see)  # for nice plotting (optional)
# 
# check_model(mixed_model)

```

```{r}
# df <- df %>%
#   mutate(
#     successes = round(accuracy * 10),
#     failures  = 10 - round(accuracy * 10)
#   )
# 
# glmer_model <- glmer(
#   cbind(successes, failures) ~ model + (1 | subj_id),
#   data = df, family = binomial
# )
# 
# library(emmeans)
# 
# emm <- emmeans(glmer_model, pairwise ~ model, type = "response")
# # type = "response" gives results back-transformed to probabilities
# 
# emm$emmeans    # mean predicted accuracy for each model
# emm$contrasts  # pairwise contrasts + p-values


```


```{r}
library(dplyr)
library(tidyr)

# df_sub <- df %>% 
#   filter(model %in% c("Hybrid", "MFRL")) %>% 
#   select(subj_id, model, accuracy)
# 
# # Convert to wide format for paired test
# df_wide <- df_sub %>%
#   pivot_wider(names_from = model, values_from = accuracy)
# 
# wilcox.test(df_wide$Hybrid, df_wide$MFRL, paired = TRUE)
```




# Discussion


<!-- The present study investigated how the Dark Factor of Personality (D-factor) influences behavior in repeated trust games, focusing on trustworthiness patterns, strategic adaptation, and perception of counterparts. Our findings reveal nuanced relationships between dark personality traits and economic decision-making that both confirm and challenge existing theoretical frameworks. -->

<!-- Our results demonstrated significant behavioral differences between individuals with high and low D-factor scores. High D-factor participants consistently returned lower proportions of investment compared to their low D-factor counterparts, with this difference becoming particularly pronounced in later rounds of the game. This pattern aligns with the fundamental definition of the D-factor as "the general tendency to maximize one's utility at the expense of others, accompanied by beliefs that serve as justifications" (Moshagen et al., 2018). The lower return percentages directly translate to greater self-benefit at the investor's expense, supporting the construct validity of the D-factor in predicting economic behavior. -->
<!-- Interestingly, the timing of these differences suggests a strategic component to this behavior. The absence of significant differences in early rounds, followed by emerging disparities in later stages of interaction, indicates a possible exploitation pattern that develops over time. This temporal dimension of trustworthiness aligns with prior research suggesting that dark personality traits may manifest most strongly after establishing a baseline relationship (Jones & Paulhus, 2009). This finding extends previous work on dark traits in one-shot economic games (Zhao & Smillie, 2015; Thielmann & Hilbig, 2019) by demonstrating how these tendencies unfold over repeated interactions. -->

<!-- The significant interaction between D-factor, investment amount, round number, and opponent type reveals sophisticated strategic differences between high and low D-factor individuals. When facing the predictable human-like HMM opponent, high D-factor participants demonstrated a distinct pattern: they significantly decreased their returns over time for high-investment trials while maintaining relatively stable returns for low-investment trials. This selective exploitation strategy suggests a calculated approach to maximize gains while minimizing the risk of triggering retaliation from the investor. -->
<!-- This pattern is particularly significant because it represents a form of Machiavellian exploitation that targets situations of high trust (indicated by higher investments) rather than indiscriminate exploitation across all conditions. By selectively reducing reciprocity in high-stake interactions, high D-factor individuals effectively exploit the trust placed in them when the potential gains are greatest. This finding aligns with the conceptualization of Machiavellianism as involving strategic, long-term orientation to personal gain (Jones & Paulhus, 2009) and supports previous research indicating that dark personality traits are associated with strategic rather than impulsive exploitation (Gunnthorsdottir et al., 2002). -->
<!-- Notably, this strategic exploitation pattern was only observed with the more predictable human-like HMM opponent, not with the volatile opponent. This distinction suggests that high D-factor individuals may be particularly adept at identifying and exploiting predictable social dynamics, while showing more caution in volatile or unpredictable social environments. This contextual sensitivity adds important nuance to our understanding of how dark personality traits manifest in economic decisions. -->


<!-- The significant four-way interaction involving investment, order of opponent presentation, D-factor, and round number further illuminates the adaptive nature of exploitation strategies. High D-factor participants who first encountered the stable (human-like) opponent showed decreasing returns over rounds for high and medium investments but maintained stable returns for low investments. In contrast, those who initially faced the volatile opponent reduced returns for low and medium investments while maintaining returns for high investments. -->
<!-- This pattern suggests that high D-factor individuals rapidly adapt their exploitation strategies based on initial experiences. When first exposed to a predictable environment, they learn to exploit high-trust situations. Conversely, when first exposed to volatility, they adopt a more conservative strategy that maintains cooperation in high-stake interactions while reducing reciprocity in lower-risk situations. This adaptive learning demonstrates sophisticated social intelligence that may underlie the effectiveness of dark personality traits in navigating complex social environments. -->
<!-- Low D-factor participants, regardless of the order in which they faced opponents, maintained relatively stable return rates across rounds and investment levels, suggesting a more consistent approach to reciprocity that is less influenced by strategic considerations or learning effects. This stability in cooperative behavior may reflect stronger adherence to fairness norms and less susceptibility to exploitative tendencies. -->


<!-- The analysis of opponent ratings revealed that D-factor scores significantly influenced how participants perceived their counterparts. High D-factor participants consistently rated their opponents lower on cooperativeness, trustworthiness, and desirability for future interaction, regardless of the opponent's actual behavior. This negative perceptual bias is consistent with research suggesting that individuals with dark personality traits may have distorted social perceptions that justify exploitation (Moshagen et al., 2018; Zettler et al., 2021). -->
<!-- The interaction between D-factor, game order, and opponent type for trust ratings suggests complex differences in how high and low D-factor individuals update their social perceptions based on experience. While low D-factor participants showed increased trust in human-like opponents from first to second game, high D-factor participants showed decreased trust in volatile opponents. This differential updating may reflect differences in attribution processes: low D-factor individuals may attribute positive interactions to stable traits of their partner, while high D-factor individuals may be more sensitive to negative interactions and use them to justify subsequent exploitation. -->
<!-- These findings extend beyond economic behavior to suggest that the D-factor influences the entire process of social perception and decision-making. The negative bias in opponent evaluation may serve as a cognitive mechanism that facilitates exploitation by reducing empathic concern and moral constraints associated with harming a positively regarded other. -->


<!-- The analysis of final-round behavior, where participants knew there would be no further interactions, provides insight into purely self-interested tendencies without the strategic considerations of reputation building. In these last rounds, high D-factor participants returned significantly lower amounts than low D-factor participants, both in absolute terms and as a percentage of investment. This finding represents a clear manifestation of the maximizing self-interest component of the D-factor when strategic constraints are removed. -->
<!-- The last-round effect essentially transforms the trust game into a dictator game, where participants can freely decide how much to return without fear of future consequences. The significant D-factor difference in this context aligns with previous research showing associations between the D-factor and selfish behavior in dictator games (Moshagen et al., 2020). The consistency across economic paradigms strengthens the conclusion that the D-factor represents a stable tendency toward self-maximization when social constraints are minimal. -->

<!-- A particularly interesting finding was that despite returning lower percentages, high D-factor participants did not achieve significantly higher total payoffs compared to low D-factor participants. This seemingly paradoxical result can be explained by the adaptive nature of the HMM opponent, which reduced investments in response to lower returns from high D-factor participants. This dynamic illustrates how exploitative strategies may fail to maximize long-term gains in environments with responsive counterparts, as initial exploitation triggers defensive reactions that ultimately limit future opportunities for gain. -->
<!-- This outcome has important implications for understanding the evolutionary stability of dark personality traits. While the D-factor may confer advantages in certain one-shot interactions or where reputation effects are minimal, its effectiveness as a long-term strategy in repeated interactions with responsive partners appears limited. This aligns with theoretical accounts suggesting that dark personality traits may represent frequency-dependent strategies that are most beneficial when rare in a population (Mealey, 1995), as widespread exploitation would trigger universal defensive responses that limit its effectiveness. -->

<!-- ## Theoretical and practical implications -->
<!-- Our findings have several important implications for personality psychology and behavioral economics. First, they demonstrate that the D-factor, as a unifying construct of dark personality traits, provides meaningful predictive power for understanding trustworthiness in economic exchanges. The convergent patterns of exploitation, negative social perception, and self-maximization across different measures support the conceptual coherence of the D-factor construct. -->
<!-- Second, our results highlight the importance of considering the temporal dimension of trust and reciprocity. The emerging differences between high and low D-factor participants over repeated interactions suggest that single-round economic games may underestimate the influence of personality traits on economic behavior. Future research should continue to examine how personality influences behavioral trajectories rather than just static decision points. -->
<!-- Third, the interaction between D-factor and opponent volatility provides insight into the contextual sensitivity of dark personality traits. The finding that high D-factor individuals modulate their exploitation strategies based on opponent predictability suggests sophisticated social intelligence rather than rigid antisocial tendencies. This nuance is important for developing more accurate models of how personality influences social decision-making across different environments. -->
<!-- Finally, our findings have practical implications for promoting cooperation in economic exchanges. The fact that high D-factor participants received lower investments over time indicates that exploitative strategies trigger defensive responses that ultimately limit opportunities for mutual gain. Interventions that highlight these long-term consequences might help redirect self-interested motivations toward more sustainable cooperative strategies. -->

<!-- ## Limitations and future directions -->
<!-- Several limitations of the current study suggest directions for future research. First, while we observed clear behavioral differences between high and low D-factor individuals, our design cannot determine which specific aspects of the D-factor (e.g., Machiavellianism, psychopathy, or narcissism) drive these effects. Future studies could include measures of these specific traits alongside the D-factor to examine their relative contributions. -->
<!-- Second, our use of HMM opponents provided excellent experimental control but may limit ecological validity. Future research could examine D-factor influences in fully human interactions to capture the richer social dynamics of real-world trust building. -->
<!-- <!-- Third, our computational modeling approach suggested differences in learning and decision strategies between high and low D-factor individuals, but further refinement of these models could provide deeper insights into the cognitive mechanisms underlying these behavioral differences. More sophisticated models incorporating theory of mind and planning horizons may better capture the strategic aspects of exploitation. --> -->
<!-- Finally, while we found significant differences in behavior and perception, we did not explore the underlying affective or cognitive processes that mediate these effects. Future studies could incorporate measures of empathy, moral disengagement, or social value orientation to understand how dark personality traits influence the subjective experience of economic exchanges. -->

The present study investigated how the Dark Factor of Personality (D-factor) influences behavior in repeated trust games, focusing on trustworthiness patterns, strategic adaptation, and perception of counterparts. Our findings reveal nuanced relationships between dark personality traits and economic decision-making that both confirm and challenge existing theoretical frameworks.

Our results demonstrated significant behavioral differences between individuals with high and low D-factor scores. High D-factor participants consistently returned lower proportions of investment compared to their low D-factor counterparts, with this difference becoming particularly pronounced in later rounds of the game. This pattern aligns with the fundamental definition of the D-factor as "the general tendency to maximize one's utility at the expense of others, accompanied by beliefs that serve as justifications" [@Moshagen2018]. The lower return percentages directly translate to greater self-benefit at the investor's expense, supporting the construct validity of the D-factor in predicting economic behavior.
Interestingly, the timing of these differences suggests a strategic component to this behavior. The absence of significant differences in early rounds, followed by emerging disparities in later stages of interaction, indicates a possible exploitation pattern that develops over time. This temporal dimension of trustworthiness aligns with prior research suggesting that dark personality traits may manifest most strongly after establishing a baseline relationship [@Jones2009]. This finding extends previous work on dark traits in one-shot economic games [@Zhao2015; @Thielmann2019] by demonstrating how these tendencies unfold over repeated interactions.

The significant interaction between D-factor, investment amount, round number, and opponent type reveals sophisticated strategic differences between high and low D-factor individuals. When facing the predictable human-like HMM opponent, high D-factor participants demonstrated a distinct pattern: they significantly decreased their returns over time for high-investment trials while maintaining relatively stable returns for low-investment trials. This selective exploitation strategy suggests a calculated approach to maximize gains while minimizing the risk of triggering retaliation from the investor.
This pattern is particularly significant because it represents a form of Machiavellian exploitation that targets situations of high trust (indicated by higher investments) rather than indiscriminate exploitation across all conditions. By selectively reducing reciprocity in high-stake interactions, high D-factor individuals effectively exploit the trust placed in them when the potential gains are greatest. This finding aligns with the conceptualization of Machiavellianism as involving strategic, long-term orientation to personal gain [@Jones2009] and supports previous research indicating that dark personality traits are associated with strategic rather than impulsive exploitation [@Gunnthorsdottir2002].
Notably, this strategic exploitation pattern was only observed with the more predictable human-like HMM opponent, not with the volatile opponent. This distinction suggests that high D-factor individuals may be particularly adept at identifying and exploiting predictable social dynamics, while showing more caution in volatile or unpredictable social environments. This contextual sensitivity adds important nuance to our understanding of how dark personality traits manifest in economic decisions.


The significant four-way interaction involving investment, order of opponent presentation, D-factor, and round number further illuminates the adaptive nature of exploitation strategies. High D-factor participants who first encountered the stable (human-like) opponent showed decreasing returns over rounds for high and medium investments but maintained stable returns for low investments. In contrast, those who initially faced the volatile opponent reduced returns for low and medium investments while maintaining returns for high investments.
This pattern suggests that high D-factor individuals rapidly adapt their exploitation strategies based on initial experiences. When first exposed to a predictable environment, they learn to exploit high-trust situations. Conversely, when first exposed to volatility, they adopt a more conservative strategy that maintains cooperation in high-stake interactions while reducing reciprocity in lower-risk situations. This adaptive learning demonstrates sophisticated social intelligence that may underlie the effectiveness of dark personality traits in navigating complex social environments.
Low D-factor participants, regardless of the order in which they faced opponents, maintained relatively stable return rates across rounds and investment levels, suggesting a more consistent approach to reciprocity that is less influenced by strategic considerations or learning effects. This stability in cooperative behavior may reflect stronger adherence to fairness norms and less susceptibility to exploitative tendencies.


The analysis of opponent ratings revealed that D-factor scores significantly influenced how participants perceived their counterparts. High D-factor participants consistently rated their opponents lower on cooperativeness, trustworthiness, and desirability for future interaction, regardless of the opponent's actual behavior. This negative perceptual bias is consistent with research suggesting that individuals with dark personality traits may have distorted social perceptions that justify exploitation [@Moshagen2018; @Zettler2021].
The interaction between D-factor, game order, and opponent type for trust ratings suggests complex differences in how high and low D-factor individuals update their social perceptions based on experience. While low D-factor participants showed increased trust in human-like opponents from first to second game, high D-factor participants showed decreased trust in volatile opponents. This differential updating may reflect differences in attribution processes: low D-factor individuals may attribute positive interactions to stable traits of their partner, while high D-factor individuals may be more sensitive to negative interactions and use them to justify subsequent exploitation.
These findings extend beyond economic behavior to suggest that the D-factor influences the entire process of social perception and decision-making. The negative bias in opponent evaluation may serve as a cognitive mechanism that facilitates exploitation by reducing empathic concern and moral constraints associated with harming a positively regarded other.


The analysis of final-round behavior, where participants knew there would be no further interactions, provides insight into purely self-interested tendencies without the strategic considerations of reputation building. In these last rounds, high D-factor participants returned significantly lower amounts than low D-factor participants, both in absolute terms and as a percentage of investment. This finding represents a clear manifestation of the maximizing self-interest component of the D-factor when strategic constraints are removed.
The last-round effect essentially transforms the trust game into a dictator game, where participants can freely decide how much to return without fear of future consequences. The significant D-factor difference in this context aligns with previous research showing associations between the D-factor and selfish behavior in dictator games [@Moshagen2020]. The consistency across economic paradigms strengthens the conclusion that the D-factor represents a stable tendency toward self-maximization when social constraints are minimal.

A particularly interesting finding was that despite returning lower percentages, high D-factor participants did not achieve significantly higher total payoffs compared to low D-factor participants. This seemingly paradoxical result can be explained by the adaptive nature of the HMM opponent, which reduced investments in response to lower returns from high D-factor participants. This dynamic illustrates how exploitative strategies may fail to maximize long-term gains in environments with responsive counterparts, as initial exploitation triggers defensive reactions that ultimately limit future opportunities for gain.
This outcome has important implications for understanding the evolutionary stability of dark personality traits. While the D-factor may confer advantages in certain one-shot interactions or where reputation effects are minimal, its effectiveness as a long-term strategy in repeated interactions with responsive partners appears limited. This aligns with theoretical accounts suggesting that dark personality traits may represent frequency-dependent strategies that are most beneficial when rare in a population [@Mealey1995], as widespread exploitation would trigger universal defensive responses that limit its effectiveness.

## Theoretical and practical implications
Our findings have several important implications for personality psychology and behavioral economics. First, they demonstrate that the D-factor, as a unifying construct of dark personality traits, provides meaningful predictive power for understanding trustworthiness in economic exchanges. The convergent patterns of exploitation, negative social perception, and self-maximization across different measures support the conceptual coherence of the D-factor construct.
Second, our results highlight the importance of considering the temporal dimension of trust and reciprocity. The emerging differences between high and low D-factor participants over repeated interactions suggest that single-round economic games may underestimate the influence of personality traits on economic behavior. Future research should continue to examine how personality influences behavioral trajectories rather than just static decision points.
Third, the interaction between D-factor and opponent volatility provides insight into the contextual sensitivity of dark personality traits. The finding that high D-factor individuals modulate their exploitation strategies based on opponent predictability suggests sophisticated social intelligence rather than rigid antisocial tendencies. This nuance is important for developing more accurate models of how personality influences social decision-making across different environments.
Finally, our findings have practical implications for promoting cooperation in economic exchanges. The fact that high D-factor participants received lower investments over time indicates that exploitative strategies trigger defensive responses that ultimately limit opportunities for mutual gain. Interventions that highlight these long-term consequences might help redirect self-interested motivations toward more sustainable cooperative strategies.

## Limitations and future directions
Several limitations of the current study suggest directions for future research. First, while we observed clear behavioral differences between high and low D-factor individuals, our design cannot determine which specific aspects of the D-factor (e.g., Machiavellianism, psychopathy, or narcissism) drive these effects. Future studies could include measures of these specific traits alongside the D-factor to examine their relative contributions.
Second, our use of HMM opponents provided excellent experimental control but may limit ecological validity. Future research could examine D-factor influences in fully human interactions to capture the richer social dynamics of real-world trust building.
Finally, while we found significant differences in behavior and perception, we did not explore the underlying affective or cognitive processes that mediate these effects. Future studies could incorporate measures of empathy, moral disengagement, or social value orientation to understand how dark personality traits influence the subjective experience of economic exchanges.

# Conclusion
This study provides novel insights into how the Dark Factor of Personality influences behavior in repeated trust games. Our findings demonstrate that individuals with high D-factor scores exhibit systematic patterns of lower reciprocity that emerge most strongly in later rounds of interaction, particularly when facing predictable opponents and receiving high investments. These behavioral differences are accompanied by more negative perceptions of interaction partners, suggesting a comprehensive influence of dark personality traits on both social cognition and economic decision-making.
The sophistication of exploitation strategies—adapting to opponent type, investment level, and interaction history—indicates that dark personality traits may involve complex social intelligence rather than simple antisocial tendencies. However, the failure of these exploitative strategies to yield higher total payoffs highlights the self-limiting nature of exploitation in responsive social environments.
These findings bridge the gap between personality psychology and behavioral economics, demonstrating how stable personality traits manifest in dynamic economic exchanges. They extend previous research on dark personality traits by revealing how exploitation unfolds over time and varies across contexts. Future research should continue to explore the cognitive and affective mechanisms underlying these behavioral patterns and examine how interventions might promote cooperation even among individuals with stronger exploitative tendencies.
Understanding the relationship between the D-factor and trustworthiness has significant implications for promoting cooperative outcomes in economic and social interactions. By recognizing how dark personality traits influence trust dynamics, we can develop more effective strategies for fostering cooperation and limiting the social costs of exploitation.

<!-- high D-factor participants showed relatively stable returns across investor states, particularly with the volatile investor, suggesting a form of behavioral rigidity rather than strategic flexibility. -->

<!-- This behavioral inflexibility was especially evident in the volatile HMM condition, where high D-factor participants maintained consistent return rates regardless of the investor's state. In contrast, low D-factor participants showed marked sensitivity to investor states, adjusting their returns upward as the investor's state improved from unhappy to happy. This pattern held across both human-like and volatile HMM conditions, though it was more pronounced with the volatile investor. These findings suggest that contrary to the Machiavellian tendency for strategic manipulation, high D-factor individuals might actually be less adept at reading and responding to social cues in economic interactions. -->

<!-- One possible explanation for this unexpected pattern lies in the fundamental nature of the D-factor as "the tendency to maximize one's individual utility at the expense of others with self-justifying beliefs." The behavioral rigidity we observed might represent a form of defensive strategy - by maintaining stable (and relatively lower) returns regardless of the investor's state, high D-factor participants could be prioritizing consistent personal gain over reciprocity. This interpretation aligns with recent work suggesting that dark personality traits might manifest not just as active exploitation, but as a general insensitivity to social cues that would typically motivate cooperative behavior. -->

<!-- The finding that low D-factor participants showed greater behavioral flexibility and responsiveness to investor states suggests that the ability to maintain cooperative relationships might require active engagement with partner behavior rather than strategic manipulation. This has important implications for understanding how personality traits influence economic decision-making and challenges the traditional view of dark personality traits as primarily manifesting through strategic exploitation. -->

<!-- **The ratings findings reveal that Dark Factor personality traits substantially influence how participants perceive and evaluate their opponents in economic games. High D-factor participants consistently demonstrate more negative opponent evaluations across all rating dimensions, particularly in first encounters. Interestingly, while low D-factor participants show greater sensitivity to game order (with steeper declines in ratings from first to second games), high D-factor participants exhibit more nuanced discrimination between opponent types, especially in trust evaluations. This pattern suggests that individuals with elevated Dark Factor traits may approach social interactions with an initial negative bias, yet demonstrate greater strategic adaptability to different opponent behaviors over repeated interactions. These results highlight the importance of considering personality traits as moderators of subjective experience in repeated economic games, even when objective game parameters remain constant.** -->

# References
